# Callback Webhook Integration Guide
# H∆∞·ªõng d·∫´n T√≠ch h·ª£p Callback Webhook

T√†i li·ªáu n√†y m√¥ t·∫£ chi ti·∫øt 2 lo·∫°i callback webhooks kh√°c nhau v√† c√°ch backend c·∫ßn implement ƒë·ªÉ nh·∫≠n notifications.

## üìã T·ªïng quan Callback Webhooks

H·ªá th·ªëng c√≥ **2 lo·∫°i callback webhook ch√≠nh** t∆∞∆°ng ·ª©ng v·ªõi 2 workflows kh√°c nhau:

### 1. **File Upload Callback** (Raw Content Processing)
- **Endpoint Pattern**: `/api/webhooks/file-processed`
- **Workflow**: File upload ‚Üí Raw content extraction ‚Üí Qdrant storage
- **API**: `POST /companies/{companyId}/files/upload`

### 2. **AI Extraction Callback** (Structured Data Processing)  
- **Endpoint Pattern**: `/api/webhooks/ai/extraction-callback`
- **Workflow**: File ‚Üí AI template extraction ‚Üí Structured data ‚Üí Qdrant storage
- **API**: `POST /api/extract/process-async`

---

## üîÑ Workflow 1: File Upload Callback

### Backend Request Example:
```bash
POST /companies/company-123/files/upload
Content-Type: application/json

{
  "r2_url": "https://pub-xyz.r2.dev/companies/company-123/documents/file.pdf",
  "data_type": "document", 
  "industry": "REAL_ESTATE",
  "language": "VIETNAMESE",
  "metadata": {
    "original_name": "company_profile.pdf",
    "file_id": "file_123456789",
    "file_size": 1024000,
    "file_type": "application/pdf",
    "uploaded_by": "user_uid_123"
  },
  "upload_to_qdrant": true,
  "callback_url": "https://api.agent8x.io.vn/api/webhooks/file-processed"
}
```

### Expected Callback (Success):
```bash
POST https://api.agent8x.io.vn/api/webhooks/file-processed
Content-Type: application/json
X-Webhook-Source: ai-service
X-Webhook-Signature: sha256=abc123...
User-Agent: Agent8x-AI-Service/1.0

{
  "event": "file.uploaded",
  "companyId": "company-123", 
  "data": {
    "fileId": "file_123456789",
    "status": "completed",
    "chunksCreated": 8,
    "processingTime": 5.23,
    "processedAt": "2025-07-27T07:30:00.123Z",
    "tags": ["company-info", "profile", "overview"],
    
    // ‚úÖ RAW CONTENT (Full original file content for database storage)
    "raw_content": "C√îNG TY C·ªî PH·∫¶N B·∫¢O HI·ªÇM AIA VI·ªÜT NAM\n\nTh√¥ng tin c√¥ng ty:\nAIA Vi·ªát Nam ƒë∆∞·ª£c th√†nh l·∫≠p t·ª´ nƒÉm 2000...\n\nC√°c s·∫£n ph·∫©m ch√≠nh:\n1. B·∫£o hi·ªÉm nh√¢n th·ªç\n2. B·∫£o hi·ªÉm s·ª©c kh·ªèe\n3. B·∫£o hi·ªÉm li√™n k·∫øt chung...",
    
    // ‚úÖ Complete file metadata for reference
    "file_metadata": {
      "original_name": "AIA_company_profile.pdf",
      "file_name": "AIA_company_profile_processed.pdf",
      "file_size": 2048000,
      "file_type": "application/pdf",
      "uploaded_by": "user_uid_123",
      "description": "Company profile and information document",
      "r2_url": "https://static.agent8x.io.vn/company/company-123/files/AIA_company_profile.pdf"
    }
  },
  "timestamp": "2025-07-27T07:30:00.123Z"
}
```

### Expected Callback (Error):
```bash
POST https://api.agent8x.io.vn/api/webhooks/file-processed
Content-Type: application/json

{
  "event": "file.uploaded",
  "companyId": "company-123",
  "data": {
    "fileId": "file_123456789", 
    "status": "failed",
    "error": "AI extraction failed: Invalid file format",
    "failedAt": "2025-07-27T07:30:00.123Z"
  },
  "timestamp": "2025-07-27T07:30:00.123Z"
}
```

---

## üéØ Workflow 2: AI Extraction Callback

### Backend Request Example:
```bash
POST /api/extract/process-async
Content-Type: application/json

{
  "r2_url": "https://pub-xyz.r2.dev/companies/aia/documents/insurance_products.pdf",
  "company_id": "9a974d00-1a4b-4d5d-8dc3-4b5058255b8f",
  "industry": "INSURANCE",
  "file_name": "insurance_products.pdf",
  "file_size": 2048000,
  "file_type": "application/pdf", 
  "data_type": "products",
  "target_categories": ["products", "services"],
  "language": "VIETNAMESE",
  "callback_url": "https://api.agent8x.io.vn/api/webhooks/ai/extraction-callback",
  "company_info": {
    "name": "AIA Vietnam",
    "industry": "insurance"
  }
}
```

### Expected Callback (Success):
```bash
POST https://api.agent8x.io.vn/api/webhooks/ai/extraction-callback
Content-Type: application/json
X-Webhook-Source: ai-service
X-Webhook-Signature: sha256=abc123...
User-Agent: Agent8x-AI-Service/1.0

{
  "task_id": "extract_1753600241578_a6406721",
  "company_id": "9a974d00-1a4b-4d5d-8dc3-4b5058255b8f",
  "status": "completed",
  "processing_time": 16.6029052734375,
  "timestamp": "2025-07-27T07:11:00.602714",
  
  // Summary results for quick display
  "results": {
    "products_count": 3,
    "services_count": 2, 
    "total_items": 5,
    "ai_provider": "gemini",
    "template_used": "InsuranceExtractionTemplate"
  },
  
  // ‚úÖ FULL RAW CONTENT (Complete original file text)
  "raw_content": "--- D·ªäCH V·ª§ AIA VI·ªÜT NAM (25/7/2025) ‚Äì CHI TI·∫æT QUY·ªÄN L·ª¢I ‚Äì PH√ç ‚Äì ƒêI·ªÄU KI·ªÜN ---\n\n1. AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn (B·∫£o hi·ªÉm li√™n k·∫øt chung)\n   * Qu·ªπ b·∫£o v·ªá: Kh√°ch ƒë√≥ng ph√≠ c∆° b·∫£n ƒë·∫ßy ƒë·ªß trong 4‚Äë15 nƒÉm ƒë·∫ßu t√πy ph∆∞∆°ng √°n...",
  
  // ‚úÖ FULL STRUCTURED DATA (Complete products and services with all details + AI categorization)
  "structured_data": {
    "products": [
      {
        "name": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn",
        "type": "B·∫£o hi·ªÉm li√™n k·∫øt chung",
        "description": "B·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc r·ªßi ro t·ª≠ vong, th∆∞∆°ng t·∫≠t to√†n b·ªô vƒ©nh vi·ªÖn, b·ªánh hi·ªÉm ngh√®o (t√πy g√≥i). H∆∞·ªüng gi√° tr·ªã b·∫£o v·ªá ∆∞u vi·ªát; quy·ªÅn l·ª£i b·∫£o v·ªá c√≥ th·ªÉ tƒÉng th√™m t·ªõi 20% STBH nh·ªù ch∆∞∆°ng tr√¨nh AIA Vitality. Th∆∞·ªüng duy tr√¨ h·ª£p ƒë·ªìng.",
        "coverage_period": "30 nƒÉm",
        "premium": "T√πy thu·ªôc v√†o tu·ªïi, gi·ªõi t√≠nh, ch∆∞∆°ng tr√¨nh, s·∫£n ph·∫©m b·ªï sung",
        "terms_and_conditions": "T√πy s·∫£n ph·∫©m, y√™u c·∫ßu s·ª©c kh·ªèe v√† khai th√°c th√¥ng tin y t·∫ø.",
        // ‚úÖ AI-generated categorization for hybrid search
        "category": "b·∫£o_hi·ªÉm_nh√¢n_th·ªç",
        "sub_category": "b·∫£o_hi·ªÉm_li√™n_k·∫øt",
        "tags": ["nh√¢n_th·ªç", "li√™n_k·∫øt_chung", "b·∫£o_v·ªá_to√†n_di·ªán", "aia_vitality", "th∆∞·ªüng_duy_tr√¨"],
        "target_audience": ["c√°_nh√¢n", "gia_ƒë√¨nh"],
        "coverage_type": ["t·ª≠_vong", "th∆∞∆°ng_t·∫≠t", "b·ªánh_hi·ªÉm_ngh√®o"]
      },
      {
        "name": "B·∫£o hi·ªÉm To√†n di·ªán B·ªánh hi·ªÉm ngh√®o 2.0",
        "type": "Critical Illness 2.0",
        "description": "B·∫£o v·ªá tr∆∞·ªõc 107 b·ªánh hi·ªÉm ngh√®o, chi tr·∫£ theo giai ƒëo·∫°n.",
        "age_range": "30 ng√†y ‚Äì 65 tu·ªïi",
        "coverage_period": "T·ªëi ƒëa ƒë·∫øn 75 tu·ªïi",
        "premium": "Ph√≠ thay ƒë·ªïi t√πy theo tu·ªïi, g√≥i b·∫£o hi·ªÉm",
        "terms_and_conditions": "Tu·ªïi t·ª´ 30 ng√†y ƒë·∫øn 65 tu·ªïi, kh√¥ng tham gia n·∫øu ƒë√£ c√≥ b·ªánh hi·ªÉm ngh√®o t·∫°i th·ªùi ƒëi·ªÉm tham gia; Quy ƒë·ªãnh th·ªùi gian ch·ªù.",
        // ‚úÖ AI-generated categorization for hybrid search
        "category": "b·∫£o_hi·ªÉm_s·ª©c_kh·ªèe",
        "sub_category": "b·ªánh_hi·ªÉm_ngh√®o",
        "tags": ["b·ªánh_hi·ªÉm_ngh√®o", "107_b·ªánh", "chi_tr·∫£_giai_ƒëo·∫°n", "to√†n_di·ªán"],
        "target_audience": ["m·ªçi_l·ª©a_tu·ªïi"],
        "coverage_type": ["b·ªánh_hi·ªÉm_ngh√®o", "ung_th∆∞", "tim_m·∫°ch"]
      },
      {
        "name": "B·∫£o hi·ªÉm s·ª©c kh·ªèe B√πng Gia L·ª±c",
        "type": "Family Health Insurance",
        "description": "B·∫£o hi·ªÉm s·ª©c kh·ªèe cho gia ƒë√¨nh.",
        "age_range": "30 ng√†y tu·ªïi ƒë·∫øn 46 tu·ªïi",
        "coverage_area": "Ch·ªâ t·∫°i Vi·ªát Nam",
        "premium": "Ph√≠ t√πy theo g√≥i ch·ªçn (C∆° b·∫£n, N√¢ng cao, To√†n di·ªán, Ho√†n h·∫£o), gi·ªõi t√≠nh, tu·ªïi v√† ph·∫°m vi b·∫£o v·ªá (Vi·ªát Nam/To√†n c·∫ßu)",
        "terms_and_conditions": "Tu·ªïi t·ª´ 30 ng√†y ƒë·∫øn 46 tu·ªïi (ho·∫∑c theo ƒëi·ªÅu kho·∫£n c·ª• th·ªÉ), ƒëi·ªÅu ki·ªán s·ª©c kh·ªèe theo th·∫©m ƒë·ªãnh c·ªßa AIA.",
        // ‚úÖ AI-generated categorization for hybrid search
        "category": "b·∫£o_hi·ªÉm_s·ª©c_kh·ªèe",
        "sub_category": "b·∫£o_hi·ªÉm_gia_ƒë√¨nh",
        "tags": ["gia_ƒë√¨nh", "s·ª©c_kh·ªèe", "nhi·ªÅu_g√≥i", "vi·ªát_nam", "to√†n_c·∫ßu"],
        "target_audience": ["gia_ƒë√¨nh", "tr·∫ª_em"],
        "coverage_type": ["y_t·∫ø", "n·ªôi_tr√∫", "ngo·∫°i_tr√∫"]
      }
    ],
    "services": [
      {
        "name": "AIA Vitality",
        "type": "Ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i",
        "description": "Ch∆∞∆°ng tr√¨nh AIA Vitality cung c·∫•p quy·ªÅn l·ª£i b·∫£o v·ªá c√≥ th·ªÉ tƒÉng th√™m t·ªõi 20% STBH cho s·∫£n ph·∫©m AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn v√† th∆∞·ªüng ƒë·∫øn 30% ph√≠ b·∫£o hi·ªÉm trung b√¨nh 5 nƒÉm cho s·∫£n ph·∫©m B·∫£o hi·ªÉm To√†n di·ªán B·ªánh hi·ªÉm ngh√®o 2.0 v√† th∆∞·ªüng ƒë·∫øn 60% ph√≠ cho s·∫£n ph·∫©m B·∫£o hi·ªÉm s·ª©c kh·ªèe B√πng Gia L·ª±c.",
        "pricing": "T√≠ch h·ª£p v√†o c√°c g√≥i b·∫£o hi·ªÉm",
        "availability": "C√≥ s·∫µn cho c√°c s·∫£n ph·∫©m b·∫£o hi·ªÉm AIA",
        // ‚úÖ AI-generated categorization for hybrid search
        "category": "ch∆∞∆°ng_tr√¨nh_∆∞u_ƒë√£i",
        "sub_category": "vitality_rewards",
        "tags": ["∆∞u_ƒë√£i", "tƒÉng_quy·ªÅn_l·ª£i", "th∆∞·ªüng_ph√≠", "s·ª©c_kh·ªèe", "l·ªëi_s·ªëng"],
        "target_audience": ["kh√°ch_h√†ng_hi·ªán_t·∫°i"],
        "service_type": ["loyalty_program", "health_wellness"]
      },
      {
        "name": "ƒê·∫∑t l·ªãch kh√°m t·∫°i b·ªánh vi·ªán",
        "type": "D·ªãch v·ª• h·ªó tr·ª£",
        "description": "∆Øu ƒë√£i d·ªãch v·ª• ƒë·∫∑t l·ªãch kh√°m t·∫°i m·ªôt s·ªë b·ªánh vi·ªán uy t√≠n (t·ª´ 17/7/2025 ƒë·∫øn 31/12/2025)",
        "pricing": "Mi·ªÖn ph√≠",
        "availability": "T·ª´ 17/7/2025 ƒë·∫øn 31/12/2025",
        // ‚úÖ AI-generated categorization for hybrid search
        "category": "d·ªãch_v·ª•_h·ªó_tr·ª£",
        "sub_category": "ƒë·∫∑t_l·ªãch_kh√°m",
        "tags": ["ƒë·∫∑t_l·ªãch", "b·ªánh_vi·ªán", "mi·ªÖn_ph√≠", "h·ªó_tr·ª£_kh√°ch_h√†ng"],
        "target_audience": ["t·∫•t_c·∫£_kh√°ch_h√†ng"],
        "service_type": ["customer_support", "healthcare_booking"]
      }
    ],
    "extraction_summary": {
      "total_products": 3,
      "total_services": 2,
      "data_quality": "high",
      "categorization_notes": "The categorization was based on whether the item was a tangible product or an intangible service. Insurance plans were categorized as products, while additional benefits and support services were categorized as services.",
      "industry_context": "The insurance industry context was used to differentiate between insurance plans (products) and added-value services."
    }
  },
  
  // Full extraction metadata for reference
  "extraction_metadata": {
    "r2_url": "https://static.agent8x.io.vn/company/9a974d00-1a4b-4d5d-8dc3-4b5058255b8f/files/SanPham-AIA.txt",
    "extraction_mode": "auto_categorization",
    "target_categories": ["products", "services"],
    "ai_provider": "gemini",
    "template_used": "InsuranceExtractionTemplate",
    "industry": "insurance",
    "data_type": "auto",
    "file_name": "SanPham-AIA.txt",
    "file_size": 15420,
    "file_type": "text/plain",
    "language": "vi",
    "extraction_timestamp": "2025-07-26T14:52:54.626455",
    "total_items": 5,
    "source": "ai_extraction_service_v2"
  }
}
```

### Expected Callback (Error):
```bash  
POST https://api.agent8x.io.vn/api/webhooks/ai/extraction-callback
Content-Type: application/json

{
  "task_id": "extract_1753600241578_a6406721",
  "company_id": "9a974d00-1a4b-4d5d-8dc3-4b5058255b8f", 
  "status": "failed",
  "error": "AI extraction timeout after 30 seconds",
  "timestamp": "2025-07-27T07:11:00.602714"
}
```

---

## üõ† Backend Implementation Requirements

### 1. **File Upload Webhook Handler**

```javascript
// Backend implementation for File Upload Callback
app.post('/api/webhooks/file-processed', webhookAuth, async (req, res) => {
  try {
    const { event, companyId, data, timestamp } = req.body;
    
    if (event === 'file.uploaded') {
      if (data.status === 'completed') {
        // ‚úÖ File upload v√† raw extraction th√†nh c√¥ng - L∆ØU TO√ÄN B·ªò D·ªÆ LI·ªÜU
        console.log(`‚úÖ File ${data.fileId} processed successfully`);
        console.log(`   üìÑ Raw content: ${data.raw_content ? data.raw_content.length : 0} characters`);
        console.log(`   üì¶ Chunks created: ${data.chunksCreated}`);
        console.log(`   üè∑Ô∏è Tags: ${data.tags ? data.tags.join(', ') : 'none'}`);
        console.log(`   ‚è±Ô∏è Processing time: ${data.processingTime}s`);
        
        // Store file upload record in database
        const fileRecord = await db.uploaded_files.create({
          file_id: data.fileId,
          company_id: companyId,
          original_name: data.file_metadata.original_name,
          file_name: data.file_metadata.file_name,
          file_size: data.file_metadata.file_size,
          file_type: data.file_metadata.file_type,
          uploaded_by: data.file_metadata.uploaded_by,
          description: data.file_metadata.description,
          r2_url: data.file_metadata.r2_url,
          raw_content: data.raw_content,  // Store complete file content
          tags: JSON.stringify(data.tags),
          chunks_created: data.chunksCreated,
          processing_time: data.processingTime,
          processed_at: new Date(data.processedAt),
          status: data.status,
          created_at: new Date()
        });
        
        // Update company file count
        await db.companies.update(
          { id: companyId },
          { 
            total_files: db.sequelize.literal('total_files + 1'),
            last_file_uploaded: new Date()
          }
        );
        
        // Index tags for search
        if (data.tags && data.tags.length > 0) {
          for (const tag of data.tags) {
            await db.file_tags.upsert({
              company_id: companyId,
              tag_name: tag,
              file_count: db.sequelize.literal('file_count + 1'),
              updated_at: new Date()
            });
          }
        }
        
        res.status(200).json({
          success: true,
          message: "File upload record saved successfully",
          file_record: {
            id: fileRecord.id,
            file_id: data.fileId,
            chunks_created: data.chunksCreated,
            raw_content_length: data.raw_content ? data.raw_content.length : 0
          }
        });
        
      } else if (data.status === 'failed') {
        // ‚ùå File upload th·∫•t b·∫°i
        console.error(`‚ùå File ${data.fileId} processing failed: ${data.error}`);
        
        // Update database status  
        await db.uploaded_files.create({
          file_id: data.fileId,
          company_id: companyId,
          status: 'failed',
          error_message: data.error,
          raw_content: data.raw_content || "", // Partial content if available
          file_metadata: JSON.stringify(data.file_metadata || {}),
          created_at: new Date()
        });
        
        res.status(200).json({
          success: true,
          message: "Error status updated successfully"
        });
      }
    }
    
  } catch (error) {
    console.error('‚ùå File upload webhook processing failed:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});
```

### 2. **AI Extraction Webhook Handler**

```javascript
// Backend implementation for AI Extraction Callback
app.post('/api/webhooks/ai/extraction-callback', webhookAuth, async (req, res) => {
  try {
    const { 
      task_id, 
      company_id, 
      status, 
      processing_time,
      results,
      raw_content,
      structured_data,
      extraction_metadata,
      error, 
      timestamp 
    } = req.body;
    
    if (status === 'completed') {
      // ‚úÖ AI Extraction th√†nh c√¥ng - L∆ØU TO√ÄN B·ªò D·ªÆ LI·ªÜU
      console.log(`üéâ AI extraction ${task_id} completed successfully`);
      console.log(`   üì¶ Products: ${results.products_count}`);
      console.log(`   üîß Services: ${results.services_count}`);
      console.log(`   üìÑ Raw content: ${raw_content ? raw_content.length : 0} characters`);
      console.log(`   ü§ñ AI Provider: ${results.ai_provider}`);
      console.log(`   üìã Template: ${results.template_used}`);
      
      // 1. Update extraction job status
      await db.extraction_jobs.update(
        { task_id: task_id },
        {
          status: status,
          completed_at: new Date(),
          processing_time: processing_time,
          ai_provider: results.ai_provider,
          template_used: results.template_used,
          total_items_extracted: results.total_items,
          raw_content: raw_content, // Store full original content
          extraction_metadata: JSON.stringify(extraction_metadata)
        }
      );
      
      const job = await db.extraction_jobs.findOne({ task_id: task_id });
      
      // 2. Save extracted PRODUCTS to database
      if (structured_data.products && structured_data.products.length > 0) {
        for (const product of structured_data.products) {
          await db.extracted_products.create({
            job_id: job.id,
            company_id: company_id,
            name: product.name,
            type: product.type,
            description: product.description,
            coverage_period: product.coverage_period,
            age_range: product.age_range,
            coverage_area: product.coverage_area,
            premium: product.premium,
            terms_and_conditions: product.terms_and_conditions,
            created_at: new Date()
          });
        }
        console.log(`‚úÖ Saved ${structured_data.products.length} products to database`);
      }
      
      // 3. Save extracted SERVICES to database
      if (structured_data.services && structured_data.services.length > 0) {
        for (const service of structured_data.services) {
          await db.extracted_services.create({
            job_id: job.id,
            company_id: company_id,
            name: service.name,
            type: service.type,
            description: service.description,
            pricing: service.pricing,
            availability: service.availability,
            created_at: new Date()
          });
        }
        console.log(`‚úÖ Saved ${structured_data.services.length} services to database`);
      }
      
      // 4. Return success response
      res.status(200).json({
        success: true,
        message: "Extraction results saved successfully",
        saved_items: {
          products: structured_data.products ? structured_data.products.length : 0,
          services: structured_data.services ? structured_data.services.length : 0,
          total: results.total_items
        }
      });
      
    } else if (status === 'failed') {
      // ‚ùå AI Extraction th·∫•t b·∫°i  
      console.error(`‚ùå AI extraction ${task_id} failed: ${error}`);
      
      // Update database status
      await db.extraction_jobs.update(
        { task_id: task_id },
        {
          status: 'failed',
          completed_at: new Date(),
          error_message: error
        }
      );
      
      res.status(200).json({
        success: true,
        message: "Error status updated successfully"
      });
    }
    
  } catch (error) {
    console.error('‚ùå AI extraction webhook processing failed:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});
```

---

## ÔøΩ Database Schema Updates

### Required Database Tables:

#### 1. **uploaded_files table** (for file upload callbacks)
```sql
CREATE TABLE uploaded_files (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    file_id VARCHAR(255) UNIQUE NOT NULL,
    company_id VARCHAR(255) NOT NULL,
    original_name VARCHAR(500) NOT NULL,
    file_name VARCHAR(500) NOT NULL,
    file_size BIGINT NOT NULL,
    file_type VARCHAR(100) NOT NULL,
    uploaded_by VARCHAR(255),
    description TEXT,
    r2_url TEXT NOT NULL,
    raw_content TEXT,  -- Store complete file content
    tags JSONB,
    chunks_created INTEGER DEFAULT 0,
    processing_time DECIMAL(10,3),
    processed_at TIMESTAMP,
    status VARCHAR(50) DEFAULT 'uploaded',
    error_message TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

#### 2. **extraction_jobs table** (for AI extraction callbacks)
```sql
CREATE TABLE extraction_jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    task_id VARCHAR(255) UNIQUE NOT NULL,
    company_id VARCHAR(255) NOT NULL,
    file_name VARCHAR(255) NOT NULL,
    r2_url TEXT NOT NULL,
    industry VARCHAR(100) NOT NULL,
    data_type VARCHAR(50) NOT NULL,
    status VARCHAR(50) DEFAULT 'queued',
    submitted_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP NULL,
    processing_time DECIMAL(10,3) NULL,
    ai_provider VARCHAR(50) NULL,
    template_used VARCHAR(100) NULL,
    total_items_extracted INTEGER NULL,
    raw_content TEXT,  -- Store complete original content
    extraction_metadata JSONB,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

#### 3. **extracted_products table** (store individual products v·ªõi AI categorization)
```sql
CREATE TABLE extracted_products (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    job_id UUID REFERENCES extraction_jobs(id),
    company_id VARCHAR(255),
    name VARCHAR(500) NOT NULL,
    type VARCHAR(200),
    description TEXT,
    coverage_period VARCHAR(100),
    age_range VARCHAR(100),
    coverage_area VARCHAR(200),
    premium TEXT,
    terms_and_conditions TEXT,
    -- ‚úÖ AI Categorization fields cho Hybrid Search
    category VARCHAR(200), -- e.g., "b·∫£o_hi·ªÉm_nh√¢n_th·ªç", "b·∫£o_hi·ªÉm_s·ª©c_kh·ªèe"
    sub_category VARCHAR(200), -- e.g., "b·∫£o_hi·ªÉm_li√™n_k·∫øt", "b·ªánh_hi·ªÉm_ngh√®o"
    tags JSONB, -- e.g., ["nh√¢n_th·ªç", "li√™n_k·∫øt_chung", "b·∫£o_v·ªá_to√†n_di·ªán"]
    target_audience JSONB, -- e.g., ["c√°_nh√¢n", "gia_ƒë√¨nh"]
    coverage_type JSONB, -- e.g., ["t·ª≠_vong", "th∆∞∆°ng_t·∫≠t", "b·ªánh_hi·ªÉm_ngh√®o"]
    -- ‚úÖ Qdrant integration
    qdrant_point_id VARCHAR(255), -- Single point ID for individual product storage
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### 4. **extracted_services table** (store individual services v·ªõi AI categorization)
```sql
CREATE TABLE extracted_services (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    job_id UUID REFERENCES extraction_jobs(id),
    company_id VARCHAR(255),
    name VARCHAR(500) NOT NULL,
    type VARCHAR(200),
    description TEXT,
    pricing TEXT,
    availability VARCHAR(200),
    -- ‚úÖ AI Categorization fields cho Hybrid Search
    category VARCHAR(200), -- e.g., "ch∆∞∆°ng_tr√¨nh_∆∞u_ƒë√£i", "d·ªãch_v·ª•_h·ªó_tr·ª£"
    sub_category VARCHAR(200), -- e.g., "vitality_rewards", "ƒë·∫∑t_l·ªãch_kh√°m"
    tags JSONB, -- e.g., ["∆∞u_ƒë√£i", "tƒÉng_quy·ªÅn_l·ª£i", "th∆∞·ªüng_ph√≠"]
    target_audience JSONB, -- e.g., ["kh√°ch_h√†ng_hi·ªán_t·∫°i"]
    service_type JSONB, -- e.g., ["loyalty_program", "health_wellness"]
    -- ‚úÖ Qdrant integration
    qdrant_point_id VARCHAR(255), -- Single point ID for individual service storage
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### 5. **file_tags table** (for tag indexing)
```sql
CREATE TABLE file_tags (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id VARCHAR(255) NOT NULL,
    tag_name VARCHAR(100) NOT NULL,
    file_count INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(company_id, tag_name)
);
```

#### 6. **companies table** (update for file tracking)
```sql
ALTER TABLE companies 
ADD COLUMN total_files INTEGER DEFAULT 0,
ADD COLUMN last_file_uploaded TIMESTAMP;
```

### Database Indexes:
```sql
-- Performance indexes
CREATE INDEX idx_extraction_jobs_company_id ON extraction_jobs(company_id);
CREATE INDEX idx_extraction_jobs_task_id ON extraction_jobs(task_id);
CREATE INDEX idx_extracted_products_company_id ON extracted_products(company_id);
CREATE INDEX idx_extracted_services_company_id ON extracted_services(company_id);
CREATE INDEX idx_uploaded_files_company_id ON uploaded_files(company_id);
CREATE INDEX idx_file_tags_company_id ON file_tags(company_id);

-- ‚úÖ Hybrid Search indexes cho metadata filtering
CREATE INDEX idx_extracted_products_category ON extracted_products(category);
CREATE INDEX idx_extracted_products_sub_category ON extracted_products(sub_category);
CREATE INDEX idx_extracted_products_tags ON extracted_products USING GIN(tags);
CREATE INDEX idx_extracted_products_target_audience ON extracted_products USING GIN(target_audience);
CREATE INDEX idx_extracted_products_coverage_type ON extracted_products USING GIN(coverage_type);

CREATE INDEX idx_extracted_services_category ON extracted_services(category);
CREATE INDEX idx_extracted_services_sub_category ON extracted_services(sub_category);
CREATE INDEX idx_extracted_services_tags ON extracted_services USING GIN(tags);
CREATE INDEX idx_extracted_services_target_audience ON extracted_services USING GIN(target_audience);
CREATE INDEX idx_extracted_services_service_type ON extracted_services USING GIN(service_type);

-- ‚úÖ Qdrant integration indexes
CREATE INDEX idx_extracted_products_qdrant_point_id ON extracted_products(qdrant_point_id);
CREATE INDEX idx_extracted_services_qdrant_point_id ON extracted_services(qdrant_point_id);
```

---

## üîÑ Hybrid Search Strategy: AI Categorization + Vector Search + User Feedback

### Problem: Precision vs Recall Trade-off

- **Search (Precision-focused)**: T√¨m ra v√†i k·∫øt qu·∫£ **li√™n quan nh·∫•t** (v√≠ d·ª•: "tr√† n√†o t·ªët cho ng∆∞·ªùi m·∫•t ng·ªß?" -> tr·∫£ v·ªÅ tr√† hoa c√∫c)
- **Retrieval (Recall-focused)**: L·∫•y ra **t·∫•t c·∫£** c√°c m·ª•c thu·ªôc m·ªôt danh m·ª•c (v√≠ d·ª•: "li·ªát k√™ t·∫•t c·∫£ c√°c lo·∫°i tr√†" -> tr·∫£ v·ªÅ to√†n b·ªô 30 m√≥n tr√†)

### Solution: Hybrid Strategy v·ªõi AI Categorization + User Feedback Loop

#### 1. **AI Categorization at Extraction Time**

AI service s·∫Ω ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ t·ª± ƒë·ªông ph√¢n lo·∫°i products/services v·ªõi structured prompt:

```javascript
// ‚úÖ Enhanced AI Extraction Prompt Template
const extractionPrompt = `
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch s·∫£n ph·∫©m/d·ªãch v·ª•. H√£y tr√≠ch xu·∫•t th√¥ng tin v√† PH√ÇN LO·∫†I chi ti·∫øt theo format JSON sau:

IMPORTANT: Cho m·ªói product/service, h√£y t·∫°o:
1. category: Danh m·ª•c ch√≠nh (d√πng snake_case, ti·∫øng Vi·ªát kh√¥ng d·∫•u)
2. sub_category: Danh m·ª•c ph·ª• (chi ti·∫øt h∆°n)
3. tags: Array c√°c t·ª´ kh√≥a t√¨m ki·∫øm (5-8 tags)
4. target_audience: ƒê·ªëi t∆∞·ª£ng kh√°ch h√†ng m·ª•c ti√™u
5. coverage_type/service_type: Lo·∫°i b·∫£o hi·ªÉm/d·ªãch v·ª•

V√≠ d·ª• categorization cho ng√†nh b·∫£o hi·ªÉm:
- category: "bao_hiem_nhan_tho", "bao_hiem_suc_khoe", "chuong_trinh_uu_dai"
- sub_category: "bao_hiem_lien_ket", "b·ªánh_hi·ªÉm_ngh√®o", "vitality_rewards"
- tags: ["nhan_tho", "gia_dinh", "bao_ve_toan_dien", "uu_dai"]

Ph√¢n lo·∫°i d·ª±a tr√™n:
- N·ªôi dung m√¥ t·∫£ s·∫£n ph·∫©m
- ƒê·ªëi t∆∞·ª£ng kh√°ch h√†ng
- Lo·∫°i b·∫£o hi·ªÉm/d·ªãch v·ª•
- T√≠nh nƒÉng ƒë·∫∑c bi·ªát

${fileContent}

Tr·∫£ v·ªÅ JSON format v·ªõi ƒë·∫ßy ƒë·ªß categorization metadata.
`;
```

#### 2. **Enhanced Database Schema v·ªõi Qdrant Point IDs**

```sql
-- Remove chunking approach, use single point per product/service
ALTER TABLE extracted_products 
DROP COLUMN IF EXISTS qdrant_point_ids,
ADD COLUMN qdrant_point_id VARCHAR(255);  -- Single point ID

ALTER TABLE extracted_services 
DROP COLUMN IF EXISTS qdrant_point_ids,
ADD COLUMN qdrant_point_id VARCHAR(255);  -- Single point ID
```

#### 3. **Enhanced Callback Handler v·ªõi Individual Product/Service Storage + AI Categorization**

```javascript
// Enhanced AI Extraction Callback Handler v·ªõi Hybrid Search Strategy
app.post('/api/webhooks/ai/extraction-callback', webhookAuth, async (req, res) => {
  try {
    const { structured_data, extraction_metadata, ... } = req.body;
    
    if (status === 'completed') {
      // üîë STRATEGY: Store each product/service as SINGLE Qdrant point with rich metadata
      
      // Save products v·ªõi individual Qdrant storage + AI categorization
      if (structured_data.products && structured_data.products.length > 0) {
        for (let i = 0; i < structured_data.products.length; i++) {
          const product = structured_data.products[i];
          
          // 1. Create database record first ƒë·ªÉ get UUID
          const savedProduct = await db.extracted_products.create({
            job_id: job.id,
            company_id: company_id,
            name: product.name,
            type: product.type,
            description: product.description,
            coverage_period: product.coverage_period,
            age_range: product.age_range,
            coverage_area: product.coverage_area,
            premium: product.premium,
            terms_and_conditions: product.terms_and_conditions,
            // ‚úÖ Store AI categorization in database
            category: product.category,
            sub_category: product.sub_category,
            tags: JSON.stringify(product.tags || []),
            target_audience: JSON.stringify(product.target_audience || []),
            coverage_type: JSON.stringify(product.coverage_type || []),
            created_at: new Date()
          });
          
          // 2. Create SINGLE Qdrant point cho product n√†y v·ªõi rich metadata
          const productContent = `${product.name} - ${product.type}\n${product.description}\nPh√≠: ${product.premium}\nƒêi·ªÅu ki·ªán: ${product.terms_and_conditions}`;
          const pointId = `product_${savedProduct.id}`;
          
          // Generate embedding v√† store trong Qdrant v·ªõi comprehensive metadata
          const embedding = await generateEmbedding(productContent);
          
          await qdrant.upsert('multi_company_data', {
            points: [{
              id: pointId,
              vector: embedding,
              payload: {
                content: productContent,
                content_type: 'extracted_product',
                product_id: savedProduct.id, // Link to database UUID
                product_name: product.name,
                product_type: product.type,
                // ‚úÖ Rich metadata cho hybrid filtering
                category: product.category,
                sub_category: product.sub_category,
                tags: product.tags || [],
                target_audience: product.target_audience || [],
                coverage_type: product.coverage_type || [],
                // ‚úÖ Search optimization fields
                searchable_text: `${product.name} ${product.type} ${product.description} ${(product.tags || []).join(' ')}`,
                company_id: company_id,
                job_id: job.id,
                created_at: new Date().toISOString()
              }
            }]
          });
          
          // 3. Update database v·ªõi Qdrant point ID
          await savedProduct.update({
            qdrant_point_id: pointId
          });
          
          console.log(`‚úÖ Product ${savedProduct.id} stored as single Qdrant point: ${pointId}`);
          console.log(`   üìÇ Category: ${product.category}`);
          console.log(`   üè∑Ô∏è Tags: ${(product.tags || []).join(', ')}`);
        }
      }
      
      // Same strategy for services v·ªõi individual storage + AI categorization
      if (structured_data.services && structured_data.services.length > 0) {
        for (let i = 0; i < structured_data.services.length; i++) {
          const service = structured_data.services[i];
          
          // 1. Create database record first
          const savedService = await db.extracted_services.create({
            job_id: job.id,
            company_id: company_id,
            name: service.name,
            type: service.type,
            description: service.description,
            pricing: service.pricing,
            availability: service.availability,
            // ‚úÖ Store AI categorization in database
            category: service.category,
            sub_category: service.sub_category,
            tags: JSON.stringify(service.tags || []),
            target_audience: JSON.stringify(service.target_audience || []),
            service_type: JSON.stringify(service.service_type || []),
            created_at: new Date()
          });
          
          // 2. Create SINGLE Qdrant point cho service n√†y v·ªõi rich metadata
          const serviceContent = `${service.name} - ${service.type}\n${service.description}\nGi√°: ${service.pricing}\nC√≥ s·∫µn: ${service.availability}`;
          const pointId = `service_${savedService.id}`;
          
          const embedding = await generateEmbedding(serviceContent);
          
          await qdrant.upsert('multi_company_data', {
            points: [{
              id: pointId,
              vector: embedding,
              payload: {
                content: serviceContent,
                content_type: 'extracted_service',
                service_id: savedService.id, // Link to database UUID
                service_name: service.name,
                service_type_primary: service.type,
                // ‚úÖ Rich metadata cho hybrid filtering
                category: service.category,
                sub_category: service.sub_category,
                tags: service.tags || [],
                target_audience: service.target_audience || [],
                service_type: service.service_type || [],
                // ‚úÖ Search optimization fields
                searchable_text: `${service.name} ${service.type} ${service.description} ${(service.tags || []).join(' ')}`,
                company_id: company_id,
                job_id: job.id,
                created_at: new Date().toISOString()
              }
            }]
          });
          
          // 3. Update database v·ªõi Qdrant point ID
          await savedService.update({
            qdrant_point_id: pointId
          });
          
          console.log(`‚úÖ Service ${savedService.id} stored as single Qdrant point: ${pointId}`);
          console.log(`   üìÇ Category: ${service.category}`);
          console.log(`   üè∑Ô∏è Tags: ${(service.tags || []).join(', ')}`);
        }
      }
      
      // 4. Return success response
      res.status(200).json({
        success: true,
        message: "Extraction results saved successfully",
        saved_items: {
          products: structured_data.products ? structured_data.products.length : 0,
          services: structured_data.services ? structured_data.services.length : 0,
          total: results.total_items
        }
      });
      
    } else if (status === 'failed') {
      // ‚ùå AI Extraction th·∫•t b·∫°i  
      console.error(`‚ùå AI extraction ${task_id} failed: ${error}`);
      
      // Update database status
      await db.extraction_jobs.update(
        { task_id: task_id },
        {
          status: 'failed',
          completed_at: new Date(),
          error_message: error
        }
      );
      
      res.status(200).json({
        success: true,
        message: "Error status updated successfully"
      });
    }
  } catch (error) {
    console.error('‚ùå AI extraction webhook processing failed:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
});
```

---

## **‚úÖ STRATEGY 4: Hybrid Search Implementation v·ªõi Individual Product/Service Storage + AI Categorization**

```javascript
// üéØ HYBRID SEARCH: K·∫øt h·ª£p Metadata Filtering (category-based) v·ªõi Vector Search (similarity ranking)

// ============ HYBRID SEARCH: Category-based Product/Service Retrieval ============
app.post('/api/chat/hybrid-search/:company_id', async (req, res) => {
  try {
    const { company_id } = req.params;
    const { query, mode = 'hybrid', categories = [], tags = [], limit = 20 } = req.body;
    
    let searchResults = [];
    
    if (mode === 'category' || mode === 'hybrid') {
      // üîç STEP 1: Metadata Filtering ƒë·ªÉ get t·∫•t c·∫£ products/services trong categories
      const metadataFilter = {
        must: [
          { key: 'company_id', match: { value: company_id }},
          { key: 'content_type', match: { any: ['extracted_product', 'extracted_service'] }}
        ]
      };
      
      // Add category filter n·∫øu user specify categories
      if (categories.length > 0) {
        metadataFilter.must.push({
          key: 'category',
          match: { any: categories }
        });
      }
      
      // Add tag filter n·∫øu user specify tags
      if (tags.length > 0) {
        metadataFilter.must.push({
          key: 'tags',
          match: { any: tags }
        });
      }
      
      // Query v·ªõi metadata filtering only (no vector search yet)
      const metadataResults = await qdrant.scroll('multi_company_data', {
        filter: metadataFilter,
        limit: 100, // Get more results ƒë·ªÉ sau ƒë√≥ rank b·∫±ng vector search
        with_payload: true,
        with_vector: false
      });
      
      console.log(`üìÇ Metadata filtering found ${metadataResults.points.length} items`);
      
      if (mode === 'category') {
        // Pure category mode: return all found items without vector ranking
        searchResults = metadataResults.points.map(point => ({
          id: point.id,
          content: point.payload.content,
          score: 1.0, // No similarity score
          metadata: point.payload
        }));
      } else {
        // Hybrid mode: rank filtered results by vector similarity
        if (metadataResults.points.length > 0 && query) {
          const queryEmbedding = await generateEmbedding(query);
          
          // Get vectors for filtered points v√† calculate similarity
          const vectorResults = await qdrant.search('multi_company_data', {
            vector: queryEmbedding,
            filter: metadataFilter,
            limit: Math.min(limit, metadataResults.points.length),
            with_payload: true
          });
          
          searchResults = vectorResults.map(result => ({
            id: result.id,
            content: result.payload.content,
            score: result.score,
            metadata: result.payload
          }));
          
          console.log(`üéØ Hybrid search ranked ${searchResults.length} items by similarity`);
        } else {
          // Fallback to metadata results n·∫øu no query
          searchResults = metadataResults.points.slice(0, limit).map(point => ({
            id: point.id,
            content: point.payload.content,
            score: 1.0,
            metadata: point.payload
          }));
        }
      }
    } else if (mode === 'semantic') {
      // Pure semantic search
      if (query) {
        const queryEmbedding = await generateEmbedding(query);
        
        const vectorResults = await qdrant.search('multi_company_data', {
          vector: queryEmbedding,
          filter: {
            must: [
              { key: 'company_id', match: { value: company_id }},
              { key: 'content_type', match: { any: ['extracted_product', 'extracted_service'] }}
            ]
          },
          limit: limit,
          with_payload: true
        });
        
        searchResults = vectorResults.map(result => ({
          id: result.id,
          content: result.payload.content,
          score: result.score,
          metadata: result.payload
        }));
      }
    }
    
    // Group results by product/service ƒë·ªÉ avoid duplicates
    const groupedResults = {};
    searchResults.forEach(result => {
      const productId = result.metadata.product_id;
      const serviceId = result.metadata.service_id;
      const key = productId ? `product_${productId}` : `service_${serviceId}`;
      
      if (!groupedResults[key] || result.score > groupedResults[key].score) {
        groupedResults[key] = result;
      }
    });
    
    const finalResults = Object.values(groupedResults);
    
    res.json({
      success: true,
      mode: mode,
      total_found: finalResults.length,
      categories_used: categories,
      tags_used: tags,
      results: finalResults.map(result => ({
        content: result.content,
        score: result.score,
        metadata: {
          type: result.metadata.content_type,
          name: result.metadata.product_name || result.metadata.service_name,
          category: result.metadata.category,
          sub_category: result.metadata.sub_category,
          tags: result.metadata.tags,
          target_audience: result.metadata.target_audience
        }
      }))
    });
    
  } catch (error) {
    console.error('‚ùå Hybrid search error:', error);
    res.status(500).json({
      success: false,
      error: 'Hybrid search failed',
      details: error.message
    });
  }
});

// ============ CATEGORY MANAGEMENT: User Feedback Loop ============
app.post('/api/management/update-category/:company_id', async (req, res) => {
  try {
    const { company_id } = req.params;
    const { 
      item_type, // 'product' or 'service'
      item_id, 
      new_category, 
      new_sub_category, 
      new_tags = [], 
      new_target_audience = [] 
    } = req.body;
    
    // 1. Update database record
    const table = item_type === 'product' ? 'extracted_products' : 'extracted_services';
    const updateData = {
      category: new_category,
      sub_category: new_sub_category,
      tags: JSON.stringify(new_tags),
      target_audience: JSON.stringify(new_target_audience),
      updated_at: new Date()
    };
    
    const updatedRecord = await db[table].update(updateData, {
      where: { 
        id: item_id,
        company_id: company_id 
      },
      returning: true
    });
    
    if (updatedRecord[0] === 0) {
      return res.status(404).json({
        success: false,
        error: `${item_type} not found`
      });
    }
    
    // 2. Update corresponding Qdrant point v·ªõi new metadata
    const record = updatedRecord[1][0];
    const pointId = record.qdrant_point_id;
    
    if (pointId) {
      // Get current point data
      const currentPoint = await qdrant.retrieve('multi_company_data', [pointId]);
      
      if (currentPoint.length > 0) {
        const currentPayload = currentPoint[0].payload;
        
        // Update payload v·ªõi new categorization
        const updatedPayload = {
          ...currentPayload,
          category: new_category,
          sub_category: new_sub_category,
          tags: new_tags,
          target_audience: new_target_audience,
          searchable_text: `${currentPayload.product_name || currentPayload.service_name} ${currentPayload.product_type || currentPayload.service_type_primary} ${currentPayload.content} ${new_tags.join(' ')}`,
          updated_at: new Date().toISOString()
        };
        
        // Upsert v·ªõi updated payload (keep same vector)
        await qdrant.upsert('multi_company_data', {
          points: [{
            id: pointId,
            vector: currentPoint[0].vector,
            payload: updatedPayload
          }]
        });
        
        console.log(`‚úÖ Updated ${item_type} ${item_id} category: ${new_category} -> ${new_sub_category}`);
        console.log(`   üè∑Ô∏è New tags: ${new_tags.join(', ')}`);
      }
    }
    
    res.json({
      success: true,
      message: `${item_type} categorization updated`,
      updated_record: {
        id: item_id,
        category: new_category,
        sub_category: new_sub_category,
        tags: new_tags,
        target_audience: new_target_audience
      }
    });
    
  } catch (error) {
    console.error('‚ùå Category update error:', error);
    res.status(500).json({
      success: false,
      error: 'Category update failed',
      details: error.message
    });
  }
});

// ============ CATEGORY ANALYTICS: Understanding Distribution ============
app.get('/api/analytics/categories/:company_id', async (req, res) => {
  try {
    const { company_id } = req.params;
    
    // Aggregate categories from Qdrant ƒë·ªÉ get real-time distribution
    const allPoints = await qdrant.scroll('multi_company_data', {
      filter: {
        must: [
          { key: 'company_id', match: { value: company_id }},
          { key: 'content_type', match: { any: ['extracted_product', 'extracted_service'] }}
        ]
      },
      limit: 1000,
      with_payload: true,
      with_vector: false
    });
    
    const categoryStats = {};
    const tagStats = {};
    const typeStats = { products: 0, services: 0 };
    
    allPoints.points.forEach(point => {
      const payload = point.payload;
      
      // Count by type
      if (payload.content_type === 'extracted_product') {
        typeStats.products++;
      } else if (payload.content_type === 'extracted_service') {
        typeStats.services++;
      }
      
      // Count by category
      const category = payload.category || 'uncategorized';
      if (!categoryStats[category]) {
        categoryStats[category] = {
          count: 0,
          sub_categories: {}
        };
      }
      categoryStats[category].count++;
      
      // Count by sub_category
      const subCategory = payload.sub_category || 'other';
      if (!categoryStats[category].sub_categories[subCategory]) {
        categoryStats[category].sub_categories[subCategory] = 0;
      }
      categoryStats[category].sub_categories[subCategory]++;
      
      // Count by tags
      (payload.tags || []).forEach(tag => {
        if (!tagStats[tag]) {
          tagStats[tag] = 0;
        }
        tagStats[tag]++;
      });
    });
    
    res.json({
      success: true,
      total_items: allPoints.points.length,
      type_distribution: typeStats,
      category_distribution: categoryStats,
      top_tags: Object.entries(tagStats)
        .sort(([,a], [,b]) => b - a)
        .slice(0, 20)
        .map(([tag, count]) => ({ tag, count }))
    });
    
  } catch (error) {
    console.error('‚ùå Category analytics error:', error);
    res.status(500).json({
      success: false,
      error: 'Category analytics failed',
      details: error.message
    });
  }
});
```

#### 3. **CRUD Operations v·ªõi Individual Product/Service Management**

```javascript
// === UPDATE Product/Service (Individual Granular Control) ===
app.put('/api/products/:productId', async (req, res) => {
  try {
    const { productId } = req.params;
    const updates = req.body;
    
    // 1. Get existing product v·ªõi Qdrant point IDs
    const product = await db.extracted_products.findByPk(productId);
    if (!product) {
      return res.status(404).json({ error: 'Product not found' });
    }
    
    const qdrantPointIds = JSON.parse(product.qdrant_point_ids || '[]');
    
    // 2. Delete ALL old Qdrant points for this specific product
    if (qdrantPointIds.length > 0) {
      await qdrant.delete('multi_company_data', {
        points: qdrantPointIds
      });
      console.log(`üóëÔ∏è Deleted ${qdrantPointIds.length} old Qdrant points for product ${productId}`);
    }
    
    // 3. Update database record
    await product.update(updates);
    
    // 4. Create NEW Qdrant points v·ªõi updated content
    const updatedContent = `${updates.name || product.name} - ${updates.type || product.type}\n${updates.description || product.description}\nPh√≠: ${updates.premium || product.premium}\nƒêi·ªÅu ki·ªán: ${updates.terms_and_conditions || product.terms_and_conditions}`;
    
    const chunks = chunkContent(updatedContent, 2000);
    const newQdrantPointIds = [];
    
    for (let chunkIndex = 0; chunkIndex < chunks.length; chunkIndex++) {
      const pointId = `product_${productId}_chunk_${chunkIndex}`;
      newQdrantPointIds.push(pointId);
      
      const embedding = await generateEmbedding(chunks[chunkIndex]);
      
      await qdrant.upsert('multi_company_data', {
        points: [{
          id: pointId,
          vector: embedding,
          payload: {
            content: chunks[chunkIndex],
            content_type: 'extracted_product',
            product_id: productId,
            product_name: updates.name || product.name,
            product_type: updates.type || product.type,
            company_id: product.company_id,
            chunk_index: chunkIndex,
            total_chunks: chunks.length,
            updated_at: new Date().toISOString()
          }
        }]
      });
    }
    
    // 5. Update database v·ªõi new Qdrant point IDs
    await product.update({
      qdrant_point_ids: JSON.stringify(newQdrantPointIds)
    });
    
    res.json({
      success: true,
      message: 'Product updated successfully',
      product: product,
      qdrant_changes: {
        old_points_deleted: qdrantPointIds.length,
        new_points_created: newQdrantPointIds.length
      }
    });
    
  } catch (error) {
    console.error('Failed to update product:', error);
    res.status(500).json({ error: 'Failed to update product' });
  }
});

// === DELETE Product/Service (Individual Clean Removal) ===
app.delete('/api/products/:productId', async (req, res) => {
  try {
    const { productId } = req.params;
    
    // 1. Get product v·ªõi Qdrant point IDs
    const product = await db.extracted_products.findByPk(productId);
    if (!product) {
      return res.status(404).json({ error: 'Product not found' });
    }
    
    const qdrantPointIds = JSON.parse(product.qdrant_point_ids || '[]');
    
    // 2. Delete ALL Qdrant points for this specific product ONLY
    if (qdrantPointIds.length > 0) {
      await qdrant.delete('multi_company_data', {
        points: qdrantPointIds
      });
      console.log(`üóëÔ∏è Deleted ${qdrantPointIds.length} Qdrant points for product ${productId}`);
    }
    
    // 3. Delete t·ª´ database
    await product.destroy();
    
    res.json({
      success: true,
      message: 'Product deleted successfully',
      deleted_product: {
        id: productId,
        name: product.name,
        qdrant_points_deleted: qdrantPointIds.length
      }
    });
    
  } catch (error) {
    console.error('Failed to delete product:', error);
    res.status(500).json({ error: 'Failed to delete product' });
  }
});

// === PARTIAL UPDATE (ch·ªâ update specific fields) ===
app.patch('/api/products/:productId/fields', async (req, res) => {
  try {
    const { productId } = req.params;
    const { field, value } = req.body; // e.g., { field: 'premium', value: '2000 USD/year' }
    
    const product = await db.extracted_products.findByPk(productId);
    if (!product) {
      return res.status(404).json({ error: 'Product not found' });
    }
    
    // Validate field
    const allowedFields = ['name', 'type', 'description', 'premium', 'coverage_period', 'age_range', 'coverage_area', 'terms_and_conditions'];
    if (!allowedFields.includes(field)) {
      return res.status(400).json({ error: `Field '${field}' is not allowed for update` });
    }
    
    // Update specific field
    const updates = { [field]: value };
    await product.update(updates);
    
    // Re-create Qdrant points v·ªõi updated content (same as full update)
    const qdrantPointIds = JSON.parse(product.qdrant_point_ids || '[]');
    
    if (qdrantPointIds.length > 0) {
      await qdrant.delete('multi_company_data', { points: qdrantPointIds });
    }
    
    const updatedProduct = await db.extracted_products.findByPk(productId);
    const updatedContent = `${updatedProduct.name} - ${updatedProduct.type}\n${updatedProduct.description}\nPh√≠: ${updatedProduct.premium}\nƒêi·ªÅu ki·ªán: ${updatedProduct.terms_and_conditions}`;
    
    const chunks = chunkContent(updatedContent, 2000);
    const newQdrantPointIds = [];
    
    for (let chunkIndex = 0; chunkIndex < chunks.length; chunkIndex++) {
      const pointId = `product_${productId}_chunk_${chunkIndex}`;
      newQdrantPointIds.push(pointId);
      
      const embedding = await generateEmbedding(chunks[chunkIndex]);
      
      await qdrant.upsert('multi_company_data', {
        points: [{
          id: pointId,
          vector: embedding,
          payload: {
            content: chunks[chunkIndex],
            content_type: 'extracted_product',
            product_id: productId,
            product_name: updatedProduct.name,
            product_type: updatedProduct.type,
            company_id: updatedProduct.company_id,
            chunk_index: chunkIndex,
            total_chunks: chunks.length,
            updated_at: new Date().toISOString()
          }
        }]
      });
    }
    
    await updatedProduct.update({
      qdrant_point_ids: JSON.stringify(newQdrantPointIds)
    });
    
    res.json({
      success: true,
      message: `Field '${field}' updated successfully`,
      updated_field: field,
      new_value: value,
      qdrant_points_recreated: newQdrantPointIds.length
    });
    
  } catch (error) {
    console.error('Failed to update product field:', error);
    res.status(500).json({ error: 'Failed to update product field' });
  }
});

// === BULK DELETE (by company or job) v·ªõi Individual Tracking ===
app.delete('/api/companies/:companyId/extracted-data', async (req, res) => {
  try {
    const { companyId } = req.params;
    
    // 1. Get all products v√† services cho company
    const products = await db.extracted_products.findAll({
      where: { company_id: companyId }
    });
    const services = await db.extracted_services.findAll({
      where: { company_id: companyId }
    });
    
    // 2. Collect all Qdrant point IDs t·ª´ individual records
    const allQdrantPointIds = [];
    const productDetails = [];
    const serviceDetails = [];
    
    products.forEach(product => {
      const pointIds = JSON.parse(product.qdrant_point_ids || '[]');
      allQdrantPointIds.push(...pointIds);
      productDetails.push({
        id: product.id,
        name: product.name,
        points_count: pointIds.length
      });
    });
    
    services.forEach(service => {
      const pointIds = JSON.parse(service.qdrant_point_ids || '[]');
      allQdrantPointIds.push(...pointIds);
      serviceDetails.push({
        id: service.id,
        name: service.name,
        points_count: pointIds.length
      });
    });
    
    // 3. Bulk delete t·ª´ Qdrant
    if (allQdrantPointIds.length > 0) {
      await qdrant.delete('multi_company_data', {
        points: allQdrantPointIds
      });
      console.log(`üóëÔ∏è Bulk deleted ${allQdrantPointIds.length} Qdrant points for company ${companyId}`);
    }
    
    // 4. Bulk delete t·ª´ database
    await db.extracted_products.destroy({
      where: { company_id: companyId }
    });
    await db.extracted_services.destroy({
      where: { company_id: companyId }
    });
    
    res.json({
      success: true,
      message: 'All extracted data deleted successfully',
      deleted_summary: {
        products: {
          count: products.length,
          details: productDetails
        },
        services: {
          count: services.length,
          details: serviceDetails
        },
        total_qdrant_points_deleted: allQdrantPointIds.length
      }
    });
    
  } catch (error) {
    console.error('Failed to bulk delete extracted data:', error);
    res.status(500).json({ error: 'Failed to bulk delete extracted data' });
  }
});
```

#### 4. **Search v·ªõi Individual Product/Service Mapping**

```javascript
// === SEARCH v·ªõi Individual Product/Service Resolution ===
app.get('/api/companies/:companyId/search', async (req, res) => {
  try {
    const { companyId } = req.params;
    const { query, limit = 10, type = 'all' } = req.query; // type: 'products', 'services', 'all'
    
    // 1. Search Qdrant v·ªõi filters
    const filters = {
      must: [
        { key: 'company_id', match: { value: companyId } }
      ]
    };
    
    // Filter by content type if specified
    if (type === 'products') {
      filters.must.push({ key: 'content_type', match: { value: 'extracted_product' } });
    } else if (type === 'services') {
      filters.must.push({ key: 'content_type', match: { value: 'extracted_service' } });
    } else {
      filters.must.push({ 
        key: 'content_type', 
        match: { any: ['extracted_product', 'extracted_service'] } 
      });
    }
    
    const searchResults = await qdrant.search('multi_company_data', {
      vector: await generateEmbedding(query),
      filter: filters,
      limit: limit * 5, // Get more results ƒë·ªÉ aggregate by product/service
      with_payload: true,
      score_threshold: 0.7 // Only high-relevance results
    });
    
    // 2. Group search results by individual product/service IDs
    const productMatches = new Map(); // productId -> {chunks: [], maxScore: number}
    const serviceMatches = new Map(); // serviceId -> {chunks: [], maxScore: number}
    
    searchResults.forEach(result => {
      const payload = result.payload;
      const score = result.score;
      
      if (payload.content_type === 'extracted_product') {
        const productId = payload.product_id;
        if (!productMatches.has(productId)) {
          productMatches.set(productId, { chunks: [], maxScore: score });
        }
        productMatches.get(productId).chunks.push({
          content: payload.content,
          score: score,
          chunk_index: payload.chunk_index
        });
        // Update max score
        if (score > productMatches.get(productId).maxScore) {
          productMatches.get(productId).maxScore = score;
        }
      } else if (payload.content_type === 'extracted_service') {
        const serviceId = payload.service_id;
        if (!serviceMatches.has(serviceId)) {
          serviceMatches.set(serviceId, { chunks: [], maxScore: score });
        }
        serviceMatches.get(serviceId).chunks.push({
          content: payload.content,
          score: score,
          chunk_index: payload.chunk_index
        });
        if (score > serviceMatches.get(serviceId).maxScore) {
          serviceMatches.get(serviceId).maxScore = score;
        }
      }
    });
    
    // 3. Get complete database records cho matched products/services
    const productIds = Array.from(productMatches.keys());
    const serviceIds = Array.from(serviceMatches.keys());
    
    const products = await db.extracted_products.findAll({
      where: { id: productIds },
      include: [{
        model: db.extraction_jobs,
        as: 'job',
        attributes: ['task_id', 'file_name', 'submitted_at']
      }]
    });
    
    const services = await db.extracted_services.findAll({
      where: { id: serviceIds },
      include: [{
        model: db.extraction_jobs,
        as: 'job', 
        attributes: ['task_id', 'file_name', 'submitted_at']
      }]
    });
    
    // 4. Combine database records v·ªõi search scores v√† rank by relevance
    const productResults = products.map(product => ({
      ...product.toJSON(),
      search_info: {
        max_score: productMatches.get(product.id).maxScore,
        chunks_matched: productMatches.get(product.id).chunks.length,
        best_matching_chunks: productMatches.get(product.id).chunks
          .sort((a, b) => b.score - a.score)
          .slice(0, 2) // Top 2 matching chunks
      }
    })).sort((a, b) => b.search_info.max_score - a.search_info.max_score);
    
    const serviceResults = services.map(service => ({
      ...service.toJSON(),
      search_info: {
        max_score: serviceMatches.get(service.id).maxScore,
        chunks_matched: serviceMatches.get(service.id).chunks.length,
        best_matching_chunks: serviceMatches.get(service.id).chunks
          .sort((a, b) => b.score - a.score)
          .slice(0, 2)
      }
    })).sort((a, b) => b.search_info.max_score - a.search_info.max_score);
    
    // 5. Apply final limit v√† combine results
    const finalProducts = productResults.slice(0, type === 'services' ? 0 : Math.ceil(limit / 2));
    const finalServices = serviceResults.slice(0, type === 'products' ? 0 : Math.floor(limit / 2));
    
    res.json({
      success: true,
      search_query: query,
      search_type: type,
      results: {
        products: finalProducts,
        services: finalServices,
        total_products_found: productResults.length,
        total_services_found: serviceResults.length,
        returned_products: finalProducts.length,
        returned_services: finalServices.length
      },
      search_metadata: {
        qdrant_raw_matches: searchResults.length,
        unique_products_matched: productMatches.size,
        unique_services_matched: serviceMatches.size,
        score_threshold: 0.7,
        company_id: companyId
      }
    });
    
  } catch (error) {
    console.error('Search failed:', error);
    res.status(500).json({ error: 'Search failed' });
  }
});

// === ADVANCED SEARCH v·ªõi Filters ===
app.post('/api/companies/:companyId/search/advanced', async (req, res) => {
  try {
    const { companyId } = req.params;
    const {
      query,
      filters = {},
      limit = 10,
      include_chunks = false
    } = req.body;
    
    // Build dynamic Qdrant filters
    const qdrantFilters = {
      must: [
        { key: 'company_id', match: { value: companyId } }
      ]
    };
    
    // Add content type filter
    if (filters.content_type) {
      qdrantFilters.must.push({
        key: 'content_type',
        match: { value: filters.content_type }
      });
    }
    
    // Add product/service type filter (e.g., "B·∫£o hi·ªÉm s·ª©c kh·ªèe")
    if (filters.product_type) {
      qdrantFilters.must.push({
        key: 'product_type',
        match: { value: filters.product_type }
      });
    }
    
    if (filters.service_type) {
      qdrantFilters.must.push({
        key: 'service_type', 
        match: { value: filters.service_type }
      });
    }
    
    const searchResults = await qdrant.search('multi_company_data', {
      vector: await generateEmbedding(query),
      filter: qdrantFilters,
      limit: limit * 3,
      with_payload: true,
      score_threshold: 0.6
    });
    
    // Process results same as basic search but with filters applied
    // ... (same grouping and database mapping logic) ...
    
    res.json({
      success: true,
      advanced_search: true,
      filters_applied: filters,
      // ... results ...
    });
    
  } catch (error) {
    console.error('Advanced search failed:', error);
    res.status(500).json({ error: 'Advanced search failed' });
  }
});
```

#### 5. **Consistency Check Tools**

```javascript
// === VERIFY Qdrant-Database Consistency ===
app.get('/api/admin/verify-qdrant-consistency/:companyId', async (req, res) => {
  try {
    const { companyId } = req.params;
    
    // 1. Get all database records
    const products = await db.extracted_products.findAll({
      where: { company_id: companyId }
    });
    const services = await db.extracted_services.findAll({
      where: { company_id: companyId }
    });
    
    // 2. Check Qdrant points existence
    const inconsistencies = [];
    
    for (const product of products) {
      const qdrantPointIds = JSON.parse(product.qdrant_point_ids || '[]');
      
      for (const pointId of qdrantPointIds) {
        try {
          await qdrant.retrieve('multi_company_data', { ids: [pointId] });
        } catch (error) {
          inconsistencies.push({
            type: 'missing_qdrant_point',
            record_type: 'product',
            record_id: product.id,
            missing_point_id: pointId
          });
        }
      }
    }
    
    // Same check for services...
    
    res.json({
      success: true,
      company_id: companyId,
      total_products: products.length,
      total_services: services.length,
      inconsistencies: inconsistencies,
      is_consistent: inconsistencies.length === 0
    });
    
  } catch (error) {
    console.error('Consistency check failed:', error);
    res.status(500).json({ error: 'Consistency check failed' });
  }
});
```

---

## üîí Webhook Authentication

### Implement Webhook Authentication Middleware:

```javascript
// Webhook authentication middleware
const crypto = require('crypto');

function webhookAuth(req, res, next) {
  try {
    const signature = req.headers['x-webhook-signature'];
    const webhookSecret = process.env.WEBHOOK_SECRET;
    
    if (!signature || !webhookSecret) {
      return res.status(401).json({ error: 'Missing webhook signature or secret' });
    }
    
    // Extract signature from "sha256=..." format
    const receivedSignature = signature.replace('sha256=', '');
    
    // Calculate expected signature
    const payload = JSON.stringify(req.body, null, 0);
    const expectedSignature = crypto
      .createHmac('sha256', webhookSecret)
      .update(payload, 'utf8')
      .digest('hex');
    
    // Compare signatures securely
    if (!crypto.timingSafeEqual(
      Buffer.from(receivedSignature, 'hex'),
      Buffer.from(expectedSignature, 'hex')
    )) {
      return res.status(401).json({ error: 'Invalid webhook signature' });
    }
    
    next();
  } catch (error) {
    console.error('Webhook authentication failed:', error);
    return res.status(401).json({ error: 'Webhook authentication failed' });
  }
}

// Usage in routes
app.post('/api/webhooks/file-processed', webhookAuth, async (req, res) => {
  // Handler implementation...
});

app.post('/api/webhooks/ai/extraction-callback', webhookAuth, async (req, res) => {
  // Handler implementation...
});
```

---

## üîç Debugging & Testing

### Test Webhook Endpoints v·ªõi Full Data:

```bash
# Test AI extraction callback v·ªõi full structured data
curl -X POST https://api.agent8x.io.vn/api/webhooks/ai/extraction-callback \
  -H "Content-Type: application/json" \
  -H "X-Webhook-Signature: sha256=your_signature_here" \
  -d '{
    "task_id": "test-task-123",
    "company_id": "test-company",
    "status": "completed", 
    "processing_time": 15.5,
    "timestamp": "2025-07-27T07:30:00.123Z",
    "results": {
      "products_count": 2,
      "services_count": 1,
      "total_items": 3,
      "ai_provider": "gemini",
      "template_used": "InsuranceExtractionTemplate"
    },
    "raw_content": "Full original file content here...",
    "structured_data": {
      "products": [
        {
          "name": "Test Product",
          "type": "Insurance",
          "description": "Test description",
          "premium": "1000 USD/year"
        }
      ],
      "services": [
        {
          "name": "Test Service", 
          "type": "Support",
          "description": "Test service description"
        }
      ]
    }
  }'

# Test file upload callback v·ªõi raw content
curl -X POST https://api.agent8x.io.vn/api/webhooks/file-processed \
  -H "Content-Type: application/json" \
  -H "X-Webhook-Signature: sha256=your_signature_here" \
  -d '{
    "event": "file.uploaded",
    "companyId": "test-company",
    "data": {
      "fileId": "test-file-123",
      "status": "completed",
      "chunksCreated": 5,
      "processingTime": 3.2,
      "tags": ["test", "company-info"],
      "raw_content": "Complete file content here...",
      "file_metadata": {
        "original_name": "test_file.pdf",
        "file_size": 1024000,
        "file_type": "application/pdf"
      }
    },
    "timestamp": "2025-07-27T07:30:00.123Z"
  }'
```

### Verification Checklist:

#### ‚úÖ File Upload Workflow:
- [ ] Backend receives callback t·∫°i `/api/webhooks/file-processed`
- [ ] Callback c√≥ ƒë·∫ßy ƒë·ªß fields: `event`, `companyId`, `data`, `timestamp`
- [ ] `data.status` l√† `completed` ho·∫∑c `failed`  
- [ ] V·ªõi success: c√≥ `raw_content` (full file content), `chunksCreated`, `file_metadata`
- [ ] V·ªõi error: c√≥ `error` message chi ti·∫øt v√† partial `raw_content` n·∫øu c√≥
- [ ] Webhook signature verification works v·ªõi `X-Webhook-Signature`
- [ ] Database l∆∞u ƒë∆∞·ª£c complete file record v·ªõi raw content

#### ‚úÖ AI Extraction Workflow:
- [ ] Backend receives callback t·∫°i `/api/webhooks/ai/extraction-callback`
- [ ] Callback c√≥ ƒë·∫ßy ƒë·ªß fields: `task_id`, `company_id`, `status`, `timestamp`
- [ ] V·ªõi success: c√≥ `raw_content` (complete original text), `structured_data` (full products/services), `results`, `extraction_metadata`
- [ ] V·ªõi error: c√≥ `error` message chi ti·∫øt
- [ ] `structured_data.products[]` ch·ª©a t·∫•t c·∫£ product details (name, type, description, coverage_period, premium, v.v.)
- [ ] `structured_data.services[]` ch·ª©a t·∫•t c·∫£ service details (name, type, description, pricing, availability)
- [ ] Database l∆∞u ƒë∆∞·ª£c individual products v√† services t·ª´ structured_data
- [ ] Response time t·ª´ backend < 5 seconds

#### ‚úÖ Security & Authentication:
- [ ] Webhook signature verification ho·∫°t ƒë·ªông correctly
- [ ] `WEBHOOK_SECRET` ƒë∆∞·ª£c configured properly
- [ ] Timestamps ƒë∆∞·ª£c validate ƒë·ªÉ prevent replay attacks
- [ ] Error handling kh√¥ng expose sensitive information

#### ‚úÖ Database Integration:
- [ ] All required tables created (uploaded_files, extraction_jobs, extracted_products, extracted_services, file_tags)
- [ ] Raw content ƒë∆∞·ª£c stored completely cho both workflows
- [ ] Individual products/services ƒë∆∞·ª£c parsed v√† stored ƒë√∫ng c√°ch
- [ ] Company file counts ƒë∆∞·ª£c updated
- [ ] Tags ƒë∆∞·ª£c indexed properly for search

---

## üö® Troubleshooting

### Common Issues:

1. **Callback kh√¥ng nh·∫≠n ƒë∆∞·ª£c**:
   - Ki·ªÉm tra URL c√≥ accessible t·ª´ AI service kh√¥ng
   - Verify firewall/security groups
   - Check HTTP vs HTTPS

2. **Callback timeout**:
   - Backend ph·∫£i response trong < 30 seconds  
   - Return `200 OK` ngay l·∫≠p t·ª©c, process async n·∫øu c·∫ßn

3. **Callback format sai**:
   - Ensure Content-Type l√† `application/json`
   - Validate JSON payload structure

4. **Duplicate callbacks**:
   - AI service c√≥ th·ªÉ retry n·∫øu kh√¥ng nh·∫≠n ƒë∆∞·ª£c 200 OK
   - Backend c·∫ßn handle idempotency v·ªõi `task_id` ho·∫∑c `fileId`

---

## üìù Summary

**ƒê√£ implement ƒë·∫ßy ƒë·ªß c·∫£ 2 lo·∫°i callback:**

1. ‚úÖ **File Upload Callback** (`/api/webhooks/file-processed`)
   - Raw content processing notifications
   - Success/error status v·ªõi metadata

2. ‚úÖ **AI Extraction Callback** (`/api/webhooks/ai/extraction-callback`) 
   - Structured data extraction notifications
   - Products/services count v√† AI metadata

**Backend c·∫ßn implement 2 webhook endpoints t∆∞∆°ng ·ª©ng ƒë·ªÉ nh·∫≠n notifications v√† update database status accordingly.**

**Next Steps:**
1. Backend implement 2 webhook handlers theo examples tr√™n
2. Test v·ªõi curl commands ƒë·ªÉ verify
3. Update frontend ƒë·ªÉ show real-time status updates
