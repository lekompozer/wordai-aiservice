# AI-RAG System Architecture Documentation
# T√†i li·ªáu Ki·∫øn tr√∫c H·ªá th·ªëng AI-RAG

Phi√™n b·∫£n: 3.0 | Ng√†y c·∫≠p nh·∫≠t: July 22, 2025

---

## üèóÔ∏è **T·ªïng quan Ki·∫øn tr√∫c (Architecture Overview)**

H·ªá th·ªëng AI-RAG ƒë∆∞·ª£c thi·∫øt k·∫ø theo ki·∫øn tr√∫c microservices v·ªõi 4 th√†nh ph·∫ßn ch√≠nh:

1. **Unified AI Service** - D·ªãch v·ª• AI t·∫≠p trung cho embedding (768 dimensions)
2. **Multi-Tenant Qdrant Service** - Qu·∫£n l√Ω d·ªØ li·ªáu vector trong single collection  
3. **Redis Queue Manager** - X·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô tasks v√† document processing
4. **Data Processing Pipeline** - X·ª≠ l√Ω v√† upload d·ªØ li·ªáu qua queue system

```mermaid
graph TB
    A[Client Request] --> B[API Gateway]
    B --> C[Admin Service]
    C --> D[AI Service - Unified Model]
    C --> E[Qdrant Service - Single Collection]
    C --> F[Queue Manager]
    D --> G[paraphrase-multilingual-mpnet-base-v2]
    E --> H[multi_company_data Collection]
    F --> I[Redis Queue]
    J[File Upload] --> K[Document Processor]
    K --> F
    F --> L[Workers Pool]
    L --> D
    L --> E
```

---

## üß† **1. Unified AI Service (ai_service.py)**

### **M·ª•c ƒë√≠ch:**
- T·∫≠p trung h√≥a vi·ªác t·∫°o embedding cho to√†n b·ªô h·ªá th·ªëng
- S·ª≠ d·ª•ng model `paraphrase-multilingual-mpnet-base-v2` (768 dimensions)
- H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ (Vi·ªát, Anh, Trung, Nh·∫≠t, H√†n, v.v.)

### **Th√†nh ph·∫ßn ch√≠nh:**

#### **UnifiedAIService Class:**
```python
class UnifiedAIService:
    def __init__(self):
        self.embedder = SentenceTransformer("paraphrase-multilingual-mpnet-base-v2")
        self.vector_size = 768
    
    async def generate_embedding(self, text: str) -> List[float]
    async def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]
    async def calculate_similarity(self, text1: str, text2: str) -> float
    async def health_check(self) -> Dict[str, Any]
```

#### **C√°c t√≠nh nƒÉng:**
- ‚úÖ **Single Text Embedding**: T·∫°o embedding cho 1 vƒÉn b·∫£n
- ‚úÖ **Batch Processing**: X·ª≠ l√Ω nhi·ªÅu vƒÉn b·∫£n c√πng l√∫c
- ‚úÖ **Similarity Calculation**: T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a
- ‚úÖ **Health Check**: Ki·ªÉm tra tr·∫°ng th√°i ho·∫°t ƒë·ªông
- ‚úÖ **Error Handling**: X·ª≠ l√Ω l·ªói to√†n di·ªán

### **C·∫•u h√¨nh:**
```bash
# development.env
EMBEDDING_MODEL=paraphrase-multilingual-mpnet-base-v2
VECTOR_SIZE=768
```

---

## üóÑÔ∏è **2. Multi-Tenant Qdrant Service (qdrant_company_service.py)**

### **M·ª•c ƒë√≠ch:**
- **SINGLE COLLECTION ARCHITECTURE**: S·ª≠ d·ª•ng 1 collection duy nh·∫•t `multi_company_data` cho t·∫•t c·∫£ c√¥ng ty
- **Multi-Tenant Filtering**: Ph√¢n bi·ªát d·ªØ li·ªáu c√¥ng ty qua `company_id` filter
- **Qdrant Free Plan Optimization**: T·ªëi ∆∞u cho gi·ªõi h·∫°n 1 collection c·ªßa Qdrant free plan
- Th·ª±c hi·ªán t√¨m ki·∫øm lai (Hybrid Search) v·ªõi filter metadata n√¢ng cao

### **Ki·∫øn tr√∫c Single Collection:**

#### **A. Unified Collection Management:**
```python
class QdrantCompanyDataService:
    def __init__(self):
        # QUAN TR·ªåNG: Ch·ªâ s·ª≠ d·ª•ng 1 collection cho t·∫•t c·∫£ c√¥ng ty
        self.unified_collection_name = "multi_company_data"
        
async def initialize_company_collection(company_config: CompanyConfig) -> str:
    # 1. Lu√¥n tr·∫£ v·ªÅ unified collection name
    # 2. T·∫°o collection n·∫øu ch∆∞a t·ªìn t·∫°i v·ªõi vector size 768
    # 3. T·∫°o payload indexes cho multi-tenant filtering
    # 4. Cache company info trong self.company_collections
    return "multi_company_data"
```

**Single Collection Benefits:**
- ‚úÖ **Free Plan Compatible**: Ph√π h·ª£p v·ªõi gi·ªõi h·∫°n 1 collection c·ªßa Qdrant free
- ‚úÖ **Cost Effective**: Kh√¥ng c·∫ßn multiple collections
- ‚úÖ **Unified Management**: Qu·∫£n l√Ω t·∫≠p trung d·ªÖ d√†ng
- ‚úÖ **Cross-Company Search**: C√≥ th·ªÉ search cross-company n·∫øu c·∫ßn

**Multi-Tenant Payload Indexes:**
- `company_id`: **keyword index** (PRIMARY FILTER)
- `industry`: keyword index  
- `data_type`: keyword index (PRODUCTS, SERVICES, FAQ, etc.)
- `language`: keyword index (vi, en, auto_detect)
- `file_id`: keyword index
- `created_at`: datetime index

#### **B. Multi-Tenant Data Storage:**
```python
async def add_document_chunks(chunks: List[QdrantDocumentChunk]) -> Dict:
    # 1. Generate embeddings using Unified AI Service
    # 2. Create PointStruct v·ªõi company_id trong payload
    # 3. Upsert to unified collection "multi_company_data"
```

**Point Structure in Unified Collection:**
```json
{
  "id": "company1_chunk_123",
  "vector": [768-dimensional embedding],
  "payload": {
    "company_id": "golden-dragon-test",  // PRIMARY FILTER
    "data_type": "PRODUCTS",
    "language": "vi",
    "content_for_embedding": "Optimized text for AI",
    "structured_data": {"name": "Ph·ªü B√≤", "price": 85000},
    "file_id": "file_123",
    "industry": "restaurant",
    "created_at": "2025-07-22T10:00:00Z"
  }
}
```

#### **C. Multi-Tenant Hybrid Search:**
```python
async def search_company_data(
    company_id: str,
    query: str,
    data_types: Optional[List[IndustryDataType]] = None,
    language: Language = Language.VIETNAMESE
) -> List[Dict]:
    # 1. Generate query embedding v·ªõi Unified AI Service
    # 2. Build COMPANY-SPECIFIC filter conditions
    # 3. Execute vector search tr√™n unified collection
    # 4. Return filtered results cho company n√†y
```

**Enhanced Multi-Tenant Filter Strategy:**
- **MUST conditions** (b·∫Øt bu·ªôc):
  - `company_id` = current company (**ISOLATION KEY**)
  - `industry` = company industry
  - `language` = detected/specified language
  
- **SHOULD conditions** (∆∞u ti√™n):
  - `data_type` IN [PRODUCTS, SERVICES, FAQ]

**Multi-Tenant Search Flow:**
```mermaid
sequenceDiagram
    participant U as User Query (Company A)
    participant Q as Qdrant Service  
    participant A as AI Service
    participant QD as Unified Collection
    
    U->>Q: search_company_data("ph·ªü b√≤", company_id="A")
    Q->>A: generate_embedding("ph·ªü b√≤")
    A-->>Q: [embedding_vector]
    Q->>QD: vector_search + company_id="A" filter
    QD-->>Q: company_A_results_only
    Q-->>U: filtered_results
```

#### **D. Multi-Tenant Data Management:**
```python
async def delete_company_data(company_id: str, file_ids: List[str] = None):
    # Delete data cho company c·ª• th·ªÉ t·ª´ unified collection
    filter_condition = Filter(
        must=[
            FieldCondition(key="company_id", match=MatchValue(value=company_id))
        ]
    )
    
async def get_company_data_stats(company_id: str) -> CompanyDataStats:
    # Get statistics cho company c·ª• th·ªÉ t·ª´ unified collection
    filter_condition = Filter(
        must=[
            FieldCondition(key="company_id", match=MatchValue(value=company_id))
        ]
    )
```

---

## üìÅ **3. File Upload & Processing Flow**

### **A. File Upload Process:**

#### **Step 1: File Upload API**
```python
POST /api/admin/companies/{company_id}/files/upload
{
    "r2_url": "https://static.agent8x.io.vn/...",
    "data_type": "document|products|services",
    "industry": "restaurant",
    "metadata": {...},
    "upload_to_qdrant": true
}
```

#### **Step 2: Document Processing**
```python
# src/workers/document_processor.py
class AIDocumentProcessor:
    def __init__(self):
        self.embedder = SentenceTransformer("paraphrase-multilingual-mpnet-base-v2")
    
    async def process_file():
        # 1. Download from R2
        # 2. Extract text content
        # 3. Create semantic chunks
        # 4. Generate embeddings
        # 5. Upload to Qdrant
```

#### **Step 3: Chunk Creation**
```python
# Chunking Strategy:
- Company Info: 1 chunk cho to√†n b·ªô th√¥ng tin
- Documents: Semantic chunking theo paragraph
- Products/Services: 1 chunk per item
- Images: 1 chunk v·ªõi description
```

### **B. Content for Embedding Optimization:**

#### **C·∫•u tr√∫c QdrantDocumentChunk:**
```python
@dataclass
class QdrantDocumentChunk:
    chunk_id: str
    company_id: str
    content: str  # Raw content
    content_for_embedding: str  # Optimized for AI
    structured_data: Dict  # JSON data
    data_type: IndustryDataType
    language: Language
    # ... other fields
```

#### **Content Optimization Examples:**
- **Products**: "T√™n s·∫£n ph·∫©m: Ph·ªü B√≤. M√¥ t·∫£: N∆∞·ªõc d√πng ƒë·∫≠m ƒë√†. Gi√°: 85,000 VND."
- **Services**: "D·ªãch v·ª•: Giao h√†ng t·∫≠n n∆°i. Mi·ªÖn ph√≠ trong b√°n k√≠nh 5km."
- **Company Info**: "Nh√† h√†ng Golden Dragon chuy√™n ·∫©m th·ª±c Vi·ªát t·∫°i 123 Nguy·ªÖn Hu·ªá..."

---

## üîç **4. Search & Retrieval Flow**

### **A. User Query Processing:**

```mermaid
sequenceDiagram
    participant U as User
    participant C as Chat Service
    participant Q as Qdrant Service
    participant A as AI Service
    participant D as Deepseek AI
    
    U->>C: "Qu√°n c√≥ ph·ªü kh√¥ng?"
    C->>Q: search_company_data(query, filters)
    Q->>A: generate_embedding(query)
    A-->>Q: query_vector
    Q->>Q: hybrid_search(vector + filters)
    Q-->>C: relevant_chunks
    C->>C: build_context_prompt
    C->>D: chat_completion(prompt + context)
    D-->>C: ai_response
    C-->>U: "C√≥ ·∫°, qu√°n c√≥ Ph·ªü B√≤ gi√° 85,000ƒë..."
```

### **B. Context Building:**
```python
def build_rag_context(search_results: List[Dict]) -> str:
    context_parts = []
    for result in search_results:
        # Use content_for_embedding for optimal AI reading
        context_parts.append(result["content_for_rag"])
    
    return "\n".join(context_parts)
```

### **C. Final Prompt Structure:**
```
B·∫°n l√† tr·ª£ l√Ω c·ªßa {company_name}. D·ª±a v√†o th√¥ng tin sau:

--- NG·ªÆ C·∫¢NH ---
T√™n s·∫£n ph·∫©m: Ph·ªü B√≤. M√¥ t·∫£: N∆∞·ªõc d√πng ƒë·∫≠m ƒë√†. Gi√°: 85,000 VND.
D·ªãch v·ª•: Giao h√†ng t·∫≠n n∆°i. Mi·ªÖn ph√≠ trong b√°n k√≠nh 5km.
--- H·∫æT NG·ªÆ C·∫¢NH ---

C√¢u h·ªèi: "Qu√°n c√≥ ph·ªü kh√¥ng?"
```

---

## ‚öôÔ∏è **5. Configuration & Deployment**

### **A. Environment Variables:**
```bash
# AI Configuration
EMBEDDING_MODEL=paraphrase-multilingual-mpnet-base-v2
VECTOR_SIZE=768

# Qdrant Configuration
QDRANT_URL=https://your-qdrant-cloud-url
QDRANT_API_KEY=your-api-key

# AI Providers
DEEPSEEK_API_KEY=your-deepseek-key
CHATGPT_API_KEY=your-openai-key
DEFAULT_AI_PROVIDER=deepseek
```

### **B. Service Dependencies:**
```python
# Service Initialization Order:
1. UnifiedAIService (ai_service.py)
2. QdrantCompanyDataService (qdrant_company_service.py)  
3. DocumentProcessor (document_processor.py)
4. API Routes & Chat Services
```

### **C. Performance Optimizations:**
- ‚úÖ **Singleton Pattern**: AI Service instance ƒë∆∞·ª£c cache
- ‚úÖ **Batch Processing**: Multiple embeddings c√πng l√∫c
- ‚úÖ **Collection Caching**: Company collections ƒë∆∞·ª£c cache
- ‚úÖ **Async Processing**: Non-blocking operations
- ‚úÖ **Index Optimization**: Payload fields ƒë∆∞·ª£c index

---

## üêõ **6. Debugging Guide**

### **A. Common Issues & Solutions:**

#### **Vector Size Mismatch:**
```bash
# Error: Expected 768 but got 384
# Solution: Check EMBEDDING_MODEL and VECTOR_SIZE config
```

#### **Embedding Generation Fails:**
```python
# Check AI Service health:
ai_service = get_ai_service()
health = await ai_service.health_check()
print(health)
```

#### **Search Returns No Results:**
```python
# Debug search filters:
1. Check company_id exists in collection
2. Verify data_type values
3. Test language filtering
4. Check score_threshold (default 0.7)
```

### **B. Logging & Monitoring:**
```python
# Enable debug logging:
import logging
logging.getLogger("sentence_transformers").setLevel(logging.DEBUG)
```

### **C. Collection Inspection:**
```python
# Get collection info:
collection_info = qdrant_client.get_collection("restaurant_golden_dragon")
print(f"Points: {collection_info.points_count}")

# Browse points:
points = qdrant_client.scroll("restaurant_golden_dragon", limit=10)
```

---

## üìä **7. Performance Metrics**

### **A. Expected Performance:**
- **Embedding Generation**: ~50ms per text
- **Batch Embedding**: ~200ms for 10 texts
- **Vector Search**: ~10-50ms depending on collection size
- **End-to-end Query**: ~300-500ms

### **B. Scalability:**
- **Collections**: Unlimited (one per company)
- **Points per Collection**: 10M+ (Qdrant limitation)
- **Concurrent Requests**: Limited by server resources
- **Languages**: 15+ supported by the model

---

## üîÑ **8. Testing & Validation**

### **A. Unit Tests:**
```bash
# Test AI Service:
python -m pytest tests/test_ai_service.py

# Test Qdrant Service:
python -m pytest tests/test_qdrant_service.py

# Integration Test:
python tests/test_complete_admin_workflow.py
```

### **B. Manual Testing:**
```bash
# Start server:
python serve.py

# Run workflow test:
cd tests && python test_complete_admin_workflow.py
```

---

**L∆∞u √Ω quan tr·ªçng:** T√†i li·ªáu n√†y c·∫ßn ƒë∆∞·ª£c c·∫≠p nh·∫≠t khi c√≥ thay ƒë·ªïi v·ªÅ ki·∫øn tr√∫c ho·∫∑c c·∫•u h√¨nh h·ªá th·ªëng.
