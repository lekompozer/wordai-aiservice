# Ph√¢n T√≠ch Chi Ti·∫øt QdrantCompanyDataService
# Detailed Analysis of QdrantCompanyDataService for Company Context CRUD

## üèóÔ∏è Ki·∫øn Tr√∫c T·ªïng Quan (Overall Architecture)

`QdrantCompanyDataService` ƒë∆∞·ª£c thi·∫øt k·∫ø theo m√¥ h√¨nh **Multi-tenant** trong m·ªôt **Unified Collection** ƒë·ªÉ t·ªëi ∆∞u cho Qdrant Free Plan. Thay v√¨ t·∫°o collection ri√™ng cho m·ªói c√¥ng ty, t·∫•t c·∫£ d·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u trong collection `multi_company_data` v√† ph√¢n bi·ªát b·∫±ng `company_id`.

### C·∫•u Tr√∫c D·ªØ Li·ªáu (Data Structure)
```python
# Point Structure in Qdrant
{
    "id": "chunk_id",  # UUID unique
    "vector": [0.1, 0.2, ...],  # 768-dimension embedding
    "payload": {
        "company_id": "abc_insurance_001",  # PRIMARY FILTER
        "file_id": "company_context",
        "content": "Raw content text",
        "content_for_embedding": "Optimized text for embedding",
        "data_type": "company_info",  # IndustryDataType enum
        "structured_data": {...},  # Additional metadata
        "language": "vietnamese",
        "industry": "insurance",
        "location": "vietnam",
        "created_at": "2025-07-31T...",
        "updated_at": "2025-07-31T..."
    }
}
```

---

## üìã Ph√¢n T√≠ch T·ª´ng H√†m CRUD

### 1. **Initialization Functions** (Kh·ªüi T·∫°o)

#### `__init__()`
- **M·ª•c ƒë√≠ch**: Kh·ªüi t·∫°o k·∫øt n·ªëi Qdrant v√† AI service
- **Tham s·ªë**: `qdrant_url`, `qdrant_api_key` cho cloud ho·∫∑c `host/port` cho local
- **Quan tr·ªçng**: 
  - S·ª≠ d·ª•ng `unified_collection_name = "multi_company_data"`
  - Cache company metadata trong `self.company_collections`

#### `initialize_company_collection(company_config: CompanyConfig)`
- **M·ª•c ƒë√≠ch**: Kh·ªüi t·∫°o collection cho company m·ªõi
- **Ho·∫°t ƒë·ªông**:
  1. Ki·ªÉm tra collection `multi_company_data` c√≥ t·ªìn t·∫°i ch∆∞a
  2. T·∫°o collection v·ªõi `VectorParams(size=768, distance=COSINE)` n·∫øu ch∆∞a c√≥
  3. T·∫°o payload indexes cho filtering hi·ªáu qu·∫£
  4. Cache company info v√†o memory

```python
# Usage for Company Context Setup
await qdrant_service.initialize_company_collection(CompanyConfig(
    company_id="abc_insurance_001",
    industry=Industry.INSURANCE,
    company_name="ABC Insurance"
))
```

#### `ensure_unified_collection_exists()`
- **M·ª•c ƒë√≠ch**: ƒê·∫£m b·∫£o collection t·ªìn t·∫°i (phi√™n b·∫£n ƒë∆°n gi·∫£n)
- **S·ª≠ d·ª•ng**: Khi c·∫ßn ƒë·∫£m b·∫£o collection c√≥ s·∫µn tr∆∞·ªõc khi thao t√°c

---

### 2. **CREATE Operations** (T·∫°o M·ªõi)

#### `add_document_chunks(chunks: List[QdrantDocumentChunk], company_id: str)`
- **M·ª•c ƒë√≠ch**: Th√™m company context chunks v√†o Qdrant
- **Ho·∫°t ƒë·ªông**:
  1. Auto-ensure collection exists
  2. Generate embeddings cho t·ª´ng chunk
  3. Convert th√†nh PointStruct format
  4. Batch upsert v√†o Qdrant

```python
# Usage for Company Context Upload
chunks = [
    QdrantDocumentChunk(
        chunk_id=str(uuid.uuid4()),
        company_id="abc_insurance_001",
        file_id="company_context",
        content="Company basic information...",
        content_for_embedding="Optimized content for search...",
        content_type=IndustryDataType.COMPANY_INFO,
        language=Language.VIETNAMESE,
        industry=Industry.INSURANCE,
        structured_data={
            "section": "basic_info",
            "company_name": "ABC Insurance",
            "products": ["life_insurance", "health_insurance"]
        }
    )
]

result = await qdrant_service.add_document_chunks(chunks, "abc_insurance_001")
```

**ƒê·∫∑c ƒëi·ªÉm quan tr·ªçng**:
- S·ª≠ d·ª•ng `content_for_embedding` ƒë·ªÉ t·∫°o vector (t·ªëi ∆∞u cho t√¨m ki·∫øm)
- `data_type` thay v√¨ `content_type` trong payload
- Batch processing cho hi·ªáu su·∫•t cao

---

### 3. **READ Operations** (ƒê·ªçc/T√¨m Ki·∫øm)

#### `search_company_data(company_id, query, industry, data_types, language, limit, score_threshold)`
- **M·ª•c ƒë√≠ch**: T√¨m ki·∫øm semantic trong d·ªØ li·ªáu company context
- **Ho·∫°t ƒë·ªông**:
  1. Generate embedding cho query
  2. X√¢y d·ª±ng filter v·ªõi `must` v√† `should` conditions
  3. Th·ª±c hi·ªán vector search v·ªõi filtering
  4. Format k·∫øt qu·∫£ cho AI consumption

```python
# Usage for Company Context Search
results = await qdrant_service.search_company_data(
    company_id="abc_insurance_001",
    query="b·∫£o hi·ªÉm s·ª©c kh·ªèe cho gia ƒë√¨nh",
    industry=Industry.INSURANCE,
    data_types=[IndustryDataType.COMPANY_INFO, IndustryDataType.PRODUCTS],
    language=Language.VIETNAMESE,
    limit=5,
    score_threshold=0.7
)
```

**Filter Logic**:
- **MUST**: `company_id`, `industry` (b·∫Øt bu·ªôc)
- **SHOULD**: `data_types` (∆∞u ti√™n nh∆∞ng kh√¥ng b·∫Øt bu·ªôc)
- **OPTIONAL**: `language` (n·∫øu kh√¥ng ph·∫£i AUTO_DETECT)

#### `get_company_data_stats(company_id: str)`
- **M·ª•c ƒë√≠ch**: L·∫•y th·ªëng k√™ d·ªØ li·ªáu company
- **Tr·∫£ v·ªÅ**: `CompanyDataStats` v·ªõi s·ªë l∆∞·ª£ng chunks theo data_type

---

### 4. **UPDATE Operations** (C·∫≠p Nh·∫≠t)

#### `update_document_chunk(chunk: QdrantDocumentChunk, company_id: str)`
- **M·ª•c ƒë√≠ch**: C·∫≠p nh·∫≠t m·ªôt chunk c·ª• th·ªÉ
- **Ho·∫°t ƒë·ªông**:
  1. Generate embedding m·ªõi cho content
  2. Upsert point v·ªõi same ID
  3. Update `updated_at` timestamp

```python
# Usage for Company Context Update
updated_chunk = QdrantDocumentChunk(
    chunk_id="existing_chunk_id",
    company_id="abc_insurance_001",
    content="Updated company information...",
    # ... other fields
)

result = await qdrant_service.update_document_chunk(updated_chunk, "abc_insurance_001")
```

#### `upsert_points(collection_name: str, points: List[Dict])`
- **M·ª•c ƒë√≠ch**: Raw upsert operation cho batch updates
- **S·ª≠ d·ª•ng**: Khi c·∫ßn update nhi·ªÅu points c√πng l√∫c

---

### 5. **DELETE Operations** (X√≥a)

#### `delete_company_data(company_id: str, file_ids: Optional[List[str]])`
- **M·ª•c ƒë√≠ch**: X√≥a d·ªØ li·ªáu company theo file ho·∫∑c to√†n b·ªô
- **Ho·∫°t ƒë·ªông**:
  - N·∫øu c√≥ `file_ids`: X√≥a specific files
  - N·∫øu kh√¥ng: X√≥a t·∫•t c·∫£ d·ªØ li·ªáu company

```python
# Delete specific files
result = await qdrant_service.delete_company_data(
    company_id="abc_insurance_001",
    file_ids=["company_context", "old_policies"]
)

# Delete all company data
result = await qdrant_service.delete_company_data("abc_insurance_001")
```

#### `delete_points(collection_name: str, point_ids: List[str])`
- **M·ª•c ƒë√≠ch**: X√≥a points c·ª• th·ªÉ theo IDs
- **S·ª≠ d·ª•ng**: Cleanup operations

---

### 6. **Utility Functions** (H√†m Ti·ªán √çch)

#### `scroll_points(collection_name, scroll_filter, limit, offset)`
- **M·ª•c ƒë√≠ch**: Duy·ªát qua large datasets
- **S·ª≠ d·ª•ng**: Export, statistics, bulk operations

#### `_generate_embedding(text: str)`
- **M·ª•c ƒë√≠ch**: T·∫°o embedding vector cho text
- **S·ª≠ d·ª•ng**: Internal function cho t·∫•t c·∫£ operations c·∫ßn embedding

---

## üéØ ·ª®ng D·ª•ng Cho Company Context CRUD

### **Workflow Upload Company Context**

```python
# 1. Initialize company collection
await qdrant_service.initialize_company_collection(company_config)

# 2. Prepare company context chunks
basic_info_chunk = QdrantDocumentChunk(
    chunk_id=str(uuid.uuid4()),
    company_id=company_id,
    file_id="company_context",
    content=formatted_basic_info,
    content_for_embedding=optimized_content,
    content_type=IndustryDataType.COMPANY_INFO,
    language=Language.VIETNAMESE,
    industry=company_config.industry,
    structured_data={
        "section": "basic_info",
        "company_name": basic_info.company_name,
        "introduction": basic_info.introduction
    }
)

faq_chunks = [...]  # Multiple FAQ chunks
scenario_chunks = [...]  # Multiple scenario chunks

# 3. Batch upload all chunks
all_chunks = [basic_info_chunk] + faq_chunks + scenario_chunks
result = await qdrant_service.add_document_chunks(all_chunks, company_id)

# 4. Verify upload
stats = await qdrant_service.get_company_data_stats(company_id)
print(f"Uploaded {stats.total_chunks} chunks")
```

### **Integration v·ªõi CompanyContextService**

```python
# In CompanyContextService._index_context_to_qdrant()
async def _index_context_to_qdrant(self, company_id: str):
    context = await self._get_or_create_context(company_id)
    formatted_context = self._format_context_to_string(context)
    
    if not formatted_context.strip():
        return
    
    # Use QdrantCompanyDataService
    qdrant_service = await self._get_qdrant_service()
    
    context_chunk = QdrantDocumentChunk(
        chunk_id=str(uuid.uuid4()),
        company_id=company_id,
        file_id="company_context",
        content=formatted_context,
        content_for_embedding=formatted_context,
        content_type=IndustryDataType.COMPANY_INFO,
        language=Language.VIETNAMESE,
        industry=Industry.OTHER,  # Or detect from company config
    )
    
    await qdrant_service.add_document_chunks([context_chunk], company_id)
```

---

## üîß Best Practices cho Company Context

### **1. Chunk Strategy**
- **Basic Info**: 1 chunk to√†n b·ªô th√¥ng tin company
- **FAQs**: 1 chunk per FAQ ho·∫∑c group theo ch·ªß ƒë·ªÅ
- **Scenarios**: 1 chunk per scenario v·ªõi structured steps

### **2. Metadata Design**
```python
{
    "section": "basic_info|faq|scenario",
    "faq_category": "products|services|support",
    "scenario_type": "sales|support|information",
    "target_audience": ["individual", "business"],
    "priority": "high|medium|low"
}
```

### **3. Search Optimization**
- S·ª≠ d·ª•ng `content_for_embedding` v·ªõi keywords optimized
- Include synonyms v√† alternate phrasings
- Structure content theo search intent

### **4. Maintenance Strategy**
- Auto-reindex khi company context thay ƒë·ªïi
- Periodic cleanup c·ªßa stale data
- Version control cho major updates

---

## üìä Performance Considerations

### **Indexing Performance**
- Batch upload t·∫•t c·∫£ chunks c√πng l√∫c
- S·ª≠ d·ª•ng proper payload indexes
- Monitor collection size v√† query performance

### **Search Performance**
- Cache frequent search results
- Use appropriate score_threshold
- Limit search scope v·ªõi proper filtering

### **Memory Management**
- Clear company_collections cache khi c·∫ßn
- Monitor Qdrant memory usage
- Implement data retention policies

---

## üõ°Ô∏è Security & Multi-tenancy

### **Data Isolation**
- `company_id` l√† PRIMARY FILTER b·∫Øt bu·ªôc
- Validate company access trong API layer
- Audit logs cho all operations

### **Error Handling**
- Graceful fallback khi Qdrant unavailable
- Retry logic cho network failures
- Comprehensive error logging

---

Ph√¢n t√≠ch n√†y cung c·∫•p roadmap chi ti·∫øt ƒë·ªÉ implement company context CRUD operations s·ª≠ d·ª•ng `QdrantCompanyDataService` m·ªôt c√°ch hi·ªáu qu·∫£ v√† scalable.
