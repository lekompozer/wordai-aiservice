# API Documentation: Async Document Extraction Workflow

## Overview
API h·ªó tr·ª£ x·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô ƒë·ªÉ extract d·ªØ li·ªáu t·ª´ documents b·∫±ng AI (Gemini), cho ph√©p backend submit file v√† nh·∫≠n k·∫øt qu·∫£ th√¥ng qua callback mechanism.

**‚úÖ IMPLEMENTED ENDPOINTS**:
- `POST /api/extract/process-async` - Submit extraction task
- `GET /api/extract/status/{task_id}` - Check task status
- `GET /api/extract/result/{task_id}` - Get extraction results
- Callback mechanism for real-time notifications

## Performance Metrics
- **Queue Submission**: ~0.03-0.04s (immediate response)
- **AI Processing**: ~18-22s (depends on file size and complexity)
- **Total Workflow**: ~22-25s (including Qdrant upload)

---

## 1. Submit Async Extraction Request

### Endpoint
```
POST /api/extract/process-async
```

### Headers
```json
{
  "Content-Type": "application/json"
}
```

### Request Body
```json
{
  "r2_url": "https://static.agent8x.io.vn/company/{company_id}/files/{filename}",
  "company_id": "your-company-id",
  "industry": "insurance",
  "data_type": "auto",
  "file_name": "document.txt",
  "file_size": 1024000,
  "file_type": "text/plain"
}
```

### Request Parameters
| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `r2_url` | string | ‚úÖ | Full URL to the file stored in R2 |
| `company_id` | string | ‚úÖ | Unique company identifier |
| `industry` | string | ‚úÖ | Industry type (`insurance`, `banking`, `retail`, etc.) |
| `data_type` | string | ‚úÖ | Extraction type (`auto`, `products`, `services`) |
| `file_name` | string | ‚úÖ | Original filename |
| `file_size` | integer | ‚úÖ | File size in bytes |
| `file_type` | string | ‚úÖ | MIME type |

### Response (Immediate - ~0.04s)
```json
{
  "success": true,
  "message": "Document queued for processing",
  "task_id": "extract_d4f2a891-c3b2-4e6f-8a9d-1b2c3d4e5f6g",
  "estimated_processing_time": "15-25 seconds",
  "status_check_url": "/api/extract/status/{task_id}",
  "queue_position": 1
}
```

### Error Response
```json
{
  "success": false,
  "error": "Invalid request parameters",
  "error_details": {
    "r2_url": "URL is required",
    "company_id": "Company ID is required"
  }
}
```

---

## 2. Check Processing Status

### Endpoint
```
GET /api/extract/status/{task_id}
```

### Response - Processing
```json
{
  "task_id": "extract_d4f2a891-c3b2-4e6f-8a9d-1b2c3d4e5f6g",
  "status": "processing",
  "progress": {
    "stage": "ai_extraction",
    "estimated_remaining": "12-18 seconds"
  },
  "submitted_at": "2025-07-26T15:18:07.159081Z"
}
```

### Response - Completed
```json
{
  "task_id": "extract_d4f2a891-c3b2-4e6f-8a9d-1b2c3d4e5f6g",
  "status": "completed",
  "processing_time": 19.83,
  "completed_at": "2025-07-26T15:18:27.159081Z",
  "result_available": true
}
```

---

## 3. Get Extraction Results

### Endpoint
```
GET /api/extract/result/{task_id}
```

### Full Response Structure
```json
{
  "success": true,
  "message": "Auto-categorization extraction completed successfully",
  "task_id": "extract_d4f2a891-c3b2-4e6f-8a9d-1b2c3d4e5f6g",
  "processing_time": 19.83,
  "total_items_extracted": 5,
  "ai_provider": "gemini",
  "template_used": "InsuranceExtractionTemplate",
  "industry": "insurance",
  "data_type": "auto",
  "raw_content": "--- D·ªäCH V·ª§ AIA VI·ªÜT NAM... (full original text)",
  "structured_data": {
    "products": [
      {
        "name": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn",
        "type": "B·∫£o hi·ªÉm li√™n k·∫øt chung",
        "description": "B·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc r·ªßi ro...",
        "coverage_period": "30 nƒÉm",
        "premium": "T√πy thu·ªôc v√†o tu·ªïi, gi·ªõi t√≠nh...",
        "conditions": "T√πy s·∫£n ph·∫©m, y√™u c·∫ßu s·ª©c kh·ªèe..."
      }
    ],
    "services": [
      {
        "name": "AIA Vitality",
        "type": "Ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i",
        "description": "Ch∆∞∆°ng tr√¨nh AIA Vitality...",
        "pricing": "T√≠ch h·ª£p v√†o c√°c s·∫£n ph·∫©m b·∫£o hi·ªÉm",
        "availability": "√Åp d·ª•ng cho c√°c s·∫£n ph·∫©m b·∫£o hi·ªÉm t∆∞∆°ng ·ª©ng"
      }
    ],
    "extraction_summary": {
      "total_products": 3,
      "total_services": 2,
      "data_quality": "high",
      "categorization_notes": "Categorization based on product descriptions...",
      "industry_context": "Insurance products and related services..."
    }
  },
  "extraction_metadata": {
    "r2_url": "https://static.agent8x.io.vn/company/.../files/SanPham-AIA.txt",
    "extraction_mode": "auto_categorization",
    "target_categories": ["products", "services"],
    "ai_provider": "gemini",
    "template_used": "InsuranceExtractionTemplate",
    "industry": "insurance",
    "company_name": null,
    "file_extension": ".txt",
    "extraction_timestamp": "2025-07-26T15:18:07.159081",
    "total_items": 5,
    "source": "r2_extraction_service_v2",
    "categorization_summary": {
      "products": 3,
      "services": 2
    }
  },
  "error": null,
  "error_details": null
}
```

---

## 4. Webhook Callback Structure (CH√çNH X√ÅC)

### File Upload Callback (Now includes RAW CONTENT)
**Endpoint Backend**: `/api/webhooks/file-uploaded`
**Headers t·ª´ AI Service**:
```javascript
{
    "Content-Type": "application/json",
    "X-Webhook-Source": "ai-service",
    "X-Webhook-Signature": "sha256=abc123...",
    "User-Agent": "Agent8x-AI-Service/1.0"
}
```

**ENHANCED FILE UPLOAD CALLBACK** (B√¢y gi·ªù c√≥ RAW CONTENT):
```javascript
{
    "event": "file.uploaded",
    "companyId": "9a974d00-1a4b-4d5d-8dc3-4b5058255b8f",
    "data": {
        "fileId": "file_1753617620355_de12d50e",
        "status": "completed",
        "chunksCreated": 3,
        "processingTime": 5.23,
        "processedAt": "2025-07-27T12:00:38.751498",
        "tags": ["company-info", "profile", "overview"],

        // ‚úÖ RAW CONTENT (Full original file content for database storage)
        "raw_content": "C√îNG TY C·ªî PH·∫¶N B·∫¢O HI·ªÇM AIA VI·ªÜT NAM\n\nTh√¥ng tin c√¥ng ty:\nAIA Vi·ªát Nam ƒë∆∞·ª£c th√†nh l·∫≠p t·ª´ nƒÉm 2000...\n\nC√°c s·∫£n ph·∫©m ch√≠nh:\n1. B·∫£o hi·ªÉm nh√¢n th·ªç\n2. B·∫£o hi·ªÉm s·ª©c kh·ªèe\n3. B·∫£o hi·ªÉm li√™n k·∫øt chung...",

        // ‚úÖ Complete file metadata for reference
        "file_metadata": {
            "original_name": "AIA_company_profile.pdf",
            "file_name": "AIA_company_profile_processed.pdf",
            "file_size": 2048000,
            "file_type": "application/pdf",
            "uploaded_by": "user_uid_123",
            "description": "Company profile and information document",
            "r2_url": "https://static.agent8x.io.vn/company/9a974d00-1a4b-4d5d-8dc3-4b5058255b8f/files/AIA_company_profile.pdf"
        }
    },
    "timestamp": "2025-07-27T12:00:38.751498"
}
```

### AI Extraction Callback (Full Data)
**Endpoint Backend**: `/api/webhooks/ai/extraction-callback`
**Headers t·ª´ AI Service**:
```javascript
{
    "Content-Type": "application/json",
    "X-Webhook-Source": "ai-service",
    "X-Webhook-Signature": "sha256=abc123...",
    "User-Agent": "Agent8x-AI-Service/1.0"
}
```

### **FULL CALLBACK PAYLOAD** (Ch·ª©a t·∫•t c·∫£ d·ªØ li·ªáu ƒë·ªÉ l∆∞u database)
```javascript
{
    // Basic task information
    "task_id": "extract_1753617620355_de12d50e",
    "company_id": "9a974d00-1a4b-4d5d-8dc3-4b5058255b8f",
    "status": "completed",
    "processing_time": 16.318650007247925,
    "timestamp": "2025-07-27T12:00:38.751498",

    // Summary results for quick overview
    "results": {
        "products_count": 3,
        "services_count": 0,
        "total_items": 3,
        "ai_provider": "gemini",
        "template_used": "InsuranceExtractionTemplate"
    },

    // üìÑ FULL RAW CONTENT (Original text from file)
    "raw_content": "--- D·ªäCH V·ª§ AIA VI·ªÜT NAM ---\n\nC√¥ng ty AIA Vi·ªát Nam cung c·∫•p c√°c s·∫£n ph·∫©m b·∫£o hi·ªÉm...\n\n1. AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn\nƒê√¢y l√† s·∫£n ph·∫©m b·∫£o hi·ªÉm li√™n k·∫øt chung...",

    // üì¶ FULL STRUCTURED DATA (Products & Services cho database) - ‚úÖ C·∫¨P NH·∫¨T B∆Ø·ªöC 2
    "structured_data": {
        "products": [
            {
                // ‚úÖ NEW STEP 2: AI Service t·ª± generate product_id duy nh·∫•t
                "product_id": "prod_9c96ef4a-af0f-4974-b151-93ca5c1d94eb",
                "name": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn",
                "type": "B·∫£o hi·ªÉm li√™n k·∫øt chung",
                "description": "B·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc r·ªßi ro b·ªánh t·∫≠t, th∆∞∆°ng t·∫≠t v√† t·ª≠ vong, ƒë·ªìng th·ªùi t√≠ch l≈©y t√†i ch√≠nh cho t∆∞∆°ng lai",
                "coverage_period": "30 nƒÉm",
                "age_range": "18-60 tu·ªïi",
                "premium": "T√πy thu·ªôc v√†o tu·ªïi, gi·ªõi t√≠nh v√† m·ª©c b·∫£o hi·ªÉm",
                "conditions": "T√πy s·∫£n ph·∫©m, y√™u c·∫ßu s·ª©c kh·ªèe v√† ƒëi·ªÅu ki·ªán c·ª• th·ªÉ",

                // ‚úÖ NEW: Tr∆∞·ªùng retrieval_context cho RAG optimization
                "retrieval_context": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn l√† b·∫£o hi·ªÉm li√™n k·∫øt chung b·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc r·ªßi ro b·ªánh t·∫≠t, th∆∞∆°ng t·∫≠t v√† t·ª≠ vong, ƒë·ªìng th·ªùi t√≠ch l≈©y t√†i ch√≠nh cho t∆∞∆°ng lai. Th·ªùi gian b·∫£o hi·ªÉm 30 nƒÉm, ƒë·ªô tu·ªïi tham gia 18-60 tu·ªïi. Ph√≠ b·∫£o hi·ªÉm t√πy thu·ªôc v√†o tu·ªïi, gi·ªõi t√≠nh v√† m·ª©c b·∫£o hi·ªÉm.",

                // ‚úÖ NEW STEP 2: Clean data t·ª´ AI Service catalog
                "catalog_price": 1500000.0,
                "catalog_quantity": 50,
                // Backend tracking fields
                "qdrant_point_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890"
            },
            {
                // ‚úÖ NEW STEP 2: AI Service t·ª± generate product_id duy nh·∫•t
                "product_id": "prod_dc5b9197-9d52-4750-9694-de853532a20b",
                "name": "AIA ‚Äì An Gia Ph√∫ Qu√Ω",
                "type": "B·∫£o hi·ªÉm nh√¢n th·ªç truy·ªÅn th·ªëng",
                "description": "B·∫£o v·ªá t√†i ch√≠nh gia ƒë√¨nh v·ªõi quy·ªÅn l·ª£i t·ª≠ vong v√† th∆∞∆°ng t·∫≠t to√†n b·ªô vƒ©nh vi·ªÖn",
                "coverage_period": "ƒê·∫øn 99 tu·ªïi",
                "age_range": "30 ng√†y - 65 tu·ªïi",
                "premium": "Ph√≠ c·ªë ƒë·ªãnh h√†ng nƒÉm",
                "conditions": "Kh√°m s·ª©c kh·ªèe v√† khai b√°o y t·∫ø",

                // ‚úÖ NEW: Tr∆∞·ªùng retrieval_context cho RAG optimization
                "retrieval_context": "AIA ‚Äì An Gia Ph√∫ Qu√Ω l√† b·∫£o hi·ªÉm nh√¢n th·ªç truy·ªÅn th·ªëng b·∫£o v·ªá t√†i ch√≠nh gia ƒë√¨nh v·ªõi quy·ªÅn l·ª£i t·ª≠ vong v√† th∆∞∆°ng t·∫≠t to√†n b·ªô vƒ©nh vi·ªÖn. Th·ªùi gian b·∫£o hi·ªÉm ƒë·∫øn 99 tu·ªïi, ƒë·ªô tu·ªïi tham gia t·ª´ 30 ng√†y - 65 tu·ªïi. Ph√≠ c·ªë ƒë·ªãnh h√†ng nƒÉm, y√™u c·∫ßu kh√°m s·ª©c kh·ªèe v√† khai b√°o y t·∫ø.",

                // ‚úÖ NEW STEP 2: Clean data t·ª´ AI Service catalog
                "catalog_price": 2800000.0,
                "catalog_quantity": 25,
                // Backend tracking fields
                "qdrant_point_id": "b2c3d4e5-f6g7-8901-bcde-f23456789012"
            }
        ],
        "services": [
            {
                // ‚úÖ NEW STEP 2: AI Service t·ª± generate service_id duy nh·∫•t
                "service_id": "serv_aba78752-c1d2-437b-aeb9-5df058972b7e",
                "name": "AIA Vitality",
                "type": "Ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i s·ª©c kh·ªèe",
                "description": "Ch∆∞∆°ng tr√¨nh khuy·∫øn kh√≠ch l·ªëi s·ªëng l√†nh m·∫°nh v·ªõi nhi·ªÅu ∆∞u ƒë√£i v√† ph·∫ßn th∆∞·ªüng",
                "pricing": "T√≠ch h·ª£p v√†o c√°c s·∫£n ph·∫©m b·∫£o hi·ªÉm",
                "availability": "√Åp d·ª•ng cho kh√°ch h√†ng c√≥ s·∫£n ph·∫©m b·∫£o hi·ªÉm t∆∞∆°ng ·ª©ng",

                // ‚úÖ NEW: Tr∆∞·ªùng retrieval_context cho RAG optimization
                "retrieval_context": "AIA Vitality l√† ch∆∞∆°ng tr√¨nh ∆∞u ƒë√£i s·ª©c kh·ªèe khuy·∫øn kh√≠ch l·ªëi s·ªëng l√†nh m·∫°nh v·ªõi nhi·ªÅu ∆∞u ƒë√£i v√† ph·∫ßn th∆∞·ªüng. ƒê∆∞·ª£c t√≠ch h·ª£p v√†o c√°c s·∫£n ph·∫©m b·∫£o hi·ªÉm v√† √°p d·ª•ng cho kh√°ch h√†ng c√≥ s·∫£n ph·∫©m b·∫£o hi·ªÉm t∆∞∆°ng ·ª©ng.",

                // ‚úÖ NEW STEP 2: Clean data t·ª´ AI Service catalog
                "catalog_price": 500000.0,
                "catalog_quantity": -1,  // Service kh√¥ng track quantity
                // Backend tracking fields
                "qdrant_point_id": "c3d4e5f6-g7h8-9012-cdef-345678901234"
            }
        ],
        "extraction_summary": {
            "total_products": 2,
            "total_services": 1,
            "data_quality": "high",
            "categorization_notes": "Extracted 2 products and 1 services using InsuranceExtractionTemplate template",
            "industry_context": "insurance industry extraction",
            // ‚úÖ NEW STEP 2: AI Service metadata
            "internal_catalog_updates": {
                "products_registered": 2,
                "services_registered": 1,
                "catalog_service_version": "1.0.0"
            }
        }
    },

    // üìã Full extraction metadata for reference
    "extraction_metadata": {
        "r2_url": "https://static.agent8x.io.vn/company/9a974d00-1a4b-4d5d-8dc3-4b5058255b8f/files/SanPham-AIA.txt",
        "extraction_mode": "auto_categorization",
        "target_categories": ["products", "services"],
        "ai_provider": "gemini",
        "template_used": "InsuranceExtractionTemplate",
        "industry": "insurance",
        "data_type": "auto",
        "file_name": "SanPham-AIA.txt",
        "file_size": 15420,
        "file_type": "text/plain",
        "language": "vi",
        "extraction_timestamp": "2025-07-27T12:00:38.751498",
        "total_items": 4,
        "source": "ai_extraction_service_v2"
    }
}
```

### **Backend Implementation cho File Upload Callback**

```javascript
// /api/webhooks/file-uploaded
app.post('/api/webhooks/file-uploaded', webhookAuth, async (req, res) => {
    const {
        event,
        companyId,
        data: {
            fileId,
            status,
            chunksCreated,
            processingTime,
            processedAt,
            tags,
            raw_content,
            file_metadata
        }
    } = req.body;

    try {
        // 1. Store file upload record in database
        const fileRecord = await db.uploaded_files.create({
            file_id: fileId,
            company_id: companyId,
            original_name: file_metadata.original_name,
            file_name: file_metadata.file_name,
            file_size: file_metadata.file_size,
            file_type: file_metadata.file_type,
            uploaded_by: file_metadata.uploaded_by,
            description: file_metadata.description,
            r2_url: file_metadata.r2_url,
            raw_content: raw_content,  // Store complete file content
            tags: JSON.stringify(tags),
            chunks_created: chunksCreated,
            processing_time: processingTime,
            processed_at: new Date(processedAt),
            status: status,
            created_at: new Date()
        });

        // 2. Update company file count
        await db.companies.update(
            { id: companyId },
            {
                total_files: db.sequelize.literal('total_files + 1'),
                last_file_uploaded: new Date()
            }
        );

        // 3. Index tags for search
        if (tags && tags.length > 0) {
            for (const tag of tags) {
                await db.file_tags.upsert({
                    company_id: companyId,
                    tag_name: tag,
                    file_count: db.sequelize.literal('file_count + 1'),
                    updated_at: new Date()
                });
            }
        }

        // 4. Log successful processing
        console.log(`‚úÖ File upload completed for ${fileId}`);
        console.log(`   üìÑ Original name: ${file_metadata.original_name}`);
        console.log(`   üì¶ Chunks created: ${chunksCreated}`);
        console.log(`   üìÑ Raw content: ${raw_content ? raw_content.length : 0} characters`);
        console.log(`   üè∑Ô∏è Tags: ${tags ? tags.join(', ') : 'none'}`);
        console.log(`   ‚è±Ô∏è Processing time: ${processingTime}s`);

        // 5. Return success response
        res.json({
            success: true,
            message: "File upload record saved successfully",
            file_record: {
                id: fileRecord.id,
                file_id: fileId,
                chunks_created: chunksCreated,
                raw_content_length: raw_content ? raw_content.length : 0
            }
        });

    } catch (error) {
        console.error(`‚ùå Failed to save file upload record for ${fileId}:`, error);
        res.status(500).json({
            success: false,
            error: "Failed to save file upload record",
            details: error.message
        });
    }
});
```

### **Backend Implementation cho Extraction Callback**

```javascript
// /api/webhooks/ai/extraction-callback
app.post('/api/webhooks/ai/extraction-callback', webhookAuth, async (req, res) => {
    const {
        task_id,
        company_id,
        status,
        processing_time,
        raw_content,
        structured_data,
        extraction_metadata,
        results
    } = req.body;

    try {
        // 1. Update extraction job status
        await db.extraction_jobs.update(
            { task_id: task_id },
            {
                status: status,
                completed_at: new Date(),
                processing_time: processing_time,
                ai_provider: results.ai_provider,
                template_used: results.template_used,
                total_items_extracted: results.total_items,
                raw_content: raw_content, // Store full original content
                extraction_metadata: JSON.stringify(extraction_metadata)
            }
        );

        const job = await db.extraction_jobs.findOne({ task_id: task_id });

        // 2. Save extracted PRODUCTS to database - ‚úÖ C·∫¨P NH·∫¨T B∆Ø·ªöC 2
        if (structured_data.products && structured_data.products.length > 0) {
            for (const product of structured_data.products) {
                await db.extracted_products.create({
                    job_id: job.id,
                    company_id: company_id,
                    // ‚úÖ NEW STEP 2: AI Service provided product_id
                    product_id: product.product_id,  // UUID t·ª´ AI Service
                    qdrant_point_id: product.qdrant_point_id,  // Vector search ID
                    name: product.name,
                    type: product.type,
                    description: product.description,
                    coverage_period: product.coverage_period,
                    age_range: product.age_range,
                    premium: product.premium,
                    conditions: product.conditions,

                    // ‚úÖ NEW: Tr∆∞·ªùng retrieval_context cho RAG optimization
                    retrieval_context: product.retrieval_context,

                    // ‚úÖ NEW STEP 2: Clean catalog data t·ª´ AI Service
                    catalog_price: product.catalog_price,
                    catalog_quantity: product.catalog_quantity,
                    created_at: new Date()
                });
            }
            console.log(`‚úÖ Saved ${structured_data.products.length} products to database`);
            console.log(`   üîó All products have AI Service product_id for sync`);
        }

        // 3. Save extracted SERVICES to database - ‚úÖ C·∫¨P NH·∫¨T B∆Ø·ªöC 2
        if (structured_data.services && structured_data.services.length > 0) {
            for (const service of structured_data.services) {
                await db.extracted_services.create({
                    job_id: job.id,
                    company_id: company_id,
                    // ‚úÖ NEW STEP 2: AI Service provided service_id
                    service_id: service.service_id,  // UUID t·ª´ AI Service
                    qdrant_point_id: service.qdrant_point_id,  // Vector search ID
                    name: service.name,
                    type: service.type,
                    description: service.description,
                    pricing: service.pricing,
                    availability: service.availability,

                    // ‚úÖ NEW: Tr∆∞·ªùng retrieval_context cho RAG optimization
                    retrieval_context: service.retrieval_context,

                    // ‚úÖ NEW STEP 2: Clean catalog data t·ª´ AI Service
                    catalog_price: service.catalog_price,
                    catalog_quantity: service.catalog_quantity,
                    created_at: new Date()
                });
            }
            console.log(`‚úÖ Saved ${structured_data.services.length} services to database`);
            console.log(`   üîó All services have AI Service service_id for sync`);
        }

        // 4. Log successful processing
        console.log(`üéâ Extraction completed for task ${task_id}`);
        console.log(`   üì¶ Products: ${results.products_count}`);
        console.log(`   üîß Services: ${results.services_count}`);
        console.log(`   üìÑ Raw content: ${raw_content ? raw_content.length : 0} characters`);
        console.log(`   ‚è±Ô∏è Processing time: ${processing_time}s`);

        // 5. Return success response
        res.json({
            success: true,
            message: "Extraction results saved successfully",
            saved_items: {
                products: structured_data.products ? structured_data.products.length : 0,
                services: structured_data.services ? structured_data.services.length : 0,
                total: results.total_items
            }
        });

    } catch (error) {
        console.error(`‚ùå Failed to save extraction results for ${task_id}:`, error);
        res.status(500).json({
            success: false,
            error: "Failed to save extraction results",
            details: error.message
        });
    }
});
```

### **Database Schema Update - ‚úÖ C·∫¨P NH·∫¨T B∆Ø·ªöC 2**

```sql
-- Add raw_content column to store original file content
ALTER TABLE extraction_jobs
ADD COLUMN raw_content TEXT,
ADD COLUMN extraction_metadata JSONB;

-- ‚úÖ NEW STEP 2: Add AI Service sync fields to product table
ALTER TABLE extracted_products
ADD COLUMN company_id VARCHAR(255),
ADD COLUMN product_id VARCHAR(255) UNIQUE,  -- AI Service generated UUID
ADD COLUMN qdrant_point_id VARCHAR(255),    -- Vector search reference
ADD COLUMN catalog_price DECIMAL(12,2),     -- Clean price t·ª´ AI Service
ADD COLUMN catalog_quantity INTEGER,        -- Inventory count
ADD COLUMN retrieval_context TEXT;          -- ‚úÖ NEW: RAG optimized context

-- ‚úÖ NEW STEP 2: Add AI Service sync fields to service table
ALTER TABLE extracted_services
ADD COLUMN company_id VARCHAR(255),
ADD COLUMN service_id VARCHAR(255) UNIQUE,  -- AI Service generated UUID
ADD COLUMN qdrant_point_id VARCHAR(255),    -- Vector search reference
ADD COLUMN catalog_price DECIMAL(12,2),     -- Clean price t·ª´ AI Service
ADD COLUMN catalog_quantity INTEGER,        -- Availability count (-1 = kh√¥ng track)
ADD COLUMN retrieval_context TEXT;          -- ‚úÖ NEW: RAG optimized context

-- Add indexes for better performance
CREATE INDEX idx_extraction_jobs_company_id ON extraction_jobs(company_id);
CREATE INDEX idx_extracted_products_company_id ON extracted_products(company_id);
CREATE INDEX idx_extracted_services_company_id ON extracted_services(company_id);

-- ‚úÖ NEW STEP 2: Add indexes for AI Service sync
CREATE INDEX idx_extracted_products_product_id ON extracted_products(product_id);
CREATE INDEX idx_extracted_services_service_id ON extracted_services(service_id);
CREATE INDEX idx_extracted_products_qdrant_id ON extracted_products(qdrant_point_id);
CREATE INDEX idx_extracted_services_qdrant_id ON extracted_services(qdrant_point_id);
```

---

## Backend Integration Guide

### 1. Database Schema Recommendations

#### uploaded_files table (for file upload callbacks)
```sql
CREATE TABLE uploaded_files (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    file_id VARCHAR(255) UNIQUE NOT NULL,
    company_id VARCHAR(255) NOT NULL,
    original_name VARCHAR(500) NOT NULL,
    file_name VARCHAR(500) NOT NULL,
    file_size BIGINT NOT NULL,
    file_type VARCHAR(100) NOT NULL,
    uploaded_by VARCHAR(255),
    description TEXT,
    r2_url TEXT NOT NULL,
    raw_content TEXT,
    tags JSONB,
    chunks_created INTEGER DEFAULT 0,
    processing_time DECIMAL(10,3),
    processed_at TIMESTAMP,
    status VARCHAR(50) DEFAULT 'uploaded',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

#### extraction_jobs table (for AI extraction callbacks)
```sql
CREATE TABLE extraction_jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    task_id VARCHAR(255) UNIQUE NOT NULL,
    company_id VARCHAR(255) NOT NULL,
    file_name VARCHAR(255) NOT NULL,
    r2_url TEXT NOT NULL,
    industry VARCHAR(100) NOT NULL,
    data_type VARCHAR(50) NOT NULL,
    status VARCHAR(50) DEFAULT 'queued',
    submitted_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP NULL,
    processing_time DECIMAL(10,3) NULL,
    ai_provider VARCHAR(50) NULL,
    template_used VARCHAR(100) NULL,
    total_items_extracted INTEGER NULL,
    raw_content TEXT,
    extraction_metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

#### file_tags table (for tag indexing)
```sql
CREATE TABLE file_tags (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id VARCHAR(255) NOT NULL,
    tag_name VARCHAR(100) NOT NULL,
    file_count INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(company_id, tag_name)
);
```

#### extracted_products table (for AI extraction results)
```sql
CREATE TABLE extracted_products (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    job_id UUID REFERENCES extraction_jobs(id),
    company_id VARCHAR(255),
    -- ‚úÖ NEW: AI Service sync fields
    product_id VARCHAR(255) UNIQUE,     -- AI Service generated UUID
    qdrant_point_id VARCHAR(255),       -- Vector search reference
    -- Product information
    name VARCHAR(500) NOT NULL,
    type VARCHAR(200),
    description TEXT,
    coverage_period VARCHAR(100),
    age_range VARCHAR(100),
    premium TEXT,
    conditions TEXT,
    -- ‚úÖ NEW: RAG optimization field
    retrieval_context TEXT,             -- Optimized context for AI chat responses
    -- Catalog integration
    catalog_price DECIMAL(12,2),        -- Clean price t·ª´ AI Service
    catalog_quantity INTEGER,           -- Inventory count
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### extracted_services table
```sql
CREATE TABLE extracted_services (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    job_id UUID REFERENCES extraction_jobs(id),
    company_id VARCHAR(255),
    -- ‚úÖ NEW: AI Service sync fields
    service_id VARCHAR(255) UNIQUE,     -- AI Service generated UUID
    qdrant_point_id VARCHAR(255),       -- Vector search reference
    -- Service information
    name VARCHAR(500) NOT NULL,
    type VARCHAR(200),
    description TEXT,
    pricing TEXT,
    availability VARCHAR(200),
    -- ‚úÖ NEW: RAG optimization field
    retrieval_context TEXT,             -- Optimized context for AI chat responses
    -- Catalog integration
    catalog_price DECIMAL(12,2),        -- Clean price t·ª´ AI Service
    catalog_quantity INTEGER,           -- Availability count (-1 = kh√¥ng track)
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 2. Implementation Workflow

#### Step 1: Submit and Store
```python
async def submit_extraction(file_data):
    # Submit to AI service
    response = await http_client.post("/api/extract/process-async", json=file_data)
    task_data = response.json()

    # Store immediately in database
    job = await db.extraction_jobs.create({
        "task_id": task_data["task_id"],
        "company_id": file_data["company_id"],
        "file_name": file_data["file_name"],
        "r2_url": file_data["r2_url"],
        "industry": file_data["industry"],
        "data_type": file_data["data_type"],
        "status": "queued"
    })

    return {"job_id": job.id, "task_id": task_data["task_id"]}
```

#### Step 2: Monitor Processing
```python
async def monitor_extraction(task_id):
    while True:
        status = await http_client.get(f"/api/extract/status/{task_id}")

        if status["status"] == "completed":
            # Get results and store
            results = await http_client.get(f"/api/extract/result/{task_id}")
            await store_extraction_results(task_id, results)
            break
        elif status["status"] == "failed":
            await handle_extraction_failure(task_id, status)
            break

        await asyncio.sleep(2)  # Check every 2 seconds
```

#### Step 3: Store Results
```python
async def store_extraction_results(task_id, results):
    # Update job status
    await db.extraction_jobs.update(
        {"task_id": task_id},
        {
            "status": "completed",
            "completed_at": datetime.now(),
            "processing_time": results["processing_time"],
            "ai_provider": results["ai_provider"],
            "template_used": results["template_used"],
            "total_items_extracted": results["total_items"]
        }
    )

    job = await db.extraction_jobs.get({"task_id": task_id})

    # Store products
    if "products" in results["structured_data"]:
        for product in results["structured_data"]["products"]:
            await db.extracted_products.create({
                "job_id": job.id,
                "company_id": job.company_id,
                "name": product["name"],
                "type": product.get("type"),
                "description": product.get("description"),
                "premium": product.get("premium"),
                "conditions": product.get("conditions")
            })

    # Store services
    if "services" in results["structured_data"]:
        for service in results["structured_data"]["services"]:
            await db.extracted_services.create({
                "job_id": job.id,
                "company_id": job.company_id,
                "name": service["name"],
                "type": service.get("type"),
                "description": service.get("description"),
                "pricing": service.get("pricing"),
                "availability": service.get("availability")
            })
```

### 3. Polling Strategy

#### Recommended Polling Implementation
```python
class ExtractionMonitor:
    def __init__(self, http_client, db):
        self.http_client = http_client
        self.db = db

    async def start_monitoring(self, task_id):
        """Start monitoring with exponential backoff"""
        max_wait = 60  # seconds
        check_interval = 2  # start with 2 seconds
        total_waited = 0

        while total_waited < max_wait:
            try:
                status = await self.http_client.get(f"/api/extract/status/{task_id}")

                if status["status"] == "completed":
                    await self._handle_completion(task_id)
                    return True
                elif status["status"] == "failed":
                    await self._handle_failure(task_id, status)
                    return False

                await asyncio.sleep(check_interval)
                total_waited += check_interval

                # Exponential backoff (2s -> 3s -> 5s -> 5s...)
                check_interval = min(check_interval * 1.5, 5)

            except Exception as e:
                logger.error(f"Monitoring error for {task_id}: {e}")
                await asyncio.sleep(5)

        # Timeout handling
        await self._handle_timeout(task_id)
        return False
```

### 4. Error Handling

#### Common Error Scenarios
```python
async def handle_extraction_errors(task_id, error_response):
    error_mapping = {
        "file_not_found": "File kh√¥ng t·ªìn t·∫°i ho·∫∑c ƒë√£ b·ªã x√≥a",
        "unsupported_format": "ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£",
        "ai_service_error": "L·ªói d·ªãch v·ª• AI, th·ª≠ l·∫°i sau",
        "timeout": "X·ª≠ l√Ω qu√° th·ªùi gian cho ph√©p",
        "invalid_content": "N·ªôi dung file kh√¥ng h·ª£p l·ªá"
    }

    await db.extraction_jobs.update(
        {"task_id": task_id},
        {
            "status": "failed",
            "error_message": error_mapping.get(
                error_response.get("error_code"),
                "L·ªói kh√¥ng x√°c ƒë·ªãnh"
            ),
            "completed_at": datetime.now()
        }
    )
```

### 5. Performance Optimization

#### Batch Processing
```python
async def process_multiple_files(file_list):
    """Process multiple files efficiently"""
    tasks = []

    for file_data in file_list:
        task = submit_extraction(file_data)
        tasks.append(task)

    # Submit all files first (fast)
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Then monitor all in parallel
    task_ids = [r["task_id"] for r in results if not isinstance(r, Exception)]

    monitor_tasks = [
        monitor_extraction(task_id)
        for task_id in task_ids
    ]

    await asyncio.gather(*monitor_tasks, return_exceptions=True)
```

---

## ‚úÖ B∆Ø·ªöC 2: ENHANCED PRODUCT/SERVICE ID INTEGRATION

### **üîë Key Features Added (Aug 2025)**

1. **Product ID Auto-Generation**: AI Service t·ª± t·∫°o `product_id` v√† `service_id` duy nh·∫•t
2. **Internal Catalog Management**: AI Service l∆∞u tr·ªØ catalog n·ªôi b·ªô v·ªõi 4 tr∆∞·ªùng s·∫°ch
3. **Real-time Synchronization**: Backend nh·∫≠n full data v·ªõi IDs ƒë·ªÉ ƒë·ªìng b·ªô
4. **Enhanced Webhook Data**: Callback payload bao g·ªìm catalog metadata

### **üéØ Benefits cho Backend**

| Before Step 2 | After Step 2 |
|----------------|--------------|
| ‚ùå No product_id/service_id | ‚úÖ Real UUID generated by AI Service |
| ‚ùå Only raw AI data | ‚úÖ Clean catalog data (price, quantity) |
| ‚ùå No inventory integration | ‚úÖ Real-time inventory sync possible |
| ‚ùå Callback missing IDs | ‚úÖ Full webhook data with tracking IDs |

### **üîó Synchronization Use Cases**

#### 1. **Product Lookup by AI Service ID**
```javascript
// Backend c√≥ th·ªÉ tra c·ª©u product b·∫±ng AI Service ID
const product = await db.extracted_products.findOne({
    product_id: "prod_9c96ef4a-af0f-4974-b151-93ca5c1d94eb"
});

console.log(`Found product: ${product.name}`);
console.log(`AI Service price: ${product.catalog_price}`);
console.log(`AI Service quantity: ${product.catalog_quantity}`);
```

#### 2. **Cross-Reference v·ªõi Chat System**
```javascript
// AI Chat System g·ª≠i webhook v·ªõi product_id t·ª´ catalog
// Backend c√≥ th·ªÉ update inventory ch√≠nh x√°c
app.post('/api/webhooks/ai/check-quantity', async (req, res) => {
    const { product_id, requested_quantity } = req.body;

    // T√¨m product b·∫±ng AI Service ID
    const product = await db.extracted_products.findOne({
        product_id: product_id
    });

    if (product) {
        // Update quantity based on real data
        const available_quantity = await checkRealInventory(product.id);

        // Send response back to AI Service
        res.json({
            product_id: product_id,
            current_quantity: available_quantity,
            can_fulfill: available_quantity >= requested_quantity
        });
    }
});
```

#### 3. **Qdrant Vector Reference**
```javascript
// Backend c√≥ th·ªÉ x√≥a/update vectors b·∫±ng qdrant_point_id
const deleteProductFromSearch = async (product_id) => {
    const product = await db.extracted_products.findOne({ product_id });

    // Call AI Service ƒë·ªÉ x√≥a vector
    await fetch(`${AI_SERVICE_URL}/api/qdrant/delete/${product.qdrant_point_id}`, {
        method: 'DELETE'
    });

    // X√≥a kh·ªèi database
    await db.extracted_products.destroy({ where: { product_id } });
};
```

### **üìä Enhanced Callback Data Structure**

#### Key Fields Backend Should Track:

| Field | Type | Purpose | Example |
|-------|------|---------|---------|
| `product_id` | UUID | AI Service unique identifier | `prod_9c96ef4a...` |
| `service_id` | UUID | AI Service unique identifier | `serv_aba78752...` |
| `qdrant_point_id` | UUID | Vector search reference | `a1b2c3d4-e5f6...` |
| `catalog_price` | Decimal | Clean price t·ª´ AI extraction | `1500000.0` |
| `catalog_quantity` | Integer | Inventory count (-1 for services) | `50` |
| `retrieval_context` | Text | **‚úÖ NEW**: RAG-optimized context | `"AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn l√† b·∫£o hi·ªÉm li√™n k·∫øt chung..."` |

#### **üîç Chi ti·∫øt v·ªÅ tr∆∞·ªùng `retrieval_context`**

**M·ª•c ƒë√≠ch**: Tr∆∞·ªùng n√†y ƒë∆∞·ª£c AI t·∫°o ra ƒë·∫∑c bi·ªát cho h·ªá th·ªëng RAG (Retrieval-Augmented Generation) ƒë·ªÉ t·ªëi ∆∞u h√≥a c√°c cu·ªôc tr√≤ chuy·ªán v·ªõi kh√°ch h√†ng.

**C·∫•u tr√∫c**:
- **Products**: "T√™n s·∫£n ph·∫©m + m√¥ t·∫£ ng·∫Øn g·ªçn + th√¥ng tin gi√° + ƒëi·ªÅu ki·ªán ch√≠nh"
- **Services**: "T√™n d·ªãch v·ª• + m√¥ t·∫£ l·ª£i √≠ch + th√¥ng tin gi√° + ƒëi·ªÅu ki·ªán √°p d·ª•ng"

**V√≠ d·ª• th·ª±c t·∫ø**:

```json
{
  "product_id": "prod_9c96ef4a-af0f-4974-b151-93ca5c1d94eb",
  "name": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn",
  "retrieval_context": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn l√† b·∫£o hi·ªÉm li√™n k·∫øt chung b·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc r·ªßi ro b·ªánh t·∫≠t, th∆∞∆°ng t·∫≠t v√† t·ª≠ vong, ƒë·ªìng th·ªùi t√≠ch l≈©y t√†i ch√≠nh cho t∆∞∆°ng lai. Th·ªùi gian b·∫£o hi·ªÉm 30 nƒÉm, ƒë·ªô tu·ªïi tham gia 18-60 tu·ªïi. Ph√≠ b·∫£o hi·ªÉm t√πy thu·ªôc v√†o tu·ªïi, gi·ªõi t√≠nh v√† m·ª©c b·∫£o hi·ªÉm."
}
```

**L·ª£i √≠ch cho Backend**:
- üìÑ **Content Ready**: S·∫µn s√†ng hi·ªÉn th·ªã cho kh√°ch h√†ng kh√¥ng c·∫ßn x·ª≠ l√Ω th√™m
- ü§ñ **AI-Optimized**: ƒê∆∞·ª£c t·∫°o ra b·ªüi AI ƒë·ªÉ ph√π h·ª£p v·ªõi ng·ªØ c·∫£nh tr√≤ chuy·ªán
- üîç **Search Friendly**: T·ªëi ∆∞u cho vi·ªác t√¨m ki·∫øm v√† g·ª£i √Ω s·∫£n ph·∫©m
- üì± **Mobile Friendly**: VƒÉn b·∫£n ng·∫Øn g·ªçn, d·ªÖ ƒë·ªçc tr√™n mobile

**S·ª≠ d·ª•ng trong Backend**:
```javascript
// Hi·ªÉn th·ªã th√¥ng tin s·∫£n ph·∫©m cho kh√°ch h√†ng
const displayProductInfo = (product) => {
  return {
    id: product.product_id,
    name: product.name,
    price: product.catalog_price,
    summary: product.retrieval_context,  // ‚úÖ S·∫µn s√†ng hi·ªÉn th·ªã
    quantity: product.catalog_quantity
  };
};

// T√¨m ki·∫øm s·∫£n ph·∫©m v·ªõi AI context
const searchProducts = async (query) => {
  return await db.extracted_products.findAll({
    where: {
      [Op.or]: [
        { name: { [Op.iLike]: `%${query}%` } },
        { retrieval_context: { [Op.iLike]: `%${query}%` } }  // ‚úÖ Search trong context
      ]
    }
  });
};
```

#### Internal Catalog Updates:
```javascript
// AI Service s·∫Ω g·ª≠i th√™m metadata v·ªÅ catalog updates
"extraction_summary": {
    "internal_catalog_updates": {
        "products_registered": 2,
        "services_registered": 1,
        "catalog_service_version": "1.0.0"
    }
}
```

### **‚öôÔ∏è Implementation Notes cho Backend**

1. **Database Migration**: Ch·∫°y SQL schema updates tr∆∞·ªõc khi deploy
2. **Index Performance**: C√°c index m·ªõi s·∫Ω tƒÉng t·ªëc lookup by product_id/service_id
3. **Webhook Validation**: Validate product_id format (`prod_` ho·∫∑c `serv_` prefix)
4. **Error Handling**: Handle case khi AI Service kh√¥ng th·ªÉ generate ID (fallback)

---

## üìã PAYLOAD STRUCTURE SUMMARY - Tr∆∞·ªùng retrieval_context m·ªõi

### **üîÑ Comparison: Before vs After**

#### **Before (Old Structure)**
```json
{
  "structured_data": {
    "products": [{
      "name": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn",
      "type": "B·∫£o hi·ªÉm li√™n k·∫øt chung",
      "description": "B·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc r·ªßi ro b·ªánh t·∫≠t...",
      "coverage_period": "30 nƒÉm",
      "age_range": "18-60 tu·ªïi"
      // Thi·∫øu retrieval_context - AI ph·∫£i t·ª± gh√©p n·ªëi t·ª´ nhi·ªÅu tr∆∞·ªùng
    }]
  }
}
```

#### **After (New Structure v·ªõi retrieval_context)**
```json
{
  "structured_data": {
    "products": [{
      "product_id": "prod_9c96ef4a-af0f-4974-b151-93ca5c1d94eb",
      "name": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn",
      "type": "B·∫£o hi·ªÉm li√™n k·∫øt chung",
      "description": "B·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc r·ªßi ro b·ªánh t·∫≠t...",
      "coverage_period": "30 nƒÉm",
      "age_range": "18-60 tu·ªïi",

      "retrieval_context": "AIA ‚Äì Kh·ªèe Tr·ªçn V·∫πn l√† b·∫£o hi·ªÉm li√™n k·∫øt chung b·∫£o v·ªá t√†i ch√≠nh tr∆∞·ªõc r·ªßi ro b·ªánh t·∫≠t, th∆∞∆°ng t·∫≠t v√† t·ª≠ vong, ƒë·ªìng th·ªùi t√≠ch l≈©y t√†i ch√≠nh cho t∆∞∆°ng lai. Th·ªùi gian b·∫£o hi·ªÉm 30 nƒÉm, ƒë·ªô tu·ªïi tham gia 18-60 tu·ªïi. Ph√≠ b·∫£o hi·ªÉm t√πy thu·ªôc v√†o tu·ªïi, gi·ªõi t√≠nh v√† m·ª©c b·∫£o hi·ªÉm.",

      "catalog_price": 1500000.0,
      "catalog_quantity": 50,
      "qdrant_point_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890"
    }]
  }
}
```

### **üí° Key Benefits c·ªßa retrieval_context**

| Aspect | Before | After |
|--------|--------|-------|
| **AI Response Quality** | Ph·∫£i gh√©p t·ª´ nhi·ªÅu fields | ‚úÖ Context s·∫µn s√†ng, ch·∫•t l∆∞·ª£ng cao |
| **Database Storage** | L∆∞u ri√™ng r·∫ª nhi·ªÅu tr∆∞·ªùng | ‚úÖ M·ªôt tr∆∞·ªùng t·ªëi ∆∞u cho RAG |
| **Search Performance** | Query nhi·ªÅu columns | ‚úÖ Search trong 1 tr∆∞·ªùng ƒë√£ t·ªëi ∆∞u |
| **Mobile Display** | Text d√†i, ph·ª©c t·∫°p | ‚úÖ Ng·∫Øn g·ªçn, d·ªÖ ƒë·ªçc |
| **Maintenance** | Update nhi·ªÅu fields | ‚úÖ Ch·ªâ c·∫ßn update 1 field |

### **üéØ Implementation Checklist cho Backend**

- [ ] **Database Schema**: Th√™m column `retrieval_context TEXT` v√†o `extracted_products` v√† `extracted_services`
- [ ] **Webhook Handler**: Update callback handler ƒë·ªÉ l∆∞u tr∆∞·ªùng `retrieval_context`
- [ ] **API Response**: Include `retrieval_context` trong product/service API responses
- [ ] **Search Function**: S·ª≠ d·ª•ng `retrieval_context` cho t√¨m ki·∫øm s·∫£n ph·∫©m
- [ ] **Display Logic**: S·ª≠ d·ª•ng `retrieval_context` cho hi·ªÉn th·ªã th√¥ng tin nhanh
- [ ] **Mobile Optimization**: Leverage ng·∫Øn g·ªçn c·ªßa `retrieval_context` cho mobile UI

### **üì± Frontend Usage Examples**

```javascript
// Product Card Component
const ProductCard = ({ product }) => (
  <div className="product-card">
    <h3>{product.name}</h3>
    <p className="product-summary">
      {product.retrieval_context}  {/* ‚úÖ Perfect for quick display */}
    </p>
    <span className="price">{product.catalog_price.toLocaleString()} VNƒê</span>
  </div>
);

// Search Results
const SearchResults = ({ results }) => (
  <div>
    {results.map(item => (
      <div key={item.product_id} className="search-result">
        <strong>{item.name}</strong>
        <p>{item.retrieval_context}</p>  {/* ‚úÖ No need to concat fields */}
      </div>
    ))}
  </div>
);
```

---

## Testing v√† Validation

### Test Script Usage
```bash
# Run comprehensive test
python test_realtime_async.py

# Results saved to: async_workflow_complete_test_YYYYMMDD_HHMMSS.json
```

### Expected Performance
- ‚úÖ Queue submission: < 0.1s
- ‚úÖ AI processing: 15-25s (typical file)
- ‚úÖ Total workflow: < 30s
- ‚úÖ Success rate: > 95%

### Monitoring Recommendations
1. **Queue Length**: Monitor Redis queue length
2. **Processing Time**: Track average processing time
3. **Error Rate**: Monitor failed extractions
4. **Resource Usage**: CPU/Memory during AI processing

---

## Contact & Support

ƒê·ªÉ h·ªó tr·ª£ implementation ho·∫∑c troubleshooting, ki·ªÉm tra logs t·∫°i:
- Application logs: `/logs/`
- Worker logs: Worker processing details
- Redis monitoring: Queue status v√† task progress
