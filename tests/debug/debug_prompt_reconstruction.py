#!/usr/bin/env python3
"""
Reconstruct exact prompt sent to DeepSeek from ai_extraction_service.py
"""
import sys
import json

sys.path.append("/Users/user/Code/ai-chatbot-rag")

from src.services.ai_extraction_service import AIExtractionService
from src.services.extraction_templates.template_factory import ExtractionTemplateFactory


def reconstruct_deepseek_prompt():
    """Reconstruct the exact prompt sent to DeepSeek"""

    print("üîç RECONSTRUCTING DEEPSEEK PROMPT")
    print("=" * 60)

    # Initialize services
    ai_service = AIExtractionService()
    template_factory = ExtractionTemplateFactory()

    # Test data - Fashion CSV content
    csv_text = """CSV FILE: ivy-fashion-products.csv
Total Rows: 25
Columns: product_id, product_name, category, brand, price, size, color, material, stock_quantity, description

HEADER:
product_id | product_name | category | brand | price | size | color | material | stock_quantity | description

DATA ROWS:
Row 1: FW001 | √Åo blazer n·ªØ cao c·∫•p | √Åo kho√°c | IVY Fashion | 1580000 | S|M|L|XL | ƒêen|X√°m|Be | V·∫£i wool blend | 25 | √Åo blazer n·ªØ phong c√°ch c√¥ng s·ªü, thi·∫øt k·∫ø thanh l·ªãch
Row 2: FW002 | V√°y midi hoa nh√≠ | V√°y | IVY Fashion | 890000 | S|M|L | H·ªìng|Xanh|Tr·∫Øng | Cotton | 40 | V√°y midi h·ªça ti·∫øt hoa nh√≠, ph√π h·ª£p d·∫°o ph·ªë
Row 3: FW003 | Qu·∫ßn jean skinny | Qu·∫ßn | Denim Style | 650000 | 26|27|28|29|30 | Xanh ƒë·∫≠m|Xanh nh·∫°t|ƒêen | Denim cotton | 60 | Qu·∫ßn jean skinny √¥m d√°ng, co gi√£n t·ªët
Row 4: FW004 | √Åo s∆° mi l·ª•a | √Åo | Silk Garden | 1200000 | S|M|L | Tr·∫Øng|Kem|H·ªìng ph·∫•n | L·ª•a t∆° t·∫±m | 30 | √Åo s∆° mi l·ª•a cao c·∫•p, m·ªÅm m·∫°i v√† tho√°ng m√°t
Row 5: FW005 | Ch√¢n v√°y ch·ªØ A | V√°y | Classic Line | 420000 | S|M|L|XL | ƒêen|X√°m|Navy | Polyester | 45 | Ch√¢n v√°y ch·ªØ A c∆° b·∫£n, d·ªÖ ph·ªëi ƒë·ªì
Row 6: FW006 | √Åo len c·ªï l·ªç | √Åo len | Warm Winter | 580000 | S|M|L | ƒê·ªè|Xanh|N√¢u | Len merino | 35 | √Åo len c·ªï l·ªç ·∫•m √°p, ch·∫•t li·ªáu cao c·∫•p
Row 7: FW007 | ƒê·∫ßm maxi hoa | ƒê·∫ßm | Summer Breeze | 750000 | S|M|L | Xanh l√°|V√†ng|T√≠m | Chiffon | 28 | ƒê·∫ßm maxi h·ªça ti·∫øt hoa, ph√π h·ª£p d·ª± ti·ªác
Row 8: FW008 | Qu·∫ßn t√¢y n·ªØ | Qu·∫ßn | Office Lady | 680000 | S|M|L|XL | ƒêen|X√°m|Navy | Wool blend | 50 | Qu·∫ßn t√¢y n·ªØ c√¥ng s·ªü, form d√°ng chu·∫©n
Row 9: FW009 | √Åo kho√°c cardigan | √Åo kho√°c | Cozy Time | 480000 | S|M|L | Be|X√°m|H·ªìng | Acrylic | 38 | Cardigan nh·∫π nh√†ng, ph√π h·ª£p m√πa thu
Row 10: FW010 | V√°y ng·∫Øn da | V√°y | Rock Style | 950000 | S|M|L | ƒêen|N√¢u | Da th·∫≠t | 22 | V√°y ng·∫Øn da th·∫≠t, phong c√°ch c√° t√≠nh"""

    # Metadata
    metadata = {
        "industry": "fashion",
        "original_name": "ivy-fashion-products.csv",
        "file_type": "text/csv",
    }

    target_categories = ["products"]
    company_info = None

    # Step 1: Get template
    template = template_factory.get_template_with_metadata(metadata)
    print(f"üìã Template: {template.__class__.__name__}")

    # Step 2: Build prompts exactly like in ai_extraction_service.py
    system_prompt = ai_service._build_auto_categorization_system_prompt(
        template, target_categories, company_info
    )

    user_prompt = ai_service._build_auto_categorization_user_prompt(
        template, target_categories, metadata, company_info
    )

    # Step 3: Enhanced user prompt with text content (like in _extract_with_deepseek_text)
    enhanced_user_prompt = f"""{user_prompt}

DOCUMENT CONTENT TO PROCESS:
{csv_text}

RAW DATA + JSON REQUIREMENT / Y√äU C·∫¶U RAW DATA + JSON:
For DeepSeek text processing, you must return BOTH:
1. raw_content: The original text content as processed
2. structured_data: JSON formatted according to the schema

IMPORTANT INSTRUCTIONS / H∆Ø·ªöNG D·∫™N QUAN TR·ªåNG:
1. Analyze the above text content carefully
2. Extract ALL text as raw_content (preserve original content)
3. Process and structure the data according to the JSON schema
4. Return BOTH raw content and structured data in the format specified
5. Return ONLY the JSON response, no additional text, explanations, or formatting

Expected response format:
{{
  "raw_content": "Complete original content of the file...",
  "structured_data": {{
    {', '.join([f'"{cat}": [...extracted {cat}...]' for cat in target_categories])},
    "extraction_summary": {{
      "total_items": number,
      "data_quality": "high|medium|low",
      "extraction_notes": "Any relevant notes..."
    }}
  }}
}}"""

    # Step 4: Enhanced system prompt (like in _call_deepseek)
    enhanced_system_prompt = f"""{system_prompt}

TEXT PROCESSING INSTRUCTIONS:
- Analyze the provided text content carefully
- Extract all relevant data following the JSON schema
- Process structured text formats (JSON, CSV, TXT)
- Pay attention to patterns and formatting in the content

RAW DATA + JSON REQUIREMENT / Y√äU C·∫¶U RAW DATA + JSON:
You must return BOTH:
1. raw_content: The original text content as processed
2. structured_data: JSON formatted according to the schema

Return format:
{{
  "raw_content": "The original text content being processed...",
  "structured_data": {{
    "items": [...],
    "extraction_summary": {{...}}
  }}
}}

CRITICAL JSON FORMATTING INSTRUCTIONS:
- Return ONLY valid JSON format
- Include both raw_content and structured_data sections
- Use proper JSON syntax with double quotes
- Ensure all numbers are numeric (not strings) 
- For missing values, use null instead of empty strings
- Array fields should be empty arrays [] if no data found
- Do not wrap JSON in code blocks or markdown
- Start response directly with {{ and end with }}
"""

    final_user_prompt = f"""{enhanced_user_prompt}

IMPORTANT: Return ONLY the JSON response with both raw_content and structured_data sections, no additional text, explanations, or formatting."""

    print(f"\nüìè PROMPT LENGTHS:")
    print(f"System prompt: {len(enhanced_system_prompt)} characters")
    print(f"User prompt: {len(final_user_prompt)} characters")
    print(f"Total: {len(enhanced_system_prompt) + len(final_user_prompt)} characters")

    print(f"\nüìù SYSTEM PROMPT:")
    print("=" * 40)
    print(enhanced_system_prompt)

    print(f"\nüìù USER PROMPT:")
    print("=" * 40)
    print(final_user_prompt)

    # Create messages for DeepSeek
    messages = [
        {"role": "system", "content": enhanced_system_prompt},
        {"role": "user", "content": final_user_prompt},
    ]

    print(f"\nüìä MESSAGES FOR DEEPSEEK:")
    print("=" * 40)
    print(f"Number of messages: {len(messages)}")
    for i, msg in enumerate(messages):
        print(f"Message {i+1} ({msg['role']}): {len(msg['content'])} chars")

    # Save to file for testing
    with open("deepseek_prompt_test.json", "w", encoding="utf-8") as f:
        json.dump(messages, f, indent=2, ensure_ascii=False)

    print(f"\nüíæ Saved to deepseek_prompt_test.json for testing")

    return messages


if __name__ == "__main__":
    reconstruct_deepseek_prompt()
