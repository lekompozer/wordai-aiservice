#!/usr/bin/env python3
"""
Test script for Folder-Prioritized Image Search System
Kiá»ƒm tra há»‡ thá»‘ng tÃ¬m kiáº¿m hÃ¬nh áº£nh Æ°u tiÃªn folder

This test validates the new logic:
1. Search folders first (limit 2)
2. AI Provider selects best folder
3. Search unlimited images in selected folder
4. Fallback to direct image search if no folders found
"""

import asyncio
import json
import logging
from datetime import datetime
from typing import Dict, Any, List

from src.services.admin_service import get_admin_service
from src.services.unified_chat_service import UnifiedChatService
from src.models.unified_models import UnifiedChatRequest, UserInfo, Source

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(
            f'test_folder_search_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        ),
        logging.StreamHandler(),
    ],
)

logger = logging.getLogger(__name__)


class FolderPrioritizedImageSearchTester:
    """Test class for folder-prioritized image search"""

    def __init__(self):
        self.admin_service = get_admin_service()
        self.chat_service = UnifiedChatService()
        self.test_company_id = "test_company_001"

    async def test_folder_search_logic(self) -> Dict[str, Any]:
        """Test the new folder search logic directly"""
        logger.info("ğŸ§ª Testing folder search logic...")

        test_queries = [
            "sáº£n pháº©m Ã¡o thun",
            "quáº§n jean nam",
            "giÃ y sneaker",
            "tÃºi xÃ¡ch ná»¯",
            "Ä‘á»“ng há»“ thÃ´ng minh",
        ]

        results = {}

        for query in test_queries:
            logger.info(f"\nğŸ“ Testing query: '{query}'")

            try:
                # Test with folder prioritization
                search_result = await self.admin_service.search_images_by_description(
                    company_id=self.test_company_id,
                    query=query,
                    limit=5,
                    score_threshold=0.6,
                    prefer_folders=True,
                )

                result_type = search_result.get("type", "unknown")
                data = search_result.get("data", [])

                results[query] = {
                    "result_type": result_type,
                    "count": len(data),
                    "data": data,
                }

                if result_type == "folders":
                    logger.info(f"   ğŸ—‚ï¸ Found {len(data)} folders:")
                    for folder in data:
                        logger.info(
                            f"      ğŸ“ {folder['folder_name']} (score: {folder['score']:.3f})"
                        )
                        logger.info(f"         Description: {folder['description']}")

                elif result_type == "images":
                    logger.info(f"   ğŸ–¼ï¸ Found {len(data)} images:")
                    for img in data[:3]:  # Show first 3
                        logger.info(
                            f"      ğŸ“¸ {img['description'][:50]}... (score: {img['score']:.3f})"
                        )
                        logger.info(f"         Folder: {img.get('folder_name', 'N/A')}")

                # Simulate delay between searches
                await asyncio.sleep(0.5)

            except Exception as e:
                logger.error(f"âŒ Error testing query '{query}': {e}")
                results[query] = {"error": str(e)}

        return results

    async def test_full_chat_integration(self) -> Dict[str, Any]:
        """Test the complete chat integration with image search"""
        logger.info("\nğŸ§ª Testing full chat integration...")

        test_messages = [
            "TÃ´i muá»‘n xem má»™t sá»‘ sáº£n pháº©m Ã¡o thun Ä‘áº¹p",
            "CÃ³ thá»ƒ cho tÃ´i xem hÃ¬nh áº£nh quáº§n jean khÃ´ng?",
            "Báº¡n cÃ³ thá»ƒ gá»­i cho tÃ´i má»™t sá»‘ máº«u giÃ y sneaker?",
            "Hiá»ƒn thá»‹ cho tÃ´i hÃ¬nh áº£nh tÃºi xÃ¡ch ná»¯",
        ]

        results = {}

        for i, message in enumerate(test_messages):
            logger.info(f"\nğŸ“± Testing message {i+1}: '{message}'")

            try:
                # Create chat request
                chat_request = UnifiedChatRequest(
                    message=message,
                    session_id=f"test_session_{i+1}",
                    company_id=self.test_company_id,
                    user_info=UserInfo(user_id=f"test_user_{i+1}", source=Source.WEB),
                    conversation_id=f"test_conv_{i+1}",
                    industry="fashion",
                    context={},
                )

                # Process message
                response = await self.chat_service.process_message(chat_request)

                # Extract results
                has_attachments = bool(response.attachments)
                attachment_count = (
                    len(response.attachments) if response.attachments else 0
                )

                results[f"message_{i+1}"] = {
                    "message": message,
                    "has_attachments": has_attachments,
                    "attachment_count": attachment_count,
                    "response_content": (
                        response.content[:200] + "..."
                        if len(response.content) > 200
                        else response.content
                    ),
                    "attachments": response.attachments,
                }

                logger.info(f"   âœ… Response generated")
                logger.info(f"   ğŸ“ Has attachments: {has_attachments}")
                logger.info(f"   ğŸ“¸ Attachment count: {attachment_count}")

                if response.attachments:
                    for j, attachment in enumerate(
                        response.attachments[:3]
                    ):  # Show first 3
                        method = attachment.get("metadata", {}).get(
                            "selection_method", "unknown"
                        )
                        folder = attachment.get("metadata", {}).get(
                            "folder_name", "N/A"
                        )
                        score = attachment.get("metadata", {}).get("score", 0)
                        logger.info(
                            f"      ğŸ“¸ Image {j+1}: {attachment.get('description', 'No description')[:40]}..."
                        )
                        logger.info(
                            f"         Method: {method}, Folder: {folder}, Score: {score:.3f}"
                        )

                # Simulate delay between tests
                await asyncio.sleep(1)

            except Exception as e:
                logger.error(f"âŒ Error testing message '{message}': {e}")
                results[f"message_{i+1}"] = {"error": str(e)}

        return results

    async def test_ai_folder_selection(self) -> Dict[str, Any]:
        """Test AI Provider folder selection logic"""
        logger.info("\nğŸ§ª Testing AI folder selection...")

        # Mock folder data for testing
        mock_folders = [
            {
                "folder_name": "ao_thun_nam",
                "description": "Bá»™ sÆ°u táº­p Ã¡o thun nam cao cáº¥p, nhiá»u mÃ u sáº¯c vÃ  kÃ­ch cá»¡",
                "score": 0.85,
            },
            {
                "folder_name": "ao_thun_nu",
                "description": "Ão thun ná»¯ thá»i trang, thiáº¿t káº¿ tráº» trung vÃ  nÄƒng Ä‘á»™ng",
                "score": 0.82,
            },
        ]

        test_query = "Ã¡o thun nam mÃ u Ä‘en"

        # Test folder selection prompt
        folder_selection_prompt = f"""
Dá»±a trÃªn truy váº¥n cá»§a ngÆ°á»i dÃ¹ng: "{test_query}"

CÃ¡c thÆ° má»¥c hÃ¬nh áº£nh cÃ³ liÃªn quan:
{chr(10).join([f"- {folder['folder_name']}: {folder['description']} (score: {folder['score']:.3f})" for folder in mock_folders])}

HÃ£y chá»n 1 thÆ° má»¥c phÃ¹ há»£p nháº¥t dá»±a trÃªn:
1. TÃªn thÆ° má»¥c
2. MÃ´ táº£ thÆ° má»¥c  
3. Äá»™ liÃªn quan vá»›i truy váº¥n

Chá»‰ tráº£ lá»i tÃªn thÆ° má»¥c Ä‘Æ°á»£c chá»n, khÃ´ng giáº£i thÃ­ch thÃªm.
"""

        try:
            # Test AI selection (if AI manager is available)
            if hasattr(self.chat_service, "ai_manager"):
                selected_folder = await self.chat_service.ai_manager.generate_response(
                    prompt=folder_selection_prompt,
                    model_type="chatgpt",
                    temperature=0.3,
                    max_tokens=50,
                )

                logger.info(f"   ğŸ¤– AI selected folder: '{selected_folder.strip()}'")

                return {
                    "query": test_query,
                    "available_folders": mock_folders,
                    "ai_selection": selected_folder.strip(),
                    "prompt_used": folder_selection_prompt,
                }
            else:
                logger.warning(
                    "   âš ï¸ AI Manager not available, skipping AI selection test"
                )
                return {"error": "AI Manager not available"}

        except Exception as e:
            logger.error(f"âŒ Error testing AI folder selection: {e}")
            return {"error": str(e)}

    async def run_all_tests(self) -> Dict[str, Any]:
        """Run all tests and return comprehensive results"""
        logger.info("ğŸš€ Starting Folder-Prioritized Image Search Tests")
        logger.info("=" * 60)

        test_results = {
            "test_start_time": datetime.now().isoformat(),
            "test_company_id": self.test_company_id,
            "tests": {},
        }

        # Test 1: Folder search logic
        logger.info("\n1ï¸âƒ£ TESTING FOLDER SEARCH LOGIC")
        test_results["tests"]["folder_search"] = await self.test_folder_search_logic()

        # Test 2: Full chat integration
        logger.info("\n2ï¸âƒ£ TESTING FULL CHAT INTEGRATION")
        test_results["tests"][
            "chat_integration"
        ] = await self.test_full_chat_integration()

        # Test 3: AI folder selection
        logger.info("\n3ï¸âƒ£ TESTING AI FOLDER SELECTION")
        test_results["tests"]["ai_selection"] = await self.test_ai_folder_selection()

        test_results["test_end_time"] = datetime.now().isoformat()

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ Test Summary:")
        logger.info(
            f"   âœ… Folder search tests: {len([k for k, v in test_results['tests']['folder_search'].items() if 'error' not in v])}"
        )
        logger.info(
            f"   âœ… Chat integration tests: {len([k for k, v in test_results['tests']['chat_integration'].items() if 'error' not in v])}"
        )
        logger.info(
            f"   âœ… AI selection test: {'âœ… Passed' if 'error' not in test_results['tests']['ai_selection'] else 'âŒ Failed'}"
        )

        return test_results


async def main():
    """Main test execution function"""
    print("ğŸ§ª Folder-Prioritized Image Search System Test")
    print("=" * 60)

    tester = FolderPrioritizedImageSearchTester()

    try:
        results = await tester.run_all_tests()

        # Save results to file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"test_results_folder_search_{timestamp}.json"

        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ“„ Test results saved to: {results_file}")

        # Print summary
        print("\nğŸ“Š QUICK SUMMARY:")
        for test_name, test_data in results["tests"].items():
            if isinstance(test_data, dict):
                if test_name == "folder_search":
                    success_count = len(
                        [k for k, v in test_data.items() if "error" not in v]
                    )
                    print(f"   {test_name}: {success_count} successful queries")
                elif test_name == "chat_integration":
                    success_count = len(
                        [k for k, v in test_data.items() if "error" not in v]
                    )
                    print(f"   {test_name}: {success_count} successful chats")
                elif test_name == "ai_selection":
                    status = "âœ… Success" if "error" not in test_data else "âŒ Failed"
                    print(f"   {test_name}: {status}")

    except Exception as e:
        logger.error(f"âŒ Test execution failed: {e}")
        print(f"âŒ Test failed: {e}")


if __name__ == "__main__":
    asyncio.run(main())
