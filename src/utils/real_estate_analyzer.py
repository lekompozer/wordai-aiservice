import re
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from src.utils.logger import setup_logger

logger = setup_logger()

@dataclass
class LocationData:
    """Location information structure"""
    address: Optional[str] = None
    street: Optional[str] = None
    ward: Optional[str] = None
    district: Optional[str] = None
    city: Optional[str] = None
    area: Optional[str] = None
    province: Optional[str] = None
    full: List[str] = None

    def __post_init__(self):
        if self.full is None:
            self.full = []

@dataclass
class RealEstateAnalysis:
    """Complete analysis result for real estate query"""
    has_price_intent: bool = False
    has_question_pattern: bool = False
    property_type: Optional[str] = None
    project_name: Optional[str] = None
    dientich: Optional[str] = None  # ‚úÖ TH√äM M·ªöI: di·ªán t√≠ch
    bedrooms: Optional[str] = None
    location: LocationData = None
    search_query: Optional[str] = None
    confidence: float = 0.0
    original_question: str = ""

    def __post_init__(self):
        if self.location is None:
            self.location = LocationData()

class RealEstateQueryAnalyzer:
    """
    üè† Advanced Real Estate Query Analyzer - Python version
    Chuy·ªÉn ƒë·ªïi ch√≠nh x√°c t·ª´ JavaScript sang Python
    """
    
    def __init__(self):
        logger.info("üè† Initializing Real Estate Query Analyzer...")

    def analyze_real_estate_query(self, question: str) -> RealEstateAnalysis:
        """
        üîç Analyze real estate question - Main function
        """
        # ‚úÖ Initialize analysis object
        analysis = RealEstateAnalysis(
            original_question=question,
            location=LocationData()
        )

        if not question or not isinstance(question, str):
            return analysis

        # ‚úÖ Log c√¢u h·ªèi g·ªëc ƒë·∫ßy ƒë·ªß
        logger.info("=" * 60)
        logger.info(f"[REAL ESTATE ANALYZER] ORIGINAL QUESTION (FULL): \"{question}\"")
        logger.info(f"[REAL ESTATE ANALYZER] Question length: {len(question)} characters")
        logger.info("=" * 60)

        # ‚úÖ Normalize question
        normalized_question = self._normalize_question(question)
        logger.info(f"[REAL ESTATE ANALYZER] NORMALIZED QUESTION: \"{normalized_question}\"")

        # ‚úÖ 1. Ki·ªÉm tra √Ω ƒë·ªãnh v·ªÅ gi√° (price intent) - M·ªû R·ªòNG
        self._detect_price_intent(normalized_question, analysis)

        # ‚úÖ 2. Ki·ªÉm tra c√°c pattern c√¢u h·ªèi - M·ªöI TH√äM
        self._detect_question_patterns(normalized_question, analysis)

        # ‚úÖ 3. Tr√≠ch xu·∫•t lo·∫°i b·∫•t ƒë·ªông s·∫£n - M·ªû R·ªòNG
        self._extract_property_type(normalized_question, analysis)

        # ‚úÖ 4. Tr√≠ch xu·∫•t s·ªë ph√≤ng ng·ªß
        self._extract_bedrooms(normalized_question, analysis)

        # ‚úÖ 5. Tr√≠ch xu·∫•t t√™n d·ª± √°n b·∫•t ƒë·ªông s·∫£n - M·ªöI TH√äM
        self._extract_project_name(normalized_question, analysis)

        # ‚úÖ 6. X·ª≠ l√Ω 63 t·ªânh th√†nh Vi·ªát Nam - HO√ÄN CH·ªàNH
        self._extract_province(normalized_question, analysis)

        # ‚úÖ 7. Tr√≠ch xu·∫•t qu·∫≠n/huy·ªán (CH√çNH X√ÅC H∆†N)
        self._extract_district(normalized_question, analysis)

        # ‚úÖ 8. Tr√≠ch xu·∫•t t√™n ƒë∆∞·ªùng - M·ªöI TH√äM
        self._extract_street(normalized_question, analysis)

        # ‚úÖ 9. Tr√≠ch xu·∫•t di·ªán t√≠ch
        self._extract_area_size(normalized_question, analysis)

        # ‚úÖ 10. Tr√≠ch xu·∫•t khu v·ª±c/qu·∫≠n huy·ªán - CH√çNH X√ÅC H∆†N
        self._extract_area_info(normalized_question, analysis)

        # ‚úÖ 11. T·∫°o search query S·∫†CH S·∫º H∆†N
        self._generate_search_query(analysis)

        # ‚úÖ Log k·∫øt qu·∫£ cu·ªëi c√πng - C·∫¨P NH·∫¨T
        self._log_final_results(analysis)

        return analysis

    def _normalize_question(self, question: str) -> str:
        """Normalize question text"""
        normalized = question.lower()
        # Replace non-word characters except Vietnamese and question marks
        normalized = re.sub(r'[^\w\s√Ä-·ªπ\?]', ' ', normalized)
        # Replace multiple spaces with single space
        normalized = re.sub(r'\s+', ' ', normalized)
        return normalized.strip()

    def _detect_price_intent(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 1. Ki·ªÉm tra √Ω ƒë·ªãnh v·ªÅ gi√° (price intent) - M·ªû R·ªòNG"""
        price_keywords = [
            'ƒë·ªãnh gi√°', 'gi√°', 'gi√° c·∫£', 'bao nhi√™u ti·ªÅn', 'chi ph√≠', 'cost',
            'price', 'gi√° tr·ªã', 'th·ªã gi√°', 'gi√° th·ªã tr∆∞·ªùng', '∆∞·ªõc t√≠nh',
            'tham kh·∫£o gi√°', 'b√°o gi√°', 'pricing', 'valuation', 'ƒë·ªãnh gi√°',
            'gi√° b√°n', 'gi√° mua', 'bao nhi√™u', 'gi√° hi·ªán t·∫°i', 'gi√° m·ªõi nh·∫•t'
        ]

        for keyword in price_keywords:
            if keyword in normalized_question:
                analysis.has_price_intent = True
                analysis.confidence += 0.3
                logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Price intent detected: \"{keyword}\"")
                break

    def _detect_question_patterns(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 2. Ki·ªÉm tra c√°c pattern c√¢u h·ªèi - M·ªöI TH√äM"""
        question_patterns = [
            (r'bao nhi√™u', re.IGNORECASE),
            (r'th·∫ø n√†o', re.IGNORECASE),
            (r'nh∆∞ n√†o', re.IGNORECASE),
            (r'ra sao', re.IGNORECASE),
            (r'\?', 0),
            (r'c√≥ ƒë·∫Øt kh√¥ng', re.IGNORECASE),
            (r'c√≥ r·∫ª kh√¥ng', re.IGNORECASE),
            (r'kho·∫£ng', re.IGNORECASE),
            (r't·∫ßm', re.IGNORECASE),
            (r't·ª´.*ƒë·∫øn', re.IGNORECASE)
        ]

        for pattern, flags in question_patterns:
            if re.search(pattern, normalized_question, flags):
                analysis.has_question_pattern = True
                analysis.confidence += 0.2
                logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Question pattern detected: {pattern}")
                break

    def _extract_property_type(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 3. Tr√≠ch xu·∫•t lo·∫°i b·∫•t ƒë·ªông s·∫£n - M·ªû R·ªòNG"""
        property_types = [
            {'keywords': ['b·∫•t ƒë·ªông s·∫£n', 'real estate', 'property'], 'type': 'b·∫•t ƒë·ªông s·∫£n'},
            {'keywords': ['nh√† ƒë·∫•t', 'ƒë·∫•t nh√†'], 'type': 'nh√† ƒë·∫•t'},
            {'keywords': ['cƒÉn h·ªô', 'apartment', 'condo'], 'type': 'cƒÉn h·ªô'},
            {'keywords': ['chung c∆∞', 'condominiums'], 'type': 'chung c∆∞'},
            {'keywords': ['nh√† ri√™ng', 'nh√† ph·ªë', 'townhouse'], 'type': 'nh√† ri√™ng'},
            {'keywords': ['bi·ªát th·ª±', 'villa'], 'type': 'bi·ªát th·ª±'},
            {'keywords': ['ƒë·∫•t n·ªÅn', 'l√¥ ƒë·∫•t', 'm·∫£nh ƒë·∫•t', 'land'], 'type': 'ƒë·∫•t n·ªÅn'},
            {'keywords': ['shophouse', 'nh√† m·∫∑t ti·ªÅn'], 'type': 'shophouse'},
            {'keywords': ['vƒÉn ph√≤ng', 'office'], 'type': 'vƒÉn ph√≤ng'},
            {'keywords': ['kho x∆∞·ªüng', 'warehouse'], 'type': 'kho x∆∞·ªüng'},
            {'keywords': ['penthouse'], 'type': 'penthouse'},
            {'keywords': ['duplex'], 'type': 'duplex'},
            {'keywords': ['studio'], 'type': 'studio'}
        ]

        for property_type in property_types:
            for keyword in property_type['keywords']:
                if keyword in normalized_question:
                    analysis.property_type = property_type['type']
                    analysis.confidence += 0.25
                    logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Property type detected: \"{property_type['type']}\" (keyword: \"{keyword}\")")
                    return

    def _extract_bedrooms(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 4. Tr√≠ch xu·∫•t s·ªë ph√≤ng ng·ªß"""
        bedroom_patterns = [
            r'(\d+)\s*pn',           # 2PN, 3PN
            r'(\d+)\s*ph√≤ng ng·ªß',    # 2 ph√≤ng ng·ªß
            r'(\d+)\s*bedroom'       # 2 bedroom
        ]

        for pattern in bedroom_patterns:
            match = re.search(pattern, normalized_question, re.IGNORECASE)
            if match:
                analysis.bedrooms = f"{match.group(1)}PN"
                analysis.confidence += 0.1
                logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Bedrooms: \"{analysis.bedrooms}\"")
                break

    def _extract_project_name(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 5. Tr√≠ch xu·∫•t t√™n d·ª± √°n b·∫•t ƒë·ªông s·∫£n - FIXED: Better project detection"""
        project_patterns = [
            # ‚úÖ FIXED: Generic pattern to catch project names after property type (3 words max)
            r'(?:cƒÉn h·ªô|chung c∆∞|nh√† ph·ªë|bi·ªát th·ª±|ƒë·∫•t n·ªÅn)\s+([A-Za-z][A-Za-z0-9\s]{2,30}?)(?:\s+\d+pn|\s+\d+m|\s+t·∫°i|\s+gi√°|$)',
            
            # ‚úÖ FIXED: Specific patterns for known developers (capture full names)
            r'(vinhomes\s+grand\s+park)',           # Vinhomes Grand Park
            r'(vinhomes\s+central\s+park)',         # Vinhomes Central Park
            r'(vinhomes\s+golden\s+river)',         # Vinhomes Golden River
            r'(vinhomes\s+smart\s+city)',           # Vinhomes Smart City
            r'(vinhomes\s+ocean\s+park)',           # Vinhomes Ocean Park
            r'(vinhomes\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)', # Generic Vinhomes projects (1-2 words)
            
            r'(masteri\s+th·∫£o\s+ƒëi·ªÅn)',             # Masteri Th·∫£o ƒêi·ªÅn
            r'(masteri\s+an\s+ph√∫)',                # Masteri An Ph√∫
            r'(masteri\s+millennium)',              # Masteri Millennium
            r'(masteri\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)', # Generic Masteri projects
            
            # ‚úÖ FIXED: Bcons projects - capture full name
            r'(bcons\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)',              # Bcons Solary, Bcons Garden, etc.
            
            r'(saigon\s+pearl)',
            r'(landmark\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)',
            r'(eco\s+green\s+saigon)',
            r'(eco\s+green)',
            r'(golden\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)',
            r'(sunrise\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)',
            r'(feliz\s+en\s+vista)',
            r'(the\s+manor)',
            r'(estella\s+heights)',
            r'(diamond\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)',
            r'(imperia\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)',
            r'(kingdom\s+[^,.\n\s]+(?:\s+[^,.\n\s]+)?)',
            
            # Pattern chung cho d·ª± √°n
            r'd·ª± √°n\s+([^,.\n]{3,30})',
            r'khu ƒë√¥ th·ªã\s+([^,.\n]{3,30})',
            r'khu d√¢n c∆∞\s+([^,.\n]{3,30})'
        ]

        for pattern in project_patterns:
            match = re.search(pattern, normalized_question, re.IGNORECASE)
            if match:
                # ‚úÖ FIXED: Get the full match for developer patterns, or captured group for generic patterns
                if pattern.startswith('(?:cƒÉn h·ªô|chung c∆∞'):
                    # Generic pattern after property type
                    project_name = match.group(1).strip()
                    # Clean up common trailing words
                    project_name = re.sub(r'\s+(t·∫°i|gi√°|·ªü|thu·ªôc).*$', '', project_name, flags=re.IGNORECASE)
                    project_name = re.sub(r'\s+\d+.*$', '', project_name)  # Remove numbers at end
                elif pattern.startswith('d·ª± √°n|khu ƒë√¥ th·ªã|khu d√¢n c∆∞'):
                    # Pattern with prefix
                    project_name = match.group(1).strip()
                else:
                    # Developer-specific patterns - take full match
                    project_name = match.group(1).strip() if match.groups() else match.group(0).strip()
                
                # ‚úÖ Clean up common words from project name
                project_name = re.sub(r'\b(d·ª± √°n|khu ƒë√¥ th·ªã|khu d√¢n c∆∞)\s+', '', project_name, flags=re.IGNORECASE)
                project_name = project_name.strip()
                
                # ‚úÖ FIXED: Limit to 3 words max, but allow full developer + project name
                words = project_name.split()
                if len(words) > 3:
                    project_name = ' '.join(words[:3])
                
                if project_name and len(project_name) > 1:
                    analysis.project_name = project_name
                    analysis.confidence += 0.15
                    logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Project name detected: \"{analysis.project_name}\"")
                    break

    def _extract_province(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 6. X·ª≠ l√Ω 63 t·ªânh th√†nh Vi·ªát Nam - HO√ÄN CH·ªàNH"""
        vietnam_provinces = [
            # Th√†nh ph·ªë trung ∆∞∆°ng
            'h·ªì ch√≠ minh', 'tp h·ªì ch√≠ minh', 's√†i g√≤n', 'ho chi minh city', 'hcmc', 'tphcm',
            'h√† n·ªôi', 'hanoi', 'th·ªß ƒë√¥',
            'ƒë√† n·∫µng', 'da nang', 'danang',
            'h·∫£i ph√≤ng', 'hai phong',
            'c·∫ßn th∆°', 'can tho',

            # ‚úÖ NEW: Add B√¨nh D∆∞∆°ng v√† c√°c th√†nh ph·ªë
            'b√¨nh d∆∞∆°ng', 'binh duong', 'th·ªß d·∫ßu m·ªôt', 'thu dau mot',
            'dƒ© an', 'di an', 'tp dƒ© an', 'tp di an', 'th√†nh ph·ªë dƒ© an',
            'thu·∫≠n an', 'thuan an',
            't√¢n uy√™n', 'tan uyen',
            'b·∫øn c√°t', 'ben cat',
            
            # T·ªânh mi·ªÅn B·∫Øc
            'h√† giang', 'cao b·∫±ng', 'l√†o cai', 'ƒëi·ªán bi√™n', 'lai ch√¢u', 's∆°n la',
            'y√™n b√°i', 'ho√† b√¨nh', 'th√°i nguy√™n', 'l·∫°ng s∆°n', 'qu·∫£ng ninh',
            'b·∫Øc giang', 'ph√∫ th·ªç', 'vƒ©nh ph√∫c', 'b·∫Øc ninh', 'h·∫£i d∆∞∆°ng',
            'h∆∞ng y√™n', 'th√°i b√¨nh', 'h√† nam', 'nam ƒë·ªãnh', 'ninh b√¨nh',
            
            # T·ªânh mi·ªÅn Trung
            'thanh h√≥a', 'ngh·ªá an', 'h√† tƒ©nh', 'qu·∫£ng b√¨nh', 'qu·∫£ng tr·ªã',
            'th·ª´a thi√™n hu·∫ø', 'qu·∫£ng nam', 'qu·∫£ng ng√£i', 'b√¨nh ƒë·ªãnh',
            'ph√∫ y√™n', 'kh√°nh h√≤a', 'ninh thu·∫≠n', 'b√¨nh thu·∫≠n',
            
            # T·ªânh mi·ªÅn Nam
            'kon tum', 'gia lai', 'ƒë·∫Øk l·∫Øk', 'ƒë·∫Øk n√¥ng', 'l√¢m ƒë·ªìng',
            'b√¨nh ph∆∞·ªõc', 't√¢y ninh', 'b√¨nh d∆∞∆°ng', 'ƒë·ªìng nai', 'b√† r·ªãa v≈©ng t√†u',
            'long an', 'ti·ªÅn giang', 'b·∫øn tre', 'tr√† vinh', 'vƒ©nh long',
            'ƒë·ªìng th√°p', 'an giang', 'ki√™n giang', 'h·∫≠u giang', 's√≥c trƒÉng',
            'b·∫°c li√™u', 'c√† mau',
            
            # Th√™m c√°c c√°ch g·ªçi kh√°c
            'v≈©ng t√†u', 'vung tau', 'nha trang', 'hu·∫ø', 'hue',
            'bi√™n h√≤a', 'bien hoa', 'th·ªß d·∫ßu m·ªôt', 'thu dau mot',
            'long xuy√™n', 'r·∫°ch gi√°', 'c√† mau', 'b·∫°c li√™u'
        ]

        for province in vietnam_provinces:
            if province in normalized_question:
                analysis.location.province = province
                analysis.confidence += 0.2
                logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Province/City detected: \"{province}\"")
                break

    def _extract_district(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 7. Tr√≠ch xu·∫•t qu·∫≠n/huy·ªán (CH√çNH X√ÅC H∆†N)"""
        district_pattern = r'qu·∫≠n\s+(\d+|[a-zA-Z√Ä-·ªπ\s]+)|huy·ªán\s+([^,.\n\s]+)'
        district_match = re.search(district_pattern, normalized_question, re.IGNORECASE)
        if district_match:
            district_name = (district_match.group(1) or district_match.group(2)).strip()
            analysis.location.district = district_name
            analysis.confidence += 0.15
            logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ District: \"{district_name}\"")

    def _extract_street(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 8. Tr√≠ch xu·∫•t t√™n ƒë∆∞·ªùng - FIXED: capture full street names"""
        street_patterns = [
            r'ƒë∆∞·ªùng\s+([^,.\n]+?)(?:\s+(?:qu·∫≠n|huy·ªán|ph∆∞·ªùng|x√£|tp|th√†nh ph·ªë|t·ªânh)|$)',
            r'ph·ªë\s+([^,.\n]+?)(?:\s+(?:qu·∫≠n|huy·ªán|ph∆∞·ªùng|x√£|tp|th√†nh ph·ªë|t·ªânh)|$)',
            r'street\s+([^,.\n]+?)(?:\s+(?:district|ward|city|province)|$)',
            r'road\s+([^,.\n]+?)(?:\s+(?:district|ward|city|province)|$)'
        ]

        for pattern in street_patterns:
            match = re.search(pattern, normalized_question, re.IGNORECASE)
            if match:
                # ‚úÖ FIXED: Extract street name only, without location suffix
                street_name = match.group(1).strip()
                
                # ‚úÖ Clean up the street name
                street_name = re.sub(r'\s+', ' ', street_name)  # Remove extra spaces
                
                analysis.location.street = f"ƒë∆∞·ªùng {street_name}" if not street_name.startswith(('ƒë∆∞·ªùng', 'ph·ªë')) else street_name
                analysis.location.full.append(analysis.location.street)
                analysis.confidence += 0.1
                logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Street: \"{analysis.location.street}\"")
                break

    def _extract_area_size(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 9. Tr√≠ch xu·∫•t di·ªán t√≠ch"""
        dientich_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:m2|m¬≤|m√©t vu√¥ng)',
            r'(\d+(?:\.\d+)?)\s*x\s*(\d+(?:\.\d+)?)',
            r'dt\s*:?\s*(\d+(?:\.\d+)?)'
        ]
        
        for pattern in dientich_patterns:
            match = re.search(pattern, normalized_question, re.IGNORECASE)
            if match:
                if 'x' in pattern:
                    # Tr∆∞·ªùng h·ª£p "5x20" -> t√≠nh di·ªán t√≠ch
                    width = float(match.group(1))
                    length = float(match.group(2))
                    area_calculated = width * length
                    analysis.dientich = f"{area_calculated}m¬≤"
                    logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Area (calculated): {analysis.dientich}")
                else:
                    analysis.dientich = f"{match.group(1)}m¬≤"
                    logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Area: {analysis.dientich}")
                analysis.confidence += 0.15
                break

    def _extract_area_info(self, normalized_question: str, analysis: RealEstateAnalysis):
        """‚úÖ 10. Tr√≠ch xu·∫•t khu v·ª±c/qu·∫≠n huy·ªán - CH√çNH X√ÅC H∆†N"""
        area_patterns = [
            (r'khu v·ª±c\s+([^,.\n]+)', 'area'),
            (r'qu·∫≠n\s+(\d+|[a-zA-Z√Ä-·ªπ\s]+)', 'district'),
            (r'huy·ªán\s+([^,.\n\s]+)', 'district'),
            (r'th·ªã x√£\s+([^,.\n\s]+)', 'district'),
            (r'(th·ªß ƒë·ª©c|thu duc)', 'area')  # ƒê·∫∑c bi·ªát cho Th·ªß ƒê·ª©c
        ]

        for pattern, location_type in area_patterns:
            match = re.search(pattern, normalized_question, re.IGNORECASE)
            if match:
                matched_text = match.group(0).strip()
                
                if location_type == 'area':
                    if 'khu v·ª±c' in pattern:
                        analysis.location.area = match.group(1).strip()
                        logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Area: \"{analysis.location.area}\"")
                    elif 'th·ªß ƒë·ª©c' in pattern.lower():
                        analysis.location.area = 'Th·ªß ƒê·ª©c'
                        logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ Area: \"Th·ªß ƒê·ª©c\"")
                elif location_type == 'district':
                    if 'qu·∫≠n' in pattern:
                        district_name = match.group(1).strip()
                        analysis.location.district = district_name
                        logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ District: qu·∫≠n {district_name}")
                    else:
                        district_name = match.group(1).strip()
                        analysis.location.district = district_name
                        logger.info(f"[REAL ESTATE ANALYZER] ‚úÖ District: \"{matched_text}\"")
                
                analysis.location.full.append(matched_text)
                analysis.confidence += 0.15

    def _generate_search_query(self, analysis: RealEstateAnalysis):
        """‚úÖ 11. T·∫°o search query S·∫†CH S·∫º H∆†N - FIXED: Include project name properly"""
        if (analysis.has_price_intent or analysis.has_question_pattern or 
            analysis.property_type or analysis.location.province):
            
            query_parts = []
            
            # Th√™m t·ª´ kh√≥a gi√°
            if analysis.has_price_intent or analysis.has_question_pattern:
                query_parts.append('gi√°')
            
            # Th√™m lo·∫°i b·∫•t ƒë·ªông s·∫£n
            if analysis.property_type:
                query_parts.append(analysis.property_type)
            
            # ‚úÖ FIXED: Th√™m t√™n d·ª± √°n ngay sau lo·∫°i BƒêS
            if analysis.project_name:
                query_parts.append(analysis.project_name)
            
            # Th√™m s·ªë ph√≤ng ng·ªß
            if analysis.bedrooms:
                query_parts.append(analysis.bedrooms)
            
            # Th√™m di·ªán t√≠ch
            if analysis.dientich:
                query_parts.append(analysis.dientich)
            
            # ‚úÖ FIXED: Only add street name without district/province
            if analysis.location.street:
                street_clean = analysis.location.street
                # Remove common location words that might duplicate with province/district
                street_clean = re.sub(r'\b(qu·∫≠n|huy·ªán|th√†nh ph·ªë|tp|t·ªânh)\s+\w+', '', street_clean, flags=re.IGNORECASE)
                street_clean = street_clean.strip()
                if street_clean:
                    query_parts.append(street_clean)
            
            # ‚úÖ FIXED: Add district only if not already in street
            if analysis.location.district:
                district_text = f"qu·∫≠n {analysis.location.district}" if analysis.location.district.isdigit() else analysis.location.district
                query_parts.append(district_text)
            
            # ‚úÖ FIXED: Add area only if different from district
            if analysis.location.area and analysis.location.area != analysis.location.district:
                query_parts.append(analysis.location.area)
            
            # ‚úÖ FIXED: Add province, but avoid duplication
            if analysis.location.province:
                province_clean = analysis.location.province
                # Don't add if already mentioned in street or area
                if not any(province_clean.lower() in part.lower() for part in query_parts if part):
                    query_parts.append(province_clean)
            
            # T·ª´ kh√≥a nƒÉm
            query_parts.append('2025')
            
            # ‚úÖ FIXED: Advanced deduplication
            unique_parts = []
            seen_words = set()
            
            for part in query_parts:
                if part:
                    part_clean = part.strip().lower()
                    # Check if this part contains words we've already seen
                    part_words = set(re.findall(r'\w+', part_clean))
                    
                    # Only add if it doesn't significantly overlap with existing words
                    if not (part_words & seen_words) or len(part_words - seen_words) > 0:
                        unique_parts.append(part)
                        seen_words.update(part_words)
            
            # ‚úÖ Join and limit length
            analysis.search_query = ' '.join(unique_parts).strip()[:100]
            
            # ‚úÖ Final cleanup - remove common duplicated words
            query_words = analysis.search_query.split()
            final_words = []
            seen_normalized = set()
            
            for word in query_words:
                word_normalized = word.lower().strip()
                if word_normalized not in seen_normalized:
                    final_words.append(word)
                    seen_normalized.add(word_normalized)
            
            analysis.search_query = ' '.join(final_words)

    def _log_final_results(self, analysis: RealEstateAnalysis):
        """‚úÖ Log k·∫øt qu·∫£ cu·ªëi c√πng - C·∫¨P NH·∫¨T"""
        logger.info("=" * 60)
        logger.info("[REAL ESTATE ANALYZER] FINAL ANALYSIS RESULT:")
        logger.info(f"[REAL ESTATE ANALYZER] - Has Price Intent: {analysis.has_price_intent}")
        logger.info(f"[REAL ESTATE ANALYZER] - Has Question Pattern: {analysis.has_question_pattern}")
        logger.info(f"[REAL ESTATE ANALYZER] - Property Type: {analysis.property_type or 'none'}")
        logger.info(f"[REAL ESTATE ANALYZER] - Project Name: {analysis.project_name or 'none'}")
        logger.info(f"[REAL ESTATE ANALYZER] - Bedrooms: {analysis.bedrooms or 'none'}")  # ‚úÖ M·ªöI
        logger.info(f"[REAL ESTATE ANALYZER] - Area Size: {analysis.dientich or 'none'}")
        logger.info(f"[REAL ESTATE ANALYZER] - Location Street: {analysis.location.street or 'none'}")  # ‚úÖ M·ªöI
        logger.info(f"[REAL ESTATE ANALYZER] - Location Area: {analysis.location.area or 'none'}")  # ‚úÖ M·ªöI
        logger.info(f"[REAL ESTATE ANALYZER] - Location Province: {analysis.location.province or 'none'}")
        logger.info(f"[REAL ESTATE ANALYZER] - Location District: {analysis.location.district or 'none'}")
        logger.info(f"[REAL ESTATE ANALYZER] - All Locations: [{', '.join(analysis.location.full)}]")
        logger.info(f"[REAL ESTATE ANALYZER] - Search Query: \"{analysis.search_query or 'none'}\"")
        logger.info(f"[REAL ESTATE ANALYZER] - Confidence Score: {round(analysis.confidence * 100)}%")
        logger.info("=" * 60)

# ‚úÖ Global instance
real_estate_analyzer = RealEstateQueryAnalyzer()

# ‚úÖ Convenience function
def analyze_real_estate_query(question: str) -> RealEstateAnalysis:
    """
    üîç Analyze real estate query - Convenience function
    """
    return real_estate_analyzer.analyze_real_estate_query(question)

# ‚úÖ Export function for backward compatibility
def get_analysis_dict(question: str) -> Dict[str, Any]:
    """
    üìä Get analysis result as dictionary (for API responses)
    """
    analysis = analyze_real_estate_query(question)
    result = asdict(analysis)
    # Convert LocationData to dict manually if needed
    if hasattr(result['location'], '__dict__'):
        result['location'] = asdict(result['location'])
    return result