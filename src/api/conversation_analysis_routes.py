"""
Conversation Analysis API Routes
API routes cho ph√¢n t√≠ch cu·ªôc tr√≤ chuy·ªán v√† remarketing insights
"""

import json
import logging
from fastapi import APIRouter, HTTPException, Request, Header
from typing import Dict, Any, Optional, List
from datetime import datetime

from src.services.unified_chat_service import unified_chat_service

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()


@router.post("/api/conversation/analyze")
async def analyze_conversation_deep(
    request: Dict[str, Any],
    http_request: Request,
    x_company_id: Optional[str] = Header(
        None, description="Company ID for frontend access"
    ),
):
    """
    Deep conversation analysis for remarketing and business insights using Google Gemini
    Ph√¢n t√≠ch chuy√™n s√¢u cu·ªôc tr√≤ chuy·ªán cho remarketing v√† th√¥ng tin kinh doanh s·ª≠ d·ª•ng Google Gemini
    """
    try:
        # Extract parameters
        session_id = request.get("session_id")
        conversation_id = request.get("conversation_id")
        company_id = x_company_id or request.get("company_id")

        if not company_id:
            raise HTTPException(
                status_code=400,
                detail="Company ID required. Include X-Company-Id header or company_id in request body.",
            )

        if not session_id and not conversation_id:
            raise HTTPException(
                status_code=400,
                detail="Either session_id or conversation_id is required",
            )

        # Get client IP for logging
        client_ip = http_request.client.host
        logger.info(f"üîç [CONVERSATION_ANALYSIS] Request from {client_ip}")
        logger.info(
            f"   Company: {company_id} | Session: {session_id} | Conversation: {conversation_id}"
        )

        # Get conversation history
        if session_id:
            conversation_history = unified_chat_service._get_conversation_history(
                session_id
            )
            conversation_stats = unified_chat_service.get_conversation_stats(session_id)
        else:
            # In production, you would fetch by conversation_id from database
            conversation_history = []
            conversation_stats = {}

        if not conversation_history:
            return {
                "error": "No conversation data found",
                "session_id": session_id,
                "conversation_id": conversation_id,
            }

        # Perform deep analysis using Google Gemini
        analysis_result = await _perform_deep_conversation_analysis_with_gemini(
            conversation_history=conversation_history,
            company_id=company_id,
            conversation_stats=conversation_stats,
        )

        logger.info(f"‚úÖ [CONVERSATION_ANALYSIS] Analysis completed")

        return {
            "session_id": session_id,
            "conversation_id": conversation_id,
            "company_id": company_id,
            "analysis": analysis_result,
            "conversation_stats": conversation_stats,
            "analyzed_at": datetime.now().isoformat(),
            "ai_provider": "google_gemini",
        }

    except Exception as e:
        logger.error(f"‚ùå [CONVERSATION_ANALYSIS] Error: {e}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Analysis failed",
                "message": str(e),
                "session_id": request.get("session_id"),
                "conversation_id": request.get("conversation_id"),
            },
        )


@router.get("/api/conversation/{conversation_id}/summary")
async def get_conversation_summary(
    conversation_id: str, company_id: Optional[str] = Header(None, alias="X-Company-Id")
):
    """
    Get quick conversation summary without deep analysis
    L·∫•y t√≥m t·∫Øt nhanh cu·ªôc tr√≤ chuy·ªán m√† kh√¥ng c·∫ßn ph√¢n t√≠ch s√¢u
    """
    try:
        if not company_id:
            raise HTTPException(status_code=400, detail="Company ID required")

        logger.info(
            f"üìä [CONVERSATION_SUMMARY] Getting summary for conversation {conversation_id}"
        )

        # Try to find session by conversation_id
        session_data = None
        conversation_history = []
        session_id = None

        # Search through sessions to find matching conversation
        for sid, conv_data in unified_chat_service.sessions.items():
            if conv_data.get("conversation_id") == conversation_id:
                session_data = conv_data
                session_id = sid
                conversation_history = unified_chat_service._get_conversation_history(
                    sid
                )
                break

        if not session_data:
            # Try direct session lookup if conversation_id is actually session_id
            if conversation_id in unified_chat_service.sessions:
                session_data = unified_chat_service.sessions[conversation_id]
                session_id = conversation_id
                conversation_history = unified_chat_service._get_conversation_history(
                    conversation_id
                )

        if not session_data:
            raise HTTPException(status_code=404, detail="Conversation not found")

        # Create quick summary
        user_message_count = len(
            [msg for msg in conversation_history if getattr(msg, "role", "") == "user"]
        )
        ai_message_count = len(
            [
                msg
                for msg in conversation_history
                if getattr(msg, "role", "") == "assistant"
            ]
        )

        last_message = conversation_history[-1] if conversation_history else None
        last_message_preview = (
            getattr(last_message, "content", "")[:100] + "..." if last_message else ""
        )

        # Calculate duration
        created_at = session_data.get("created_at", datetime.now())
        last_activity = session_data.get("last_activity", datetime.now())
        duration_seconds = (
            (last_activity - created_at).total_seconds()
            if isinstance(created_at, datetime)
            else 0
        )

        # Calculate average response length
        ai_messages_content = [
            getattr(msg, "content", "")
            for msg in conversation_history
            if getattr(msg, "role", "") == "assistant"
        ]
        avg_response_length = sum(
            len(content) for content in ai_messages_content
        ) / max(len(ai_messages_content), 1)

        summary = {
            "conversation_id": conversation_id,
            "session_id": session_id,
            "company_id": company_id,
            "status": (
                "ACTIVE" if session_data.get("message_count", 0) > 0 else "INACTIVE"
            ),
            "message_count": len(conversation_history),
            "user_messages": user_message_count,
            "ai_messages": ai_message_count,
            "created_at": (
                created_at.isoformat()
                if isinstance(created_at, datetime)
                else str(created_at)
            ),
            "last_activity": (
                last_activity.isoformat()
                if isinstance(last_activity, datetime)
                else str(last_activity)
            ),
            "duration_seconds": duration_seconds,
            "last_message_preview": last_message_preview,
            "quick_stats": {
                "avg_response_length": round(avg_response_length, 2),
                "conversation_length": len(conversation_history),
                "has_images": any(
                    getattr(msg, "images", None) for msg in conversation_history
                ),
                "languages_detected": list(
                    set(
                        (
                            getattr(msg, "language", "unknown").value
                            if hasattr(getattr(msg, "language", None), "value")
                            else "unknown"
                        )
                        for msg in conversation_history
                    )
                ),
                "intents_detected": list(
                    set(
                        (
                            getattr(msg, "intent", "unknown").value
                            if hasattr(getattr(msg, "intent", None), "value")
                            else "unknown"
                        )
                        for msg in conversation_history
                    )
                ),
            },
        }

        logger.info(
            f"‚úÖ [CONVERSATION_SUMMARY] Summary generated: {user_message_count} user msgs, {ai_message_count} AI msgs"
        )
        return summary

    except Exception as e:
        logger.error(f"‚ùå Error getting conversation summary: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/api/conversation/list")
async def list_conversations(
    company_id: Optional[str] = Header(None, alias="X-Company-Id"),
    limit: int = 50,
    offset: int = 0,
):
    """
    List all conversations for a company
    Li·ªát k√™ t·∫•t c·∫£ cu·ªôc tr√≤ chuy·ªán c·ªßa m·ªôt c√¥ng ty
    """
    try:
        if not company_id:
            raise HTTPException(status_code=400, detail="Company ID required")

        logger.info(
            f"üìã [LIST_CONVERSATIONS] Getting conversations for company {company_id}"
        )

        conversations = []

        # Get all sessions and filter by company
        for session_id, session_data in unified_chat_service.sessions.items():
            # In a real system, you would filter by company_id stored in session
            # For now, we'll include all sessions

            conversation_history = unified_chat_service._get_conversation_history(
                session_id
            )
            if not conversation_history:
                continue

            user_message_count = len(
                [
                    msg
                    for msg in conversation_history
                    if getattr(msg, "role", "") == "user"
                ]
            )
            last_message = conversation_history[-1] if conversation_history else None

            conversations.append(
                {
                    "conversation_id": session_data.get("conversation_id", session_id),
                    "session_id": session_id,
                    "message_count": len(conversation_history),
                    "user_messages": user_message_count,
                    "created_at": session_data.get(
                        "created_at", datetime.now()
                    ).isoformat(),
                    "last_activity": session_data.get(
                        "last_activity", datetime.now()
                    ).isoformat(),
                    "last_message_preview": (
                        getattr(last_message, "content", "")[:50] + "..."
                        if last_message
                        else ""
                    ),
                    "status": "ACTIVE" if len(conversation_history) > 0 else "INACTIVE",
                }
            )

        # Sort by last activity (newest first)
        conversations.sort(key=lambda x: x["last_activity"], reverse=True)

        # Apply pagination
        total = len(conversations)
        paginated_conversations = conversations[offset : offset + limit]

        return {
            "conversations": paginated_conversations,
            "total": total,
            "limit": limit,
            "offset": offset,
            "has_more": offset + limit < total,
        }

    except Exception as e:
        logger.error(f"‚ùå Error listing conversations: {e}")
        raise HTTPException(status_code=500, detail=str(e))


async def _perform_deep_conversation_analysis_with_gemini(
    conversation_history: List, company_id: str, conversation_stats: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Perform deep analysis of entire conversation using Google Gemini
    Th·ª±c hi·ªán ph√¢n t√≠ch s√¢u to√†n b·ªô cu·ªôc tr√≤ chuy·ªán s·ª≠ d·ª•ng Google Gemini
    """
    try:
        # Step 1: Initialize Gemini AI service
        from src.providers.gemini_provider import GeminiProvider

        gemini_provider = GeminiProvider()

        # Step 2: Combine all messages into analysis text
        user_messages = []
        ai_messages = []
        full_conversation = []

        for msg in conversation_history:
            role = getattr(msg, "role", "unknown")
            content = getattr(msg, "content", "")
            timestamp = getattr(msg, "timestamp", datetime.now())

            if role == "user":
                user_messages.append(content)
            elif role == "assistant":
                ai_messages.append(content)

            full_conversation.append(f"{role.title()}: {content}")

        combined_conversation = "\n".join(full_conversation)

        logger.info(
            f"üìä Analyzing conversation with Gemini: {len(user_messages)} user messages, {len(ai_messages)} AI responses"
        )

        # Step 3: Create comprehensive analysis prompt for Gemini
        analysis_prompt = f"""
B·∫†N L√Ä CHUY√äN GIA PH√ÇN T√çCH CU·ªòC TR√í CHUY·ªÜN V√Ä REMARKETING CHUY√äN NGHI·ªÜP.

TO√ÄN B·ªò CU·ªòC TR√í CHUY·ªÜN:
{combined_conversation}

TH·ªêNG K√ä CU·ªòC TR√í CHUY·ªÜN:
- T·ªïng s·ªë tin nh·∫Øn: {len(conversation_history)}
- Tin nh·∫Øn t·ª´ kh√°ch h√†ng: {len(user_messages)}
- Ph·∫£n h·ªìi t·ª´ AI: {len(ai_messages)}
- Th·ªùi l∆∞·ª£ng: {conversation_stats.get('duration_seconds', 0)} gi√¢y

NHI·ªÜM V·ª§ PH√ÇN T√çCH CHUY√äN S√ÇU:

1. **Ph√¢n t√≠ch √Ω ƒë·ªãnh ch√≠nh (Primary Intent Analysis)**
   - X√°c ƒë·ªãnh √Ω ƒë·ªãnh ch√≠nh c·ªßa kh√°ch h√†ng
   - ƒê·ªô tin c·∫≠y c·ªßa vi·ªác ph√°t hi·ªán √Ω ƒë·ªãnh
   - S·ª± thay ƒë·ªïi √Ω ƒë·ªãnh qua cu·ªôc tr√≤ chuy·ªán

2. **ƒê√°nh gi√° m·ª©c ƒë·ªô h√†i l√≤ng kh√°ch h√†ng (Customer Satisfaction)**
   - HIGH: Kh√°ch h√†ng h√†i l√≤ng, c√≥ c√¢u tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß
   - MEDIUM: Kh√°ch h√†ng ƒë∆∞·ª£c h·ªó tr·ª£ nh∆∞ng v·∫´n c√≥ th·∫Øc m·∫Øc
   - LOW: Kh√°ch h√†ng kh√¥ng h√†i l√≤ng ho·∫∑c v·∫•n ƒë·ªÅ ch∆∞a ƒë∆∞·ª£c gi·∫£i quy·∫øt

3. **K·∫øt qu·∫£ cu·ªôc tr√≤ chuy·ªán (Conversation Outcome)**
   - CONVERTED: Kh√°ch h√†ng ƒë√£ chuy·ªÉn ƒë·ªïi (mua h√†ng, ƒëƒÉng k√Ω)
   - INTERESTED: Kh√°ch h√†ng quan t√¢m, c·∫ßn theo d√µi
   - NEEDS_FOLLOWUP: C·∫ßn li√™n h·ªá l·∫°i
   - LOST: Kh√°ch h√†ng kh√¥ng quan t√¢m
   - INCOMPLETE: Cu·ªôc tr√≤ chuy·ªán ch∆∞a ho√†n th√†nh

4. **C∆° h·ªôi Remarketing**
   - Email campaigns
   - Phone follow-up
   - Social media targeting
   - Product recommendations

5. **ƒê·ªÅ xu·∫•t c·∫£i thi·ªán h·ªá th·ªëng**

TR·∫¢ V·ªÄ JSON CH√çNH X√ÅC THEO ƒê·ªäNH D·∫†NG:
{{
    "primary_intent": "SALES_INQUIRY|INFORMATION|SUPPORT|BOOKING|COMPLAINT|GENERAL_CHAT",
    "intent_confidence": 0.95,
    "intent_evolution": [
        {{"turn": 1, "intent": "INFORMATION", "confidence": 0.8, "message_preview": "T√¥i mu·ªën bi·∫øt v·ªÅ..."}},
        {{"turn": 3, "intent": "SALES_INQUIRY", "confidence": 0.9, "message_preview": "Gi√° bao nhi·ªÅu?"}}
    ],
    "customer_satisfaction": "HIGH|MEDIUM|LOW",
    "satisfaction_indicators": [
        "Kh√°ch h√†ng c·∫£m ∆°n nhi·ªÅu l·∫ßn",
        "H·ªèi th√™m th√¥ng tin chi ti·∫øt"
    ],
    "conversation_outcome": "CONVERTED|INTERESTED|NEEDS_FOLLOWUP|LOST|INCOMPLETE",
    "outcome_reasoning": "Kh√°ch h√†ng ƒë√£ h·ªèi gi√° v√† y√™u c·∫ßu th√¥ng tin li√™n h·ªá, cho th·∫•y m·ª©c ƒë·ªô quan t√¢m cao",
    "customer_pain_points": [
        "Lo l·∫Øng v·ªÅ gi√° c·∫£",
        "C·∫ßn t∆∞ v·∫•n v·ªÅ s·∫£n ph·∫©m ph√π h·ª£p"
    ],
    "products_mentioned": [
        "G√≥i vay mua nh√†",
        "B·∫£o hi·ªÉm xe √¥ t√¥"
    ],
    "key_requirements": [
        "L√£i su·∫•t th·∫•p",
        "Th·ªß t·ª•c nhanh g·ªçn"
    ],
    "unresolved_issues": [
        "Ch∆∞a r√µ ƒëi·ªÅu ki·ªán vay c·ª• th·ªÉ",
        "Ch∆∞a c√≥ th√¥ng tin v·ªÅ ph√≠ d·ªãch v·ª•"
    ],
    "remarketing_opportunities": [
        {{
            "type": "EMAIL_CAMPAIGN",
            "priority": "HIGH",
            "suggestion": "G·ª≠i email ∆∞u ƒë√£i l√£i su·∫•t ƒë·∫∑c bi·ªát cho kh√°ch h√†ng m·ªõi",
            "timing": "24H",
            "target_products": ["G√≥i vay mua nh√†"],
            "personalization": "Nh·∫Øc ƒë·∫øn y√™u c·∫ßu l√£i su·∫•t th·∫•p c·ªßa kh√°ch h√†ng"
        }},
        {{
            "type": "PHONE_FOLLOWUP",
            "priority": "MEDIUM",
            "suggestion": "G·ªçi ƒëi·ªán t∆∞ v·∫•n chi ti·∫øt v·ªÅ ƒëi·ªÅu ki·ªán vay",
            "timing": "WEEK",
            "talking_points": ["ƒêi·ªÅu ki·ªán vay c·ª• th·ªÉ", "Ph√≠ d·ªãch v·ª•"]
        }}
    ],
    "improvement_suggestions": [
        {{
            "category": "PRODUCT_INFO",
            "issue": "Thi·∫øu th√¥ng tin chi ti·∫øt v·ªÅ ph√≠ d·ªãch v·ª•",
            "solution": "B·ªï sung b·∫£ng ph√≠ chi ti·∫øt trong c∆° s·ªü d·ªØ li·ªáu",
            "priority": "HIGH"
        }},
        {{
            "category": "RESPONSE_QUALITY",
            "issue": "AI ch∆∞a ch·ªß ƒë·ªông h·ªèi v·ªÅ nhu c·∫ßu c·ª• th·ªÉ",
            "solution": "C·∫£i thi·ªán prompt ƒë·ªÉ AI h·ªèi th√™m v·ªÅ requirements",
            "priority": "MEDIUM"
        }}
    ],
    "next_actions": [
        "G·ª≠i email follow-up trong 24h",
        "Chu·∫©n b·ªã t√†i li·ªáu ƒëi·ªÅu ki·ªán vay chi ti·∫øt",
        "L√™n l·ªãch g·ªçi ƒëi·ªán t∆∞ v·∫•n"
    ],
    "conversation_sentiment": {{
        "overall": "POSITIVE|NEUTRAL|NEGATIVE",
        "customer_tone": "FRIENDLY|PROFESSIONAL|CONCERNED|FRUSTRATED",
        "engagement_level": "HIGH|MEDIUM|LOW"
    }},
    "business_value": {{
        "potential_revenue": "HIGH|MEDIUM|LOW",
        "conversion_probability": 0.75,
        "customer_lifetime_value": "HIGH|MEDIUM|LOW"
    }},
    "ai_performance": {{
        "response_relevance": 0.85,
        "response_helpfulness": 0.80,
        "response_speed": "GOOD|AVERAGE|SLOW",
        "missed_opportunities": [
            "Kh√¥ng ƒë·ªÅ xu·∫•t s·∫£n ph·∫©m b·ªï sung",
            "Ch∆∞a thu th·∫≠p th√¥ng tin li√™n h·ªá"
        ],
        "strengths": [
            "Tr·∫£ l·ªùi ch√≠nh x√°c c√°c c√¢u h·ªèi",
            "Th√°i ƒë·ªô th√¢n thi·ªán"
        ]
    }},
    "summary": "Kh√°ch h√†ng quan t√¢m ƒë·∫øn g√≥i vay mua nh√† v·ªõi y√™u c·∫ßu l√£i su·∫•t th·∫•p. M·ª©c ƒë·ªô engagement cao, c·∫ßn follow-up trong 24h v·ªõi ∆∞u ƒë√£i c·ª• th·ªÉ.",
    "analysis_metadata": {{
        "ai_provider": "google_gemini",
        "analysis_timestamp": "{datetime.now().isoformat()}",
        "conversation_length_chars": {len(combined_conversation)},
        "analysis_duration_ms": 0
    }}
}}

Y√äU C·∫¶U QUAN TR·ªåNG:
1. Ph√¢n t√≠ch kh√°ch quan v√† chi ti·∫øt
2. ƒê∆∞a ra remarketing suggestions th·ª±c t·∫ø v√† kh·∫£ thi
3. ƒê√°nh gi√° hi·ªáu qu·∫£ AI m·ªôt c√°ch c√¥ng b·∫±ng
4. T·∫≠p trung v√†o business value v√† conversion opportunities
5. Tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng c√≥ text b·ªï sung
"""

        # Step 4: Get analysis from Gemini
        logger.info("ü§ñ Sending conversation to Gemini for deep analysis...")

        analysis_response = await gemini_provider.get_completion(
            prompt=analysis_prompt,
            max_tokens=4000,
            temperature=0.3,  # Lower temperature for more consistent analysis
        )

        # Step 5: Parse and validate response
        try:
            # Clean JSON response
            clean_response = _clean_json_response(analysis_response)
            analysis_data = json.loads(clean_response)

            # Add processing metadata
            analysis_data["analysis_metadata"].update(
                {
                    "total_messages": len(conversation_history),
                    "user_messages_count": len(user_messages),
                    "ai_messages_count": len(ai_messages),
                    "company_id": company_id,
                    "analyzer_version": "2.0_gemini",
                }
            )

            logger.info(f"‚úÖ Gemini analysis completed successfully")
            logger.info(
                f"   Primary Intent: {analysis_data.get('primary_intent', 'Unknown')}"
            )
            logger.info(
                f"   Outcome: {analysis_data.get('conversation_outcome', 'Unknown')}"
            )
            logger.info(
                f"   Satisfaction: {analysis_data.get('customer_satisfaction', 'Unknown')}"
            )
            logger.info(
                f"   Remarketing Opportunities: {len(analysis_data.get('remarketing_opportunities', []))}"
            )

            return analysis_data

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Failed to parse Gemini analysis JSON: {e}")

            # Return fallback analysis
            return {
                "error": "Analysis parsing failed",
                "raw_analysis": (
                    analysis_response[:500] + "..."
                    if len(analysis_response) > 500
                    else analysis_response
                ),
                "fallback_summary": f"Cu·ªôc tr√≤ chuy·ªán c√≥ {len(user_messages)} tin nh·∫Øn t·ª´ kh√°ch h√†ng. C·∫ßn ph√¢n t√≠ch th·ªß c√¥ng.",
                "analysis_metadata": {
                    "ai_provider": "google_gemini",
                    "total_messages": len(conversation_history),
                    "user_messages_count": len(user_messages),
                    "ai_messages_count": len(ai_messages),
                    "error": str(e),
                    "analysis_timestamp": datetime.now().isoformat(),
                },
            }

    except Exception as e:
        logger.error(f"‚ùå Gemini analysis error: {e}")
        return {
            "error": f"Analysis failed: {str(e)}",
            "analysis_metadata": {
                "ai_provider": "google_gemini",
                "total_messages": (
                    len(conversation_history)
                    if "conversation_history" in locals()
                    else 0
                ),
                "error": str(e),
                "analysis_timestamp": datetime.now().isoformat(),
            },
        }


def _clean_json_response(response: str) -> str:
    """
    Clean and extract JSON from Gemini response
    L√†m s·∫°ch v√† tr√≠ch xu·∫•t JSON t·ª´ ph·∫£n h·ªìi c·ªßa Gemini
    """
    try:
        # Remove markdown code blocks
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1].split("```")[0]

        # Remove extra whitespace
        response = response.strip()

        # Find JSON object bounds
        start_idx = response.find("{")
        end_idx = response.rfind("}")

        if start_idx != -1 and end_idx != -1:
            response = response[start_idx : end_idx + 1]

        return response

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è JSON cleaning failed: {e}")
        return response
