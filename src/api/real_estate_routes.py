"""
FastAPI route handlers for real estate analysis endpoints with complete file processing
"""

from fastapi import APIRouter, Request
from fastapi.responses import StreamingResponse
from datetime import datetime
import json
import asyncio
import time
import base64
from typing import Dict, Any, List
import logging

from src.core.models import (
    ChatWithFilesRequest,
    RealEstateAnalysisRequest,
    RealEstateAnalysisResponse,
)
from src.core.document_utils import (
    save_real_estate_analysis_log,
    extract_text_from_pdf,
    extract_text_from_docx,
    extract_text_with_chatgpt_vision_url,
)
from src.utils.real_estate_analyzer import analyze_real_estate_query
from src.providers.ai_provider_manager import AIProviderManager
from config.config import DEEPSEEK_API_KEY, CHATGPT_API_KEY

logger = logging.getLogger(__name__)
router = APIRouter()


@router.post("/real-estate/deepseek-reasoning")
async def real_estate_deepseek_reasoning(request: ChatWithFilesRequest):
    """
    âœ… COMPLETE: Real estate analysis with DeepSeek reasoning + file processing + web search
    Supports: TXT, PDF, DOCX files and Images (OCR via ChatGPT Vision)
    """

    async def generate():
        # Initialize comprehensive analysis log
        analysis_log = {
            "request": {
                "question": request.question,
                "files_count": len(request.files) if request.files else 0,
                "file_names": (
                    request.file_names if hasattr(request, "file_names") else []
                ),
                "file_types": (
                    request.file_types if hasattr(request, "file_types") else []
                ),
                "user_id": request.user_id or "anonymous",
                "session_id": request.session_id or "default",
                "timestamp": datetime.now().isoformat(),
            },
            "processing_steps": [],
            "web_search": {
                "search_query": None,
                "properties_found": [],
                "performance_metrics": {},
            },
            "processed_files": [],
            "ai_response": "",
            "performance_metrics": {},
            "errors": [],
        }

        start_time = time.time()

        try:
            # Initialize variables
            full_response = ""
            processed_files = []
            user_id = request.user_id or "anonymous"
            session_id = request.session_id or f"re-{int(time.time())}"

            yield f'data: {json.dumps({"status": "started", "message": "Báº¯t Ä‘áº§u phÃ¢n tÃ­ch báº¥t Ä‘á»™ng sáº£n..."})}\n\n'

            # âœ… STEP 0: Quick Analysis
            logger.info("=== STEP 0: QUICK ANALYSIS ===")
            yield f'data: {json.dumps({"status": "analyzing", "message": "PhÃ¢n tÃ­ch yÃªu cáº§u..."})}\n\n'

            analysis = analyze_real_estate_query(request.question)
            logger.info(f"Quick Analysis - Confidence: {analysis.confidence:.2f}")

            analysis_log["processing_steps"].append(
                {
                    "step": 0,
                    "name": "quick_analysis",
                    "timestamp": time.time(),
                    "result": {
                        "property_type": analysis.property_type,
                        "project_name": analysis.project_name,
                        "location": {
                            "province": (
                                analysis.location.province
                                if hasattr(analysis, "location")
                                else None
                            ),
                            "district": (
                                analysis.location.district
                                if hasattr(analysis, "location")
                                else None
                            ),
                        },
                        "search_query": (
                            analysis.search_query
                            if hasattr(analysis, "search_query")
                            else None
                        ),
                        "confidence": analysis.confidence,
                    },
                }
            )

            # âœ… STEP 1: FILE PROCESSING
            files_context = ""
            if request.files and len(request.files) > 0:
                logger.info("=== STEP 1: PROCESSING FILES ===")
                yield f'data: {json.dumps({"status": "processing_files", "message": f"Äang xá»­ lÃ½ {len(request.files)} tÃ i liá»‡u..."})}\n\n'

                ai_manager = AIProviderManager(
                    deepseek_api_key=DEEPSEEK_API_KEY, chatgpt_api_key=CHATGPT_API_KEY
                )

                for i, file_base64 in enumerate(request.files):
                    filename = (
                        request.file_names[i]
                        if i < len(request.file_names)
                        else f"file_{i+1}"
                    )
                    file_type = (
                        request.file_types[i]
                        if i < len(request.file_types)
                        else "unknown"
                    )

                    file_log = {
                        "filename": filename,
                        "file_type": file_type,
                        "file_size": len(file_base64),
                        "extraction_start": time.time(),
                    }

                    extracted_text = ""
                    extraction_method = ""

                    try:
                        # âœ… IMAGE PROCESSING (OCR via ChatGPT Vision)
                        if file_type.startswith("image/") or filename.lower().endswith(
                            (".jpg", ".jpeg", ".png", ".gif", ".bmp")
                        ):
                            logger.info(f"Processing image: {filename}")
                            yield f'data: {json.dumps({"status": "ocr", "message": f"Äang OCR hÃ¬nh áº£nh {filename}..."})}\n\n'

                            try:
                                # Create a temporary image for OCR
                                import tempfile
                                import os

                                # Decode base64 image
                                image_data = base64.b64decode(file_base64)

                                # Save to temp file
                                with tempfile.NamedTemporaryFile(
                                    delete=False, suffix=f".{filename.split('.')[-1]}"
                                ) as temp_file:
                                    temp_file.write(image_data)
                                    temp_image_path = temp_file.name

                                # Use ChatGPT Vision for OCR
                                extracted_text = (
                                    await extract_text_with_chatgpt_vision_file(
                                        temp_image_path, filename
                                    )
                                )
                                extraction_method = "ChatGPT Vision OCR"

                                # Clean up temp file
                                os.unlink(temp_image_path)

                            except Exception as e:
                                logger.error(f"Image OCR error for {filename}: {e}")
                                extracted_text = (
                                    f"[Lá»—i OCR hÃ¬nh áº£nh {filename}: {str(e)}]"
                                )
                                extraction_method = "Failed OCR"
                                file_log["error"] = str(e)

                        # âœ… PDF PROCESSING
                        elif (
                            file_type == "application/pdf"
                            or filename.lower().endswith(".pdf")
                        ):
                            logger.info(f"Processing PDF: {filename}")
                            yield f'data: {json.dumps({"status": "pdf", "message": f"Äang Ä‘á»c PDF {filename}..."})}\n\n'

                            try:
                                extracted_text = (
                                    await asyncio.get_event_loop().run_in_executor(
                                        None, extract_text_from_pdf, file_base64
                                    )
                                )
                                extraction_method = "PyMuPDF"
                            except Exception as e:
                                logger.error(
                                    f"PDF processing error for {filename}: {e}"
                                )
                                extracted_text = f"[Lá»—i Ä‘á»c PDF {filename}: {str(e)}]"
                                extraction_method = "Failed PDF"
                                file_log["error"] = str(e)

                        # âœ… DOCX PROCESSING
                        elif file_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document" or filename.lower().endswith(
                            ".docx"
                        ):
                            logger.info(f"Processing DOCX: {filename}")
                            yield f'data: {json.dumps({"status": "docx", "message": f"Äang Ä‘á»c DOCX {filename}..."})}\n\n'

                            try:
                                extracted_text = (
                                    await asyncio.get_event_loop().run_in_executor(
                                        None, extract_text_from_docx, file_base64
                                    )
                                )
                                extraction_method = "python-docx"
                            except Exception as e:
                                logger.error(
                                    f"DOCX processing error for {filename}: {e}"
                                )
                                extracted_text = f"[Lá»—i Ä‘á»c DOCX {filename}: {str(e)}]"
                                extraction_method = "Failed DOCX"
                                file_log["error"] = str(e)

                        # âœ… TXT PROCESSING
                        elif file_type == "text/plain" or filename.lower().endswith(
                            ".txt"
                        ):
                            logger.info(f"Processing TXT: {filename}")
                            yield f'data: {json.dumps({"status": "txt", "message": f"Äang Ä‘á»c TXT {filename}..."})}\n\n'

                            try:
                                # Decode base64 text file
                                text_data = base64.b64decode(file_base64)
                                extracted_text = text_data.decode(
                                    "utf-8", errors="ignore"
                                )
                                extraction_method = "Direct Text"
                            except Exception as e:
                                logger.error(
                                    f"TXT processing error for {filename}: {e}"
                                )
                                extracted_text = f"[Lá»—i Ä‘á»c TXT {filename}: {str(e)}]"
                                extraction_method = "Failed TXT"
                                file_log["error"] = str(e)

                        # âœ… UNSUPPORTED FILE TYPE
                        else:
                            extracted_text = (
                                f"[Loáº¡i file {file_type} chÆ°a Ä‘Æ°á»£c há»— trá»£: {filename}]"
                            )
                            extraction_method = "Unsupported"

                    except Exception as e:
                        logger.error(
                            f"General file processing error for {filename}: {e}"
                        )
                        extracted_text = f"[Lá»—i xá»­ lÃ½ file {filename}: {str(e)}]"
                        extraction_method = "Failed"
                        file_log["error"] = str(e)

                    # Complete file log
                    file_log.update(
                        {
                            "extracted_text": extracted_text,
                            "extraction_method": extraction_method,
                            "text_length": len(extracted_text),
                            "success": len(extracted_text.strip()) > 10
                            and not extracted_text.startswith("[Lá»—i"),
                            "processing_time": time.time()
                            - file_log["extraction_start"],
                        }
                    )

                    processed_files.append(file_log)

                    # Add to context if successful
                    if file_log["success"]:
                        files_context += (
                            f"\n\n--- Ná»™i dung tá»« {filename} ---\n{extracted_text}\n"
                        )
                        yield f'data: {json.dumps({"status": "file_success", "message": f"âœ… {filename}: {len(extracted_text)} kÃ½ tá»±"})}\n\n'
                    else:
                        yield f'data: {json.dumps({"status": "file_error", "message": f"âŒ {filename}: Lá»—i xá»­ lÃ½"})}\n\n'

                # Log file processing step
                analysis_log["processing_steps"].append(
                    {
                        "step": 1,
                        "name": "file_processing",
                        "timestamp": time.time(),
                        "result": {
                            "files_processed": len(processed_files),
                            "successful_files": len(
                                [f for f in processed_files if f["success"]]
                            ),
                            "total_text_length": sum(
                                len(f["extracted_text"]) for f in processed_files
                            ),
                            "files_details": processed_files,
                        },
                    }
                )
                analysis_log["processed_files"] = processed_files

            # âœ… STEP 2: AI ANALYSIS with DeepSeek (Skip web search for better performance)
            yield f'data: {json.dumps({"status": "ai_analysis", "message": "Äang phÃ¢n tÃ­ch vá»›i AI..."})}\n\n'

            # Create comprehensive prompt
            comprehensive_prompt = f"""
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch báº¥t Ä‘á»™ng sáº£n hÃ ng Ä‘áº§u táº¡i Viá»‡t Nam vá»›i hÆ¡n 15 nÄƒm kinh nghiá»‡m.

YÃŠU Cáº¦U PHÃ‚N TÃCH: {request.question}

{files_context}

HÃ£y cung cáº¥p phÃ¢n tÃ­ch chuyÃªn sÃ¢u theo cáº¥u trÃºc sau:

ğŸ¢ **THÃ”NG TIN Tá»”NG QUAN**
- Loáº¡i hÃ¬nh báº¥t Ä‘á»™ng sáº£n vÃ  thÃ´ng sá»‘ ká»¹ thuáº­t
- Vá»‹ trÃ­ Ä‘á»‹a lÃ½ vÃ  Ä‘Ã¡nh giÃ¡ location
- ThÃ´ng tin dá»± Ã¡n/chá»§ Ä‘áº§u tÆ° (náº¿u cÃ³)

ğŸ’° **PHÃ‚N TÃCH GIÃ TRá»Š & THá»Š TRÆ¯á»œNG**
- Æ¯á»›c tÃ­nh giÃ¡ trá»‹ hiá»‡n táº¡i
- So sÃ¡nh vá»›i thá»‹ trÆ°á»ng khu vá»±c
- Xu hÆ°á»›ng giÃ¡ trong 6-12 thÃ¡ng tá»›i

ğŸ“ˆ **TIá»€M NÄ‚NG Äáº¦U TÆ¯**
- Kháº£ nÄƒng tÄƒng giÃ¡ trung/dÃ i háº¡n
- Tiá»m nÄƒng cho thuÃª vÃ  yield
- TÃ­nh thanh khoáº£n

âœ… **Æ¯U ÄIá»‚M & Rá»¦I RO**
- Äiá»ƒm máº¡nh cá»§a báº¥t Ä‘á»™ng sáº£n
- Rá»§i ro vÃ  háº¡n cháº¿ cáº§n lÆ°u Ã½
- Yáº¿u tá»‘ tÃ¡c Ä‘á»™ng giÃ¡

ğŸ¯ **KHUYáº¾N NGHá»Š CHUYÃŠN MÃ”N**
- PhÃ¹ há»£p vá»›i nhÃ³m Ä‘á»‘i tÆ°á»£ng nÃ o
- Thá»i Ä‘iá»ƒm mua/bÃ¡n/Ä‘áº§u tÆ°
- LÆ°u Ã½ phÃ¡p lÃ½ vÃ  thá»§ tá»¥c
- Káº¿t luáº­n tá»•ng thá»ƒ

PhÃ¢n tÃ­ch chi tiáº¿t, chuyÃªn nghiá»‡p vÃ  thá»±c táº¿ dá»±a trÃªn kinh nghiá»‡m thá»‹ trÆ°á»ng Viá»‡t Nam.
"""

            # Create messages for AI
            messages = [
                {
                    "role": "system",
                    "content": "Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch báº¥t Ä‘á»™ng sáº£n hÃ ng Ä‘áº§u táº¡i Viá»‡t Nam vá»›i hÆ¡n 15 nÄƒm kinh nghiá»‡m.",
                },
                {"role": "user", "content": comprehensive_prompt},
            ]

            # Initialize AI manager
            ai_manager = AIProviderManager(
                deepseek_api_key=DEEPSEEK_API_KEY, chatgpt_api_key=CHATGPT_API_KEY
            )

            # Stream AI response using async generator (fix event loop issue)
            full_response = ""

            # Stream the chunks directly without creating new event loop
            async for chunk in ai_manager.chat_completion_stream_with_reasoning(
                messages, "deepseek", use_reasoning=True
            ):
                full_response += chunk
                yield f'data: {json.dumps({"status": "streaming", "content": chunk})}\n\n'
                await asyncio.sleep(0.01)  # Small delay for smooth streaming

            # âœ… SAVE COMPLETE ANALYSIS LOG
            analysis_log.update(
                {
                    "ai_response": full_response,
                    "performance_metrics": {
                        "total_processing_time": time.time() - start_time,
                        "files_processed": len(processed_files),
                        "successful_files": len(
                            [f for f in processed_files if f["success"]]
                        ),
                        "total_characters": len(full_response),
                    },
                }
            )

            # Save log to file
            log_file = save_real_estate_analysis_log(analysis_log)

            # Send completion
            yield f'data: {json.dumps({"status": "completed", "message": "PhÃ¢n tÃ­ch hoÃ n táº¥t", "log_file": log_file, "response_length": len(full_response)})}\n\n'
            yield f"data: [DONE]\n\n"

            logger.info(
                f"âœ… Real estate analysis completed. Response length: {len(full_response)}"
            )

        except Exception as e:
            error_msg = f"Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch: {str(e)}"
            logger.error(f"âŒ Real estate analysis error: {e}")
            analysis_log["errors"].append(str(e))

            yield f'data: {json.dumps({"status": "error", "error": error_msg})}\n\n'
            yield f"data: [DONE]\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        },
    )


# âœ… HELPER FUNCTION FOR IMAGE OCR
async def extract_text_with_chatgpt_vision_file(image_path: str, filename: str) -> str:
    """
    Extract text from image file using ChatGPT Vision API
    """
    try:
        ai_manager = AIProviderManager(
            deepseek_api_key=DEEPSEEK_API_KEY, chatgpt_api_key=CHATGPT_API_KEY
        )

        # Read image file and encode to base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode("utf-8")

        # Create OCR prompt
        ocr_prompt = f"""
HÃ£y Ä‘á»c vÃ  trÃ­ch xuáº¥t toÃ n bá»™ vÄƒn báº£n tá»« hÃ¬nh áº£nh nÃ y.
TÃªn file: {filename}

YÃªu cáº§u:
1. TrÃ­ch xuáº¥t chÃ­nh xÃ¡c toÃ n bá»™ text
2. Giá»¯ nguyÃªn format vÃ  cáº¥u trÃºc
3. Náº¿u cÃ³ báº£ng, danh sÃ¡ch thÃ¬ format rÃµ rÃ ng
4. Chá»‰ tráº£ vá» ná»™i dung text, khÃ´ng giáº£i thÃ­ch thÃªm

Náº¿u khÃ´ng Ä‘á»c Ä‘Æ°á»£c text, hÃ£y mÃ´ táº£ ná»™i dung hÃ¬nh áº£nh ngáº¯n gá»n.
"""

        # Use ChatGPT Vision for OCR
        result = await ai_manager.get_response_with_image(
            question=ocr_prompt, image_base64=image_data, provider="chatgpt"
        )

        return result or f"[KhÃ´ng thá»ƒ trÃ­ch xuáº¥t text tá»« {filename}]"

    except Exception as e:
        logger.error(f"ChatGPT Vision OCR error: {e}")
        return f"[Lá»—i OCR {filename}: {str(e)}]"


@router.post("/real-estate/analysis-once")
async def real_estate_analysis_once(req: RealEstateAnalysisRequest, request: Request):
    """
    âœ… One-time real estate analysis without file processing (for quick pricing queries)
    Returns JSON response immediately without streaming
    """
    try:
        client_ip = request.client.host
        device_id = request.headers.get("Device-ID", "unknown")
        user_id = request.headers.get("User-ID", "unknown")

        logger.info(f"ğŸ  [RE-ONCE] Request from {client_ip}: {req.query[:100]}...")

        # Initialize AI manager
        ai_manager = AIProviderManager(
            deepseek_api_key=DEEPSEEK_API_KEY, chatgpt_api_key=CHATGPT_API_KEY
        )

        # Create comprehensive analysis prompt for one-time analysis
        analysis_prompt = f"""
Báº¡n lÃ  chuyÃªn gia Ä‘á»‹nh giÃ¡ báº¥t Ä‘á»™ng sáº£n vá»›i 15+ nÄƒm kinh nghiá»‡m táº¡i thá»‹ trÆ°á»ng Viá»‡t Nam.

YÃŠU Cáº¦U Äá»ŠNH GIÃ: {req.query}

HÃ£y phÃ¢n tÃ­ch vÃ  Ä‘á»‹nh giÃ¡ theo cáº¥u trÃºc sau:

ğŸ¢ **THÃ”NG TIN Báº¤T Äá»˜NG SAN**
- Loáº¡i hÃ¬nh: (cÄƒn há»™, nhÃ  phá»‘, Ä‘áº¥t ná»n, villa...)
- Diá»‡n tÃ­ch vÃ  thÃ´ng sá»‘ ká»¹ thuáº­t
- Vá»‹ trÃ­ vÃ  Ä‘á»‹a chá»‰ cá»¥ thá»ƒ (náº¿u cÃ³ trong yÃªu cáº§u)
- TÃ¬nh tráº¡ng phÃ¡p lÃ½

ğŸ’° **Äá»ŠNH GIÃ CHI TIáº¾T**
- GiÃ¡ Æ°á»›c tÃ­nh hiá»‡n táº¡i (khoáº£ng giÃ¡ tá»« - Ä‘áº¿n)
- GiÃ¡ trÃªn mÂ² hoáº·c mÂ²
- So sÃ¡nh vá»›i giÃ¡ thá»‹ trÆ°á»ng khu vá»±c
- CÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n giÃ¡

ğŸ“Š **PHÃ‚N TÃCH THá»Š TRÆ¯á»œNG**
- Xu hÆ°á»›ng giÃ¡ 6-12 thÃ¡ng gáº§n Ä‘Ã¢y
- Dá»± bÃ¡o biáº¿n Ä‘á»™ng giÃ¡ trong tÆ°Æ¡ng lai
- TÃ­nh thanh khoáº£n cá»§a loáº¡i BÄS nÃ y

âœ… **Æ¯U & NHÆ¯á»¢C ÄIá»‚M**
- Äiá»ƒm máº¡nh vá» vá»‹ trÃ­, tiá»‡n Ã­ch
- Háº¡n cháº¿ vÃ  rá»§i ro cáº§n lÆ°u Ã½
- Tiá»m nÄƒng tÄƒng giÃ¡

ğŸ¯ **KHUYáº¾N NGHá»Š**
- PhÃ¹ há»£p mua/bÃ¡n/Ä‘áº§u tÆ°?
- Thá»i Ä‘iá»ƒm tá»‘t nháº¥t Ä‘á»ƒ giao dá»‹ch
- LÆ°u Ã½ vá» thá»§ tá»¥c phÃ¡p lÃ½
- ÄÃ¡nh giÃ¡ tá»•ng thá»ƒ (NÃªn/KhÃ´ng nÃªn)

Tráº£ lá»i chi tiáº¿t, chuyÃªn nghiá»‡p dá»±a trÃªn kinh nghiá»‡m thá»±c táº¿ thá»‹ trÆ°á»ng BÄS Viá»‡t Nam.
"""

        # Get AI response (using DeepSeek for detailed reasoning - same pattern as serve.py)

        # Create messages for AI
        messages = [
            {
                "role": "system",
                "content": "Báº¡n lÃ  chuyÃªn gia Ä‘á»‹nh giÃ¡ báº¥t Ä‘á»™ng sáº£n vá»›i 15+ nÄƒm kinh nghiá»‡m táº¡i thá»‹ trÆ°á»ng Viá»‡t Nam.",
            },
            {"role": "user", "content": analysis_prompt},
        ]

        # Initialize AI manager
        ai_manager = AIProviderManager(
            deepseek_api_key=DEEPSEEK_API_KEY, chatgpt_api_key=CHATGPT_API_KEY
        )

        # Get AI response using the same pattern as serve.py (async version)
        async def collect_ai_response():
            """Collect all AI chunks into a single response"""
            try:
                chunks = []
                async for chunk in ai_manager.chat_completion_stream_with_reasoning(
                    messages, "deepseek", use_reasoning=True
                ):
                    chunks.append(chunk)
                return "".join(chunks)
            except Exception as e:
                logger.error(f"AI async call error: {e}")
                return (
                    f"âš ï¸ Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch: {str(e)}"
                )

        # Get AI response
        ai_response = await collect_ai_response()

        # Create analysis log
        analysis_log = {
            "query": req.query,
            "analysis_type": "one-time",
            "response": ai_response,
            "user_id": req.user_id,
            "session_id": req.session_id,
            "timestamp": datetime.now().isoformat(),
            "response_length": len(ai_response),
        }

        # Save log
        log_file = save_real_estate_analysis_log(analysis_log)

        logger.info(
            f"âœ… [RE-ONCE] Analysis completed. Response: {len(ai_response)} chars"
        )

        return RealEstateAnalysisResponse(
            success=True,
            response=ai_response,
            analysis_data={
                "query": req.query,
                "analysis_type": "one-time",
                "timestamp": datetime.now().isoformat(),
                "log_file": log_file,
                "response_length": len(ai_response),
            },
            search_results=None,
            session_id=req.session_id,
        )

    except Exception as e:
        logger.error(f"âŒ [RE-ONCE] Error: {e}")
        return RealEstateAnalysisResponse(
            success=False,
            response="Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh Ä‘á»‹nh giÃ¡ báº¥t Ä‘á»™ng sáº£n.",
            error=str(e),
            session_id=req.session_id,
        )


@router.post("/real-estate/simple-analysis")
async def simple_real_estate_analysis(req: RealEstateAnalysisRequest, request: Request):
    """
    âœ… Simple real estate analysis without file processing (for quick queries)
    """
    try:
        client_ip = request.client.host
        device_id = request.headers.get("Device-ID", "unknown")
        user_id = request.headers.get("User-ID", "unknown")

        logger.info(f"ğŸ  [SIMPLE RE] Request from {client_ip}: {req.query[:100]}...")

        # Initialize AI manager
        ai_manager = AIProviderManager(
            deepseek_api_key=DEEPSEEK_API_KEY, chatgpt_api_key=CHATGPT_API_KEY
        )

        # Create simple prompt
        simple_prompt = f"""
Báº¡n lÃ  chuyÃªn gia báº¥t Ä‘á»™ng sáº£n. HÃ£y phÃ¢n tÃ­ch ngáº¯n gá»n:

{req.query}

Cung cáº¥p Ä‘Ã¡nh giÃ¡ nhanh vá»:
- Loáº¡i hÃ¬nh vÃ  vá»‹ trÃ­
- Æ¯á»›c tÃ­nh giÃ¡ trá»‹
- Æ¯u nhÆ°á»£c Ä‘iá»ƒm chÃ­nh
- Khuyáº¿n nghá»‹ cÆ¡ báº£n

Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch báº±ng tiáº¿ng Viá»‡t.
"""

        # Get AI response
        ai_response = await ai_manager.get_response(
            question=simple_prompt,
            session_id=req.session_id,
            user_id=req.user_id,
            provider="deepseek",
        )

        return RealEstateAnalysisResponse(
            success=True,
            response=ai_response,
            analysis_data={
                "query": req.query,
                "analysis_type": "simple",
                "timestamp": datetime.now().isoformat(),
            },
            search_results=None,
            session_id=req.session_id,
        )

    except Exception as e:
        logger.error(f"âŒ [SIMPLE RE] Error: {e}")
        return RealEstateAnalysisResponse(
            success=False,
            response="Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch.",
            error=str(e),
            session_id=req.session_id,
        )
