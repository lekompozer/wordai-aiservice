"""
Unified Chat Service
Dá»‹ch vá»¥ chat thá»‘ng nháº¥t vá»›i phÃ¡t hiá»‡n Ã½ Ä‘á»‹nh vÃ  Ä‘á»‹nh tuyáº¿n thÃ´ng minh
"""

import json
import re
import asyncio
import uuid
import time
from typing import Dict, Any, Optional, List, AsyncGenerator
from datetime import datetime
from fastapi.responses import StreamingResponse

from src.models.unified_models import (
    UnifiedChatRequest,
    UnifiedChatResponse,
    ChatIntent,
    Language,
    Industry,
    ConversationHistory,
    ChannelType,
    LeadSourceInfo,
)
from src.services.language_detector import language_detector
from src.services.intent_detector import intent_detector
from src.services.admin_service import AdminService
from src.services.qdrant_company_service import get_qdrant_service
from src.services.product_catalog_service import get_product_catalog_service
from src.providers.ai_provider_manager import AIProviderManager
from src.services.webhook_service import webhook_service
from src.core.config import APP_CONFIG
from src.utils.logger import setup_logger

logger = setup_logger()


class UnifiedChatService:
    """
    Unified chat service with intelligent routing
    Dá»‹ch vá»¥ chat thá»‘ng nháº¥t vá»›i Ä‘á»‹nh tuyáº¿n thÃ´ng minh
    """

    def __init__(self):
        # Initialize AI provider / Khá»Ÿi táº¡o AI provider
        from src.core.config import APP_CONFIG

        self.ai_manager = AIProviderManager(
            deepseek_api_key=APP_CONFIG.get("deepseek_api_key"),
            chatgpt_api_key=APP_CONFIG.get("chatgpt_api_key"),
            gemini_api_key=APP_CONFIG.get("gemini_api_key"),
            cerebras_api_key=APP_CONFIG.get("cerebras_api_key"),
        )

        # Initialize Admin Service for company data search / Khá»Ÿi táº¡o Admin Service cho tÃ¬m kiáº¿m dá»¯ liá»‡u cÃ´ng ty
        self.admin_service = AdminService()

        # Initialize Qdrant service for hybrid search / Khá»Ÿi táº¡o Qdrant service cho hybrid search
        self.qdrant_service = get_qdrant_service()

        # âœ… STEP 3: Initialize ProductCatalogService for inventory data
        self.catalog_service = None  # Will be initialized async
        logger.info("ğŸ”„ ProductCatalogService will be initialized on first use")

        # Initialize MongoDB conversation manager / Khá»Ÿi táº¡o MongoDB conversation manager
        try:
            from src.database.db_manager import DBManager
            from src.database.conversation_manager import ConversationManager

            self.db_manager = DBManager()
            # Increase token limit to ensure complete chat history display
            self.conversation_manager = ConversationManager(
                self.db_manager,
                max_token_limit=128000,  # Increased from 64K to 128K
                system_reserved_tokens=2000,  # Increased reserved tokens
            )
            logger.info(
                "âœ… MongoDB conversation manager initialized with enhanced token limits"
            )
        except Exception as e:
            logger.warning(f"âš ï¸ MongoDB conversation manager failed to initialize: {e}")
            self.conversation_manager = None

        # Session storage (in production, use Redis/Database) / LÆ°u trá»¯ phiÃªn (production dÃ¹ng Redis/Database)
        self.sessions = {}

        # Conversation tracking for webhooks / Theo dÃµi conversation cho webhooks
        self.conversations = {}

        # Information agent for RAG-based responses / Information agent cho pháº£n há»“i dá»±a trÃªn RAG
        from src.services.information_agent import InformationAgent

        self.info_agent = InformationAgent()

        # Sales agent manager for industry-specific sales / Sales agent manager cho bÃ¡n hÃ ng chuyÃªn biá»‡t theo ngÃ nh
        from src.services.industry_sales_agents import SalesAgentManager

        self.sales_agent_manager = SalesAgentManager(self.ai_manager)

    async def _ensure_catalog_service(self):
        """âœ… STEP 3: Ensure catalog service is initialized"""
        if self.catalog_service is None:
            try:
                self.catalog_service = await get_product_catalog_service()
                logger.info("âœ… ProductCatalogService initialized successfully")
            except Exception as e:
                logger.error(f"âŒ Failed to initialize ProductCatalogService: {e}")
                self.catalog_service = None

    def _get_webhook_channel_from_channel_type(self, channel) -> str:
        """
        Convert ChannelType to webhook channel name for Backend validation
        Chuyá»ƒn Ä‘á»•i ChannelType thÃ nh tÃªn kÃªnh cho Backend validation
        Backend expects: [WEB, FACEBOOK, WHATSAPP, ZALO, INSTAGRAM, PLUGIN]
        """
        from src.models.unified_models import ChannelType

        channel_to_webhook = {
            ChannelType.CHATDEMO: "chatdemo",  # âœ… Exact value
            ChannelType.MESSENGER: "messenger",  # âœ… Exact value
            ChannelType.INSTAGRAM: "instagram",  # âœ… Exact value
            ChannelType.WHATSAPP: "whatsapp",  # âœ… Exact value
            ChannelType.ZALO: "zalo",  # âœ… Exact value
            ChannelType.CHAT_PLUGIN: "chat-plugin",  # âœ… Exact value
        }
        return channel_to_webhook.get(channel, "chatdemo")  # Default to chatdemo

    def _get_channel_from_source(self, source) -> str:
        """
        Convert UserSource to channel name for webhook (LEGACY SUPPORT)
        Chuyá»ƒn Ä‘á»•i UserSource thÃ nh tÃªn kÃªnh cho webhook (Há»– TRá»¢ CÅ¨)
        """
        source_to_channel = {
            "chatdemo": "chatdemo",
            "messenger": "messenger",
            "whatsapp": "whatsapp",
            "zalo": "zalo",
            "instagram": "instagram",
            "chat_plugin": "chat-plugin",
        }
        return source_to_channel.get(
            source.value if hasattr(source, "value") else str(source),
            "chatdemo",  # Default to chatdemo
        )

    def _generate_conversation_id(
        self, company_id: str, device_id: str, plugin_id: str = None
    ) -> str:
        """
        Generate standardized conversation ID following format: conv_{companyId}_{deviceId}_{pluginId}
        Táº¡o conversation ID chuáº©n theo format: conv_{companyId}_{deviceId}_{pluginId}
        IMPORTANT: Keep UUID format intact for compatibility with chat-plugin
        """
        # Keep company_id EXACTLY as is - NO CLEANING
        final_company_id = company_id if company_id else "unknown"

        # Keep device_id EXACTLY as is - NO CLEANING
        final_device_id = device_id if device_id else "unknown"

        # Keep plugin_id EXACTLY as is - NO CLEANING
        final_plugin_id = plugin_id if plugin_id else "default"

        conversation_id = f"conv_{final_company_id}_{final_device_id}_{final_plugin_id}"

        logger.info(f"ğŸ†” Generated conversation ID: {conversation_id}")
        return conversation_id

    def get_or_create_conversation(
        self, session_id: str, company_id: str, device_id: str = None, request=None
    ) -> str:
        """
        Get existing conversation or create new one
        Supports device-based conversation tracking for anonymous users
        Láº¥y conversation hiá»‡n cÃ³ hoáº·c táº¡o má»›i, há»— trá»£ theo dÃµi conversation dá»±a trÃªn device
        """
        # Use device_id for conversation key if available (for anonymous users)
        conversation_key = device_id if device_id else session_id

        if conversation_key not in self.conversations:
            # Get plugin_id from request
            plugin_id = getattr(request, "plugin_id", None) if request else None

            # Generate standardized conversation ID
            conversation_id = self._generate_conversation_id(
                company_id=company_id,
                device_id=device_id or session_id,
                plugin_id=plugin_id,
            )

            self.conversations[conversation_key] = {
                "conversation_id": conversation_id,
                "company_id": company_id,
                "session_id": session_id,
                "device_id": device_id,
                "created_at": datetime.now(),
                "message_count": 0,
                "last_activity": datetime.now(),
                "user_type": (
                    "anonymous"
                    if device_id and not session_id.startswith("firebase_")
                    else "authenticated"
                ),
            }
            logger.info(
                f"ğŸ†• New conversation created: {conversation_id} (key: {conversation_key})"
            )

            return conversation_id
        else:
            # Update last activity
            self.conversations[conversation_key]["last_activity"] = datetime.now()
            return self.conversations[conversation_key]["conversation_id"]

    async def _send_conversation_created_webhook(
        self, company_id: str, conversation_id: str, session_id: str, request
    ):
        """Send conversation_created webhook with user info and detected intent"""
        try:
            # Extract user info for webhook
            user_info = webhook_service._extract_user_info_for_webhook(request)

            # âœ¨ Use channel first, fallback to source for legacy support
            channel = "chatdemo"  # Default to chatdemo instead of WEB
            if request.channel:
                # Prefer channel (new way)
                channel = self._get_webhook_channel_from_channel_type(request.channel)
            elif request.user_info and request.user_info.source:
                # Fallback to source (legacy support)
                channel = self._get_channel_from_source(request.user_info.source)

            # ğŸ¯ Detect intent from first message before sending webhook
            detected_intent = "general_chat"  # Default fallback
            try:
                intent_result = await intent_detector.detect_intent(
                    message=request.message,
                    industry=request.industry,
                    company_id=company_id,
                    conversation_history=None,
                    context=request.context,
                )
                detected_intent = intent_result.intent.value
                logger.info(
                    f"ğŸ¯ Detected intent for conversation {conversation_id}: {detected_intent}"
                )
            except Exception as e:
                logger.warning(f"âš ï¸ Intent detection failed, using default: {e}")

            # Prepare context with plugin data for PLUGIN channel
            context_data = {}
            if request.channel == ChannelType.CHAT_PLUGIN:
                context_data = {
                    "plugin_id": request.plugin_id,
                    "customer_domain": request.customer_domain,
                }

            await webhook_service.notify_conversation_created(
                company_id=company_id,
                conversation_id=conversation_id,
                session_id=session_id,
                channel=channel,
                intent=detected_intent,  # Use detected intent instead of None
                metadata={},
                context=context_data,  # Pass plugin data via context
                user_info=user_info,
            )
            logger.info(
                f"ğŸ”” Conversation created webhook sent for {conversation_id} with intent: {detected_intent}"
            )
        except Exception as e:
            logger.error(f"âŒ Failed to send conversation created webhook: {e}")

    def is_new_conversation(self, session_id: str, device_id: str = None) -> bool:
        """Check if this is a new conversation"""
        conversation_key = device_id if device_id else session_id
        return (
            conversation_key not in self.conversations
            or self.conversations[conversation_key]["message_count"] == 0
        )

    def _extract_user_context(self, request: UnifiedChatRequest) -> Dict[str, Any]:
        """
        Extract comprehensive user context for AI prompt enhancement
        TrÃ­ch xuáº¥t ngá»¯ cáº£nh ngÆ°á»i dÃ¹ng toÃ n diá»‡n Ä‘á»ƒ cáº£i thiá»‡n AI prompt
        """
        context = {
            "user_id": request.user_info.user_id,
            "device_id": request.user_info.device_id,
            "source": request.user_info.source.value,
            "session_id": request.session_id,
        }

        # Add user profile if available
        if request.user_info.name:
            context["user_name"] = request.user_info.name
        if request.user_info.email:
            context["user_email"] = request.user_info.email

        # Add platform-specific data
        if request.user_info.platform_specific_data:
            platform_data = request.user_info.platform_specific_data
            context.update(
                {
                    "browser": getattr(platform_data, "browser", None),
                    "platform": getattr(platform_data, "platform", None),
                    "user_language": getattr(platform_data, "language", None),
                    "timezone": getattr(platform_data, "timezone", None),
                }
            )

        # Add context data
        if request.context:
            context_data = request.context
            context.update(
                {
                    "page_url": getattr(context_data, "page_url", None),
                    "referrer": getattr(context_data, "referrer", None),
                    "session_duration": getattr(context_data, "session_duration", None),
                    "previous_intent": getattr(context_data, "previous_intent", None),
                }
            )

        # Add metadata
        if request.metadata:
            metadata = request.metadata
            context.update(
                {
                    "app_source": getattr(metadata, "source", None),
                    "app_version": getattr(metadata, "version", None),
                    "request_id": getattr(metadata, "request_id", None),
                }
            )

        return context

    async def end_conversation(self, session_id: str, summary: str = None) -> bool:
        """
        End a conversation and notify backend
        Káº¿t thÃºc conversation vÃ  thÃ´ng bÃ¡o backend
        """
        if session_id not in self.conversations:
            return False

        conversation = self.conversations[session_id]
        company_id = conversation["company_id"]
        conversation_id = conversation["conversation_id"]
        message_count = conversation["message_count"]

        # Notify conversation ended
        success = await webhook_service.notify_conversation_updated(
            company_id=company_id,
            conversation_id=conversation_id,
            status="COMPLETED",
            message_count=message_count,
            ended_at=datetime.now(),
            summary=summary or f"Conversation completed with {message_count} messages",
        )

        if success:
            # Remove from active conversations
            del self.conversations[session_id]
            logger.info(f"ğŸ Conversation ended: {conversation_id}")

        return success

    def get_conversation_stats(self, session_id: str) -> Dict[str, Any]:
        """
        Get conversation statistics
        Láº¥y thá»‘ng kÃª conversation
        """
        if session_id not in self.conversations:
            return {}

        conversation = self.conversations[session_id]
        duration = (datetime.now() - conversation["created_at"]).total_seconds()

        return {
            "conversation_id": conversation["conversation_id"],
            "company_id": conversation["company_id"],
            "message_count": conversation["message_count"],
            "duration_seconds": duration,
            "created_at": conversation["created_at"].isoformat(),
            "last_activity": conversation["last_activity"].isoformat(),
        }

    # Helper methods continue... / CÃ¡c phÆ°Æ¡ng thá»©c há»— trá»£ tiáº¿p tá»¥c...

    def _get_conversation_history(self, session_id: str) -> List[ConversationHistory]:
        """Get conversation history for session from MongoDB / Láº¥y lá»‹ch sá»­ há»™i thoáº¡i cho phiÃªn tá»« MongoDB"""
        if self.conversation_manager:
            try:
                # Use get_optimized_messages instead of get_messages / Sá»­ dá»¥ng get_optimized_messages thay vÃ¬ get_messages
                messages = self.conversation_manager.get_optimized_messages(
                    user_id=session_id, rag_context="", current_query=""
                )
                history = []
                for msg in messages:
                    history.append(
                        ConversationHistory(
                            role=msg.get("role", "user"),
                            content=msg.get("content", ""),
                            intent=None,  # Will be populated if available
                            language=None,  # Will be populated if available
                            timestamp=msg.get("timestamp", datetime.now()),
                        )
                    )
                if history:
                    print(
                        f"ğŸ“š [CHAT_HISTORY] Loaded {len(history)} messages from MongoDB for session: {session_id}"
                    )
                    return history
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load history from MongoDB: {e}")

        # Fallback to in-memory / Fallback vá» memory
        return self.sessions.get(session_id, {}).get("history", [])

    def _get_session_data(self, session_id: str) -> Dict[str, Any]:
        """Get session data / Láº¥y dá»¯ liá»‡u phiÃªn"""
        return self.sessions.get(session_id, {}).get("data", {})

    def _update_session_data(self, session_id: str, data: Dict[str, Any]):
        """Update session data / Cáº­p nháº­t dá»¯ liá»‡u phiÃªn"""
        if session_id not in self.sessions:
            self.sessions[session_id] = {"history": [], "data": {}}
        self.sessions[session_id]["data"].update(data)

    def _build_conversation_context(self, history: List[ConversationHistory]) -> str:
        """Build conversation context string / XÃ¢y dá»±ng chuá»—i ngá»¯ cáº£nh há»™i thoáº¡i"""
        if not history:
            return ""

        context_lines = []
        for msg in history[-5:]:  # Last 5 messages
            role = "User" if msg.role == "user" else "AI"
            context_lines.append(f"{role}: {msg.content}")

        return "\n".join(context_lines)

    def _generate_suggestions(
        self, intent_result, industry: Industry, language: Language
    ) -> List[str]:
        """Generate follow-up suggestions / Táº¡o gá»£i Ã½ theo dÃµi"""
        suggestions = []

        if language == Language.VIETNAMESE:
            if intent_result.intent == ChatIntent.INFORMATION:
                if industry == Industry.BANKING:
                    suggestions = [
                        "TÃ¬m hiá»ƒu vá» lÃ£i suáº¥t vay",
                        "Äiá»u kiá»‡n vay vá»‘n",
                        "CÃ¡c sáº£n pháº©m cho vay",
                    ]
                elif industry == Industry.RESTAURANT:
                    suggestions = ["Xem thá»±c Ä‘Æ¡n", "Äáº·t bÃ n", "Dá»‹ch vá»¥ giao hÃ ng"]
            elif intent_result.intent == ChatIntent.SALES_INQUIRY:
                suggestions = [
                    "TÃ´i cáº§n há»— trá»£ gÃ¬ thÃªm?",
                    "ThÃ´ng tin chi tiáº¿t sáº£n pháº©m",
                    "LiÃªn há»‡ tÆ° váº¥n trá»±c tiáº¿p",
                ]
        else:
            if intent_result.intent == ChatIntent.INFORMATION:
                if industry == Industry.BANKING:
                    suggestions = [
                        "Learn about interest rates",
                        "Loan requirements",
                        "Available loan products",
                    ]
                elif industry == Industry.RESTAURANT:
                    suggestions = ["View menu", "Make reservation", "Delivery options"]
            elif intent_result.intent == ChatIntent.SALES_INQUIRY:
                suggestions = [
                    "What else can I help with?",
                    "Product details",
                    "Contact advisor",
                ]

        return suggestions

    def _get_error_message(self, language: Language) -> str:
        """Get error message in appropriate language / Láº¥y thÃ´ng bÃ¡o lá»—i báº±ng ngÃ´n ngá»¯ phÃ¹ há»£p"""
        if language == Language.VIETNAMESE:
            return "Xin lá»—i, tÃ´i gáº·p sá»± cá»‘ ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt."
        else:
            return "Sorry, I'm experiencing technical difficulties. Please try again in a few minutes."

    # Streaming methods will be implemented next... / CÃ¡c phÆ°Æ¡ng thá»©c streaming sáº½ Ä‘Æ°á»£c triá»ƒn khai tiáº¿p theo...

    async def _hybrid_search_company_data(
        self,
        company_id: str,
        query: str,
        limit: int = 3,
        score_threshold: float = 0.2,  # Lowered default threshold for better results
        industry: Industry = Industry.OTHER,
        data_types: Optional[List] = None,
    ) -> List[Dict[str, Any]]:
        """
        UPDATED: Use comprehensive hybrid search from QdrantCompanyDataService
        Sá»¬ Dá»¤NG: TÃ¬m kiáº¿m hybrid toÃ n diá»‡n tá»« QdrantCompanyDataService
        """
        try:
            logger.info(
                f"ğŸ” Using comprehensive hybrid search for company {company_id}: {query[:50]}..."
            )

            # Convert legacy data_types format if needed
            qdrant_data_types = None
            if data_types:
                from src.models.unified_models import IndustryDataType

                qdrant_data_types = []
                for dt in data_types:
                    if isinstance(dt, str):
                        try:
                            qdrant_data_types.append(IndustryDataType(dt))
                        except ValueError:
                            logger.warning(f"Unknown data type: {dt}")
                    elif hasattr(dt, "value"):
                        qdrant_data_types.append(dt)

            # Use comprehensive hybrid search from Qdrant service with provided threshold
            logger.info(f"ğŸ” [DEBUG] Using score_threshold: {score_threshold}")
            search_results = await self.qdrant_service.comprehensive_hybrid_search(
                company_id=company_id,
                query=query,
                industry=industry,
                data_types=qdrant_data_types,
                score_threshold=score_threshold,  # Use the provided parameter!
                max_chunks=limit * 3,  # Get more chunks for better context
            )

            # Format results to match expected format
            formatted_results = []
            for result in search_results:
                formatted_result = {
                    "chunk_id": result.get("chunk_id", ""),
                    "score": result.get("score", 0.0),
                    "content_for_rag": result.get("content_for_rag", ""),
                    "data_type": result.get("data_type", ""),
                    "content_type": result.get("content_type", ""),
                    "structured_data": result.get("structured_data", {}),
                    "file_id": result.get("file_id", ""),
                    "language": result.get("language", ""),
                    "created_at": result.get("created_at", ""),
                    "search_source": result.get("search_source", "comprehensive"),
                    "original_score": result.get(
                        "original_score", result.get("score", 0.0)
                    ),
                }
                formatted_results.append(formatted_result)

            # Limit final results
            final_results = formatted_results[:limit]

            logger.info(
                f"ğŸ¯ Comprehensive hybrid search returned {len(final_results)} chunks"
            )
            for i, result in enumerate(final_results, 1):
                logger.info(
                    f"   {i}. {result['content_type']} (score: {result['score']:.3f}, "
                    f"source: {result['search_source']})"
                )

            return final_results

        except Exception as e:
            logger.error(f"âŒ Comprehensive hybrid search failed: {e}")
            logger.error(f"âŒ Exception type: {type(e)}")
            logger.error(f"âŒ Exception details: {str(e)}")

            # Fallback to basic admin service search
            try:
                logger.info(f"ğŸ”„ Falling back to admin_service search...")
                fallback_result = await self.admin_service.search_company_data(
                    company_id=company_id,
                    query=query,
                    data_types=data_types,
                    limit=limit,
                    score_threshold=score_threshold,
                )
                logger.info(
                    f"ğŸ”„ Admin service fallback returned {len(fallback_result) if fallback_result else 0} results"
                )
                return fallback_result
            except Exception as fallback_error:
                logger.error(f"âŒ Admin service fallback also failed: {fallback_error}")
                return []

    async def stream_response_optimized(
        self, request: UnifiedChatRequest
    ) -> StreamingResponse:
        """
        âœ… FRONTEND OPTIMIZED: 7-step streamlined chat processing with channel routing
        Xá»­ lÃ½ chat tá»‘i Æ°u hÃ³a theo 7 bÆ°á»›c vá»›i routing theo kÃªnh
        """
        # Track processing start time for metrics
        processing_start_time = time.time()

        try:
            company_id = getattr(request, "company_id", "unknown")
            device_id = request.user_info.device_id if request.user_info else "unknown"
            user_query = request.message

            # NEW: Extract channel for routing logic
            channel = request.channel or ChannelType.CHATDEMO

            logger.info(
                f"ğŸš€ [FRONTEND_OPTIMIZED] Starting optimized stream for company {company_id}, device {device_id}"
            )
            logger.info(f"ğŸ“¡ [CHANNEL_ROUTING] Channel: {channel.value}")

            # Extract user information for optimization
            user_id = request.user_info.user_id if request.user_info else None
            user_name = request.user_info.name if request.user_info else None
            session_id = request.session_id

            # NEW: Log lead source if provided
            if request.lead_source:
                logger.info(
                    f"ğŸ“Š [LEAD_SOURCE] {request.lead_source.sourceCode} - {request.lead_source.name}"
                )

            logger.info(
                f"ğŸš€ [FRONTEND_OPTIMIZED] User info - user_id: {user_id}, name: {user_name}"
            )

            # Steps 1, 2, 3, 4: Parallel data fetching with user name support and products list
            # BÆ°á»›c 1, 2, 3, 4: Thu tháº­p dá»¯ liá»‡u song song vá»›i há»— trá»£ tÃªn ngÆ°á»i dÃ¹ng vÃ  danh sÃ¡ch sáº£n pháº©m
            company_data, user_context, company_context, products_list = (
                await asyncio.gather(
                    self._hybrid_search_company_data_optimized(company_id, user_query),
                    self._get_user_context_optimized(
                        device_id, session_id, user_id, user_name
                    ),
                    self._get_company_context_optimized(company_id),
                    self._get_products_list_for_prompt(company_id, user_query),
                    return_exceptions=True,
                )
            )

            # Handle exceptions from parallel tasks
            if isinstance(company_data, Exception):
                logger.warning(f"âš ï¸ Company data search failed: {company_data}")
                company_data = "No relevant company data found."

            if isinstance(user_context, Exception):
                logger.warning(f"âš ï¸ User context retrieval failed: {user_context}")
                user_context = "New user - no previous conversation history."

            if isinstance(company_context, Exception):
                logger.warning(f"âš ï¸ Company context retrieval failed: {company_context}")
                company_context = "No company context available."

            if isinstance(products_list, Exception):
                logger.warning(f"âš ï¸ Products list retrieval failed: {products_list}")
                products_list = "No products data available."

            # Step 4: Build unified prompt with intent detection and user name support
            # BÆ°á»›c 4: XÃ¢y dá»±ng prompt thÃ´ng minh vá»›i há»— trá»£ tÃªn ngÆ°á»i dÃ¹ng

            # Get company name directly from MongoDB instead of parsing text
            company_name = self._get_company_name_from_db(company_id)

            unified_prompt = self._build_unified_prompt_with_intent(
                user_context=user_context,
                company_data=company_data,
                company_context=company_context,
                products_list=products_list,
                user_query=user_query,
                industry=request.industry.value if request.industry else "general",
                company_id=company_id,
                session_id=request.session_id or "unknown",
                user_name=user_name,
                company_name=company_name,
            )

            logger.info(f"ğŸ“ Unified prompt built: {len(unified_prompt)} characters")

            # Step 5: Send to AI Provider with channel-specific routing
            # BÆ°á»›c 5: Gá»­i yÃªu cáº§u Ä‘áº¿n AI Provider vá»›i routing theo kÃªnh
            full_ai_response = ""  # Collect full response for saving
            webhook_response_data = None  # Store webhook response for final message

            async def generate_response():
                nonlocal full_ai_response, webhook_response_data
                try:
                    # CRITICAL: Channel-based response routing
                    # QUAN TRá»ŒNG: Routing response theo channel

                    if channel in [ChannelType.CHATDEMO, ChannelType.CHAT_PLUGIN]:
                        # FRONTEND CHANNELS: Stream directly to frontend + send callback to backend
                        # CÃC KÃŠNH FRONTEND: Stream trá»±c tiáº¿p vá» frontend + gá»­i callback vá» backend
                        logger.info(
                            f"ğŸ“¡ [CHANNEL_ROUTING] âœ… FRONTEND channel detected: {channel.value} - streaming to frontend"
                        )

                        async for chunk in self.ai_manager.stream_response(
                            question=unified_prompt,
                            user_id=(
                                request.user_info.user_id if request.user_info else None
                            ),
                            provider="cerebras",  # Default provider
                        ):
                            if chunk.strip():
                                # Accumulate full response for database saving
                                full_ai_response += chunk

                                # Frontend will parse the full JSON response to extract final_answer
                                # AI Service just streams the raw chunks and sends complete JSON at end
                                # Frontend tá»± parse JSON Ä‘á»ƒ extract final_answer, AI Service chá»‰ stream raw chunks
                                yield f"data: {json.dumps({'chunk': chunk, 'type': 'content'})}\n\n"

                        # Parse final response and send structured data
                        parsed_ai_response = self._parse_ai_json_response(
                            full_ai_response
                        )

                        # ğŸ”„ CHECK: If we have webhook response, use it to override final_answer
                        # ğŸ”„ KIá»‚M TRA: Náº¿u cÃ³ webhook response, sá»­ dá»¥ng nÃ³ Ä‘á»ƒ thay tháº¿ final_answer
                        if webhook_response_data and webhook_response_data.get(
                            "user_message"
                        ):
                            logger.info(
                                "ğŸ¯ [WEBHOOK_OVERRIDE] Using webhook response as final answer"
                            )
                            parsed_ai_response["final_answer"] = webhook_response_data[
                                "user_message"
                            ]
                            # Also update the original response for database saving
                            full_ai_response = json.dumps(
                                {
                                    **parsed_ai_response,
                                    "webhook_data": webhook_response_data,
                                    "original_ai_response": full_ai_response,
                                }
                            )

                        # Send completion with structured data
                        completion_data = {
                            "type": "done",
                            "structured_response": parsed_ai_response,
                        }
                        yield f"data: {json.dumps(completion_data)}\n\n"

                        # âœ¨ NEW: Send callback to backend for both chatdemo and chat-plugin
                        # âœ¨ Má»šI: Gá»­i callback vá» backend cho cáº£ chatdemo vÃ  chat-plugin
                        if channel in [ChannelType.CHATDEMO, ChannelType.CHAT_PLUGIN]:
                            logger.info(
                                f"ğŸ“¤ [CHANNEL_ROUTING] Sending callback to backend for {channel.value}"
                            )
                            # Send structured response to backend as callback
                            await self._send_response_to_backend(
                                request=request,
                                ai_response=full_ai_response,
                                parsed_response=parsed_ai_response,
                                channel=channel,
                                processing_start_time=processing_start_time,
                            )

                    else:
                        # BACKEND CHANNELS: Collect full response and send to backend (messenger, instagram, whatsapp, zalo)
                        # CÃC KÃŠNH BACKEND: Thu tháº­p full response vÃ  gá»­i vá» backend
                        logger.info(
                            f"ğŸ“¡ [CHANNEL_ROUTING] âœ… BACKEND channel detected: {channel.value}"
                        )
                        logger.info(
                            "ğŸ“¡ [CHANNEL_ROUTING] Collecting full response for backend processing"
                        )

                        # Collect full AI response without streaming to requester
                        async for chunk in self.ai_manager.stream_response(
                            question=unified_prompt,
                            user_id=(
                                request.user_info.user_id if request.user_info else None
                            ),
                            provider="cerebras",
                        ):
                            if chunk.strip():
                                full_ai_response += chunk

                        # Parse the full JSON response
                        parsed_ai_response = self._parse_ai_json_response(
                            full_ai_response
                        )

                        # ğŸ” DEBUG: Log raw AI response for analysis
                        logger.info(
                            f"ğŸ” [AI_RESPONSE_DEBUG] Raw AI response length: {len(full_ai_response)} chars"
                        )
                        logger.info(
                            f"ğŸ” [AI_RESPONSE_DEBUG] Raw AI response preview: {full_ai_response[:500]}..."
                        )
                        if "webhook_data" in full_ai_response:
                            logger.info(
                                f"ğŸ” [AI_RESPONSE_DEBUG] Raw response contains 'webhook_data'"
                            )
                        else:
                            logger.info(
                                f"ğŸ” [AI_RESPONSE_DEBUG] Raw response MISSING 'webhook_data'"
                            )

                        # ğŸ” DEBUG: Log parsed structure
                        logger.info(
                            f"ğŸ” [AI_RESPONSE_DEBUG] Parsed response keys: {list(parsed_ai_response.keys())}"
                        )
                        if "webhook_data" in parsed_ai_response:
                            webhook_data = parsed_ai_response["webhook_data"]
                            logger.info(
                                f"ğŸ” [AI_RESPONSE_DEBUG] webhook_data keys: {list(webhook_data.keys())}"
                            )
                        else:
                            logger.info(
                                f"ğŸ” [AI_RESPONSE_DEBUG] Parsed response MISSING 'webhook_data'"
                            )

                        # ğŸ”„ CHECK: If we have webhook response, use it to override final_answer
                        # ğŸ”„ KIá»‚M TRA: Náº¿u cÃ³ webhook response, sá»­ dá»¥ng nÃ³ Ä‘á»ƒ thay tháº¿ final_answer
                        if webhook_response_data and webhook_response_data.get(
                            "user_message"
                        ):
                            logger.info(
                                "ğŸ¯ [WEBHOOK_OVERRIDE] Using webhook response as final answer for backend"
                            )
                            parsed_ai_response["final_answer"] = webhook_response_data[
                                "user_message"
                            ]
                            # Also update the original response for database saving
                            full_ai_response = json.dumps(
                                {
                                    **parsed_ai_response,
                                    "webhook_data": webhook_response_data,
                                    "original_ai_response": full_ai_response,
                                }
                            )

                        # Send structured response to backend for channel processing
                        await self._send_response_to_backend(
                            request=request,
                            ai_response=full_ai_response,
                            parsed_response=parsed_ai_response,
                            channel=channel,
                            processing_start_time=processing_start_time,
                        )

                        # Return success signal to backend caller with structured data
                        success_response = {
                            "type": "backend_processed",
                            "channel": channel.value,
                            "success": True,
                            "structured_response": parsed_ai_response,
                        }
                        yield f"data: {json.dumps(success_response)}\n\n"

                    # Save conversation to database after processing - CRITICAL for user_context
                    logger.info(
                        f"ğŸ’¾ [STREAM_COMPLETE] Full AI response collected: {len(full_ai_response)} chars"
                    )
                    logger.info(
                        f"ğŸ’¾ [STREAM_COMPLETE] Saving conversation for future user_context retrieval"
                    )

                    # Use await instead of create_task to ensure conversation is saved
                    # Sá»­ dá»¥ng await thay vÃ¬ create_task Ä‘á»ƒ Ä‘áº£m báº£o conversation Ä‘Æ°á»£c lÆ°u
                    await self._save_complete_conversation_async(
                        request=request,
                        company_id=company_id,
                        user_query=user_query,
                        ai_response=full_ai_response,
                    )

                    logger.info(
                        f"âœ… [STREAM_COMPLETE] Conversation saved successfully for user_context"
                    )

                except Exception as e:
                    logger.error(f"âŒ [STREAM_ERROR] Error in generate_response: {e}")
                    yield f"data: {json.dumps({'chunk': f'Error: {str(e)}', 'type': 'error'})}\n\n"

            # Step 6: Create streaming response
            # BÆ°á»›c 6: Stream dá»¯ liá»‡u vá» caller (frontend hoáº·c backend)
            response = StreamingResponse(
                generate_response(),
                media_type="text/plain",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                    "X-Accel-Buffering": "no",
                    "X-Channel-Type": channel.value,  # NEW: Include channel in response headers
                },
            )

            return response

        except Exception as e:
            logger.error(f"âŒ Optimized stream failed: {e}")
            raise

    async def _send_response_to_backend(
        self,
        request: UnifiedChatRequest,
        ai_response: str,
        channel: ChannelType,
        parsed_response: Dict[str, Any] = None,
        processing_start_time: float = None,
    ):
        """
        Send AI response to backend for channel-specific processing
        Gá»­i AI response vá» backend Ä‘á»ƒ xá»­ lÃ½ theo kÃªnh cá»¥ thá»ƒ
        """
        try:
            logger.info(
                f"ğŸ“¤ [BACKEND_ROUTING] Sending response to backend for channel: {channel.value}"
            )

            # Here you would implement the actual backend communication
            # á» Ä‘Ã¢y báº¡n sáº½ implement giao tiáº¿p thá»±c táº¿ vá»›i backend

            # This could be:
            # 1. HTTP POST to backend endpoint
            # 2. Message queue (Redis/RabbitMQ)
            # 3. WebSocket to backend
            # 4. Direct function call if backend and AI service are in same codebase

            # Use parsed response if provided, otherwise parse from raw response
            if parsed_response is None:
                parsed_response = self._parse_ai_json_response(ai_response)

            logger.info(
                f"ğŸ§  [BACKEND_ROUTING] Using parsed response - Intent: {parsed_response.get('intent', 'unknown')}"
            )
            logger.info(
                f"ğŸ¯ [BACKEND_ROUTING] Language: {parsed_response.get('language', 'unknown')}"
            )
            logger.info(
                f"ğŸ“ [BACKEND_ROUTING] Final answer length: {len(parsed_response.get('final_answer', ''))}"
            )

            # Calculate actual processing time
            processing_time_ms = 0
            if processing_start_time:
                processing_time_ms = int((time.time() - processing_start_time) * 1000)

            # Get actual token usage from AI response metadata if available
            # Calculate token usage based on word count (approximate)
            prompt_tokens = len(request.message.split()) if request.message else 0
            completion_tokens = len(ai_response.split()) if ai_response else 0

            token_usage = {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": prompt_tokens + completion_tokens,
            }

            # Try to extract token usage from parsed response metadata (if AI provides it)
            if parsed_response and "metadata" in parsed_response:
                metadata = parsed_response["metadata"]
                if "token_usage" in metadata:
                    # Use AI provider's actual token count if available
                    provider_tokens = metadata["token_usage"]
                    if provider_tokens.get("total_tokens", 0) > 0:
                        token_usage = provider_tokens

            # Log actual metrics for monitoring
            logger.info(f"ğŸ“Š [METRICS] Processing time: {processing_time_ms}ms")
            logger.info(f"ğŸ“Š [METRICS] Token usage: {token_usage}")

            # ğŸ›’ NEW: Check intent types and handle accordingly
            detected_intent = parsed_response.get("thinking", {}).get(
                "intent", "unknown"
            )
            logger.info(f"ğŸ¯ [INTENT_CHECK] Detected intent: {detected_intent}")

            # PLACE_ORDER intent handling (updated to use complete flag)
            if detected_intent == "PLACE_ORDER":
                logger.info(
                    "ğŸ” [PLACE_ORDER_CHECK] PLACE_ORDER intent detected, checking if ready for webhook..."
                )
                is_order_ready = self._is_order_ready_for_webhook(parsed_response)
                logger.info(
                    f"ğŸ” [PLACE_ORDER_CHECK] Order webhook ready: {is_order_ready}"
                )
                is_order_completion = is_order_ready
            else:
                is_order_completion = False

            # UPDATE_ORDER intent handling (new)
            is_update_order = detected_intent == "UPDATE_ORDER"

            # CHECK_QUANTITY intent handling (new) - CHá»ˆ gá»­i webhook khi cÃ³ Ä‘á»§ thÃ´ng tin liÃªn há»‡
            is_check_quantity = (
                detected_intent == "CHECK_QUANTITY"
                and self._is_check_quantity_webhook_ready(
                    parsed_response, request.message
                )
            )

            # Log detected intents
            if is_order_completion:
                logger.info(
                    "ğŸ›’ [ORDER_DETECTION] Order completion detected, will send order.created webhook"
                )
            elif is_update_order:
                logger.info(
                    "ğŸ”„ [UPDATE_ORDER_DETECTION] Update order intent detected, will send update webhook"
                )
            elif is_check_quantity:
                logger.info(
                    "ğŸ“Š [CHECK_QUANTITY_DETECTION] Check quantity intent detected, will send quantity check webhook"
                )

            # Build payload theo documentation schema vá»›i chat-plugin support
            if channel in [ChannelType.CHATDEMO, ChannelType.CHAT_PLUGIN]:
                # Frontend channels callback with full JSON structure
                # Different event types for different frontend channels
                event_type = (
                    "ai.response.plugin.completed"  # Unified event for frontend
                )

                # ğŸ” DEBUG: Check AI response parsing for frontend
                response_content = parsed_response.get("final_answer", "")
                logger.info(
                    f"ğŸ” [FRONTEND_WEBHOOK] Response content length: {len(response_content)}"
                )
                logger.info(
                    f"ğŸ” [FRONTEND_WEBHOOK] Response preview: {response_content[:100]}..."
                )
                logger.info(
                    f"ğŸ” [FRONTEND_WEBHOOK] Parsed keys: {list(parsed_response.keys())}"
                )

                # Extract user info from frontend request
                user_info_data = None
                if request.user_info:
                    user_info_data = {
                        "user_id": request.user_info.user_id,
                        "device_id": request.user_info.device_id,
                        "source": (
                            request.user_info.source.value
                            if hasattr(request.user_info.source, "value")
                            else str(request.user_info.source)
                        ),
                        "name": request.user_info.name,
                        "email": request.user_info.email,
                    }
                    # Filter out None values
                    user_info_data = {
                        k: v for k, v in user_info_data.items() if v is not None
                    }

                # Extract thinking details from AI response
                thinking_data = parsed_response.get("thinking", {})
                if isinstance(thinking_data, dict):
                    thinking_extracted = {
                        "intent": thinking_data.get("intent", "unknown"),
                        "persona": thinking_data.get("persona", "unknown"),
                        "reasoning": thinking_data.get("reasoning", ""),
                    }
                else:
                    thinking_extracted = {
                        "intent": "unknown",
                        "persona": "unknown",
                        "reasoning": str(thinking_data) if thinking_data else "",
                    }

                webhook_data = {
                    "messageId": request.message_id,
                    "conversationId": getattr(
                        request, "conversation_id", request.session_id
                    ),
                    "processingTime": processing_time_ms / 1000,  # Convert to seconds
                    "channel": channel.value,
                    "userInfo": user_info_data,  # âœ… Added user info from frontend
                    "thinking": thinking_extracted,  # âœ… Added thinking details from AI
                    # ğŸ†• STRUCTURED: User message and AI response for full conversation context
                    "userMessage": {
                        "content": request.message,
                        "messageId": request.message_id,
                        "timestamp": datetime.now().isoformat(),
                    },
                    "aiResponse": {
                        "content": parsed_response.get("final_answer", ai_response),
                        "messageId": f"{request.message_id}_ai",
                        "timestamp": datetime.now().isoformat(),
                    },
                    "metadata": {
                        "streaming": True,
                        "language": parsed_response.get("language", "VIETNAMESE"),
                        "ai_provider": "cerebras",
                        "model": "qwen-3-235b-a22b-instruct-2507",
                        "token_usage": token_usage,
                    },
                }

                # Add plugin-specific fields for chat-plugin channel
                if channel == ChannelType.CHAT_PLUGIN:
                    webhook_data["pluginId"] = request.plugin_id
                    webhook_data["customerDomain"] = request.customer_domain

                backend_payload = {
                    "event": event_type,
                    "companyId": request.company_id,
                    "timestamp": datetime.now().isoformat(),
                    "data": webhook_data,
                    "metadata": {},
                }
            else:
                # Backend channels (messenger, instagram, whatsapp, zalo)

                # Extract user info from frontend request for backend channels too
                user_info_data = None
                if request.user_info:
                    user_info_data = {
                        "user_id": request.user_info.user_id,
                        "device_id": request.user_info.device_id,
                        "source": (
                            request.user_info.source.value
                            if hasattr(request.user_info.source, "value")
                            else str(request.user_info.source)
                        ),
                        "name": request.user_info.name,
                        "email": request.user_info.email,
                    }
                    # Filter out None values
                    user_info_data = {
                        k: v for k, v in user_info_data.items() if v is not None
                    }

                # Extract thinking details from AI response
                thinking_data = parsed_response.get("thinking", {})
                if isinstance(thinking_data, dict):
                    thinking_extracted = {
                        "intent": thinking_data.get("intent", "unknown"),
                        "persona": thinking_data.get("persona", "unknown"),
                        "reasoning": thinking_data.get("reasoning", ""),
                    }
                else:
                    thinking_extracted = {
                        "intent": "unknown",
                        "persona": "unknown",
                        "reasoning": str(thinking_data) if thinking_data else "",
                    }

                webhook_data = {
                    "messageId": request.message_id,
                    "conversationId": getattr(
                        request, "conversation_id", request.session_id
                    ),
                    "response": parsed_response.get("final_answer", ""),
                    "processingTime": processing_time_ms / 1000,  # Convert to seconds
                    "channel": channel.value,
                    "userInfo": user_info_data,  # âœ… Added user info from frontend
                    "thinking": thinking_extracted,  # âœ… Added thinking details from AI
                    "metadata": {
                        "language": parsed_response.get("language", "VIETNAMESE"),
                        "ai_provider": "cerebras",
                        "model": "qwen-3-235b-a22b-instruct-2507",
                        "token_usage": token_usage,
                    },
                }

                # âœ… Add plugin-specific fields for chat-plugin channel (backend processing too)
                if channel == ChannelType.CHAT_PLUGIN:
                    webhook_data["pluginId"] = request.plugin_id
                    webhook_data["customerDomain"] = request.customer_domain

                backend_payload = {
                    "event": "ai.response.completed",
                    "companyId": request.company_id,
                    "timestamp": datetime.now().isoformat(),
                    "data": webhook_data,
                    "metadata": {},
                }

            # Send webhook to backend vá»›i updated schema
            import httpx
            import os

            backend_url = os.getenv("BACKEND_WEBHOOK_URL", "http://localhost:8001")
            endpoint = f"{backend_url}/api/webhooks/ai/conversation"  # Updated endpoint

            # Simple webhook secret as header (from .env)
            webhook_secret = os.getenv("WEBHOOK_SECRET", "webhook-secret-for-signature")

            headers = {
                "Content-Type": "application/json",
                "X-Webhook-Source": "ai-service",
                "X-Webhook-Secret": webhook_secret,
                "User-Agent": "Agent8x-AI-Service/1.0",
            }

            # ğŸ” Log full webhook payload for debugging
            logger.info(f"ğŸ” [WEBHOOK_PAYLOAD] Sending to backend: {endpoint}")
            logger.info(f"ğŸ” [WEBHOOK_PAYLOAD] Event: {backend_payload['event']}")
            logger.info(f"ğŸ” [WEBHOOK_PAYLOAD] Company: {backend_payload['companyId']}")
            logger.info(
                f"ğŸ” [WEBHOOK_PAYLOAD] Data keys: {list(backend_payload['data'].keys())}"
            )

            # Log userMessage and aiResponse specifically
            if "userMessage" in backend_payload["data"]:
                user_msg = backend_payload["data"]["userMessage"]
                logger.info(
                    f"ğŸ” [WEBHOOK_PAYLOAD] userMessage.content: '{user_msg.get('content', 'MISSING')[:100]}...'"
                )
                logger.info(
                    f"ğŸ” [WEBHOOK_PAYLOAD] userMessage.messageId: {user_msg.get('messageId', 'MISSING')}"
                )
            else:
                logger.error(f"âŒ [WEBHOOK_PAYLOAD] userMessage field is MISSING!")

            if "aiResponse" in backend_payload["data"]:
                ai_msg = backend_payload["data"]["aiResponse"]
                logger.info(
                    f"ğŸ” [WEBHOOK_PAYLOAD] aiResponse.content: '{ai_msg.get('content', 'MISSING')[:100]}...'"
                )
                logger.info(
                    f"ğŸ” [WEBHOOK_PAYLOAD] aiResponse.messageId: {ai_msg.get('messageId', 'MISSING')}"
                )
            else:
                logger.error(f"âŒ [WEBHOOK_PAYLOAD] aiResponse field is MISSING!")

            # ğŸ“„ Save full payload to file for debugging
            import json
            import os

            # Create debug directory if it doesn't exist
            debug_dir = "debug_webhook_payloads"
            os.makedirs(debug_dir, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            payload_filename = f"webhook_payload_{request.company_id}_{request.session_id}_{timestamp}.json"
            full_path = os.path.join(debug_dir, payload_filename)

            try:
                with open(full_path, "w", encoding="utf-8") as f:
                    json.dump(backend_payload, f, indent=2, ensure_ascii=False)
                logger.info(f"ğŸ“„ [WEBHOOK_PAYLOAD] Full payload saved to: {full_path}")
            except Exception as e:
                logger.error(f"âŒ [WEBHOOK_PAYLOAD] Failed to save payload file: {e}")

            async with httpx.AsyncClient() as client:
                response = await client.post(
                    endpoint,
                    json=backend_payload,
                    headers=headers,
                    timeout=30.0,
                )

                if response.status_code == 200:
                    logger.info(
                        f"âœ… [BACKEND_ROUTING] Successfully sent to backend for {channel.value}"
                    )

                    # ğŸ›’ DUAL WEBHOOK: Send order creation webhook if this is a completed order
                    if is_order_completion:
                        logger.info(
                            "ğŸ›’ [DUAL_WEBHOOK] Sending order creation webhook after conversation webhook success"
                        )

                        # Try to get order data directly from AI response webhook_data first
                        order_data = None
                        if parsed_response.get("webhook_data", {}).get("order_data"):
                            order_data = parsed_response["webhook_data"]["order_data"]
                            logger.info(
                                "âœ… [DUAL_WEBHOOK] Using webhook_data from AI response"
                            )
                        else:
                            # Fallback: Extract order data using secondary AI call
                            logger.info(
                                "âš ï¸ [DUAL_WEBHOOK] No webhook_data, falling back to extraction"
                            )
                            order_data = await self._extract_order_data_from_response(
                                parsed_response, request.message
                            )

                        if order_data:
                            order_webhook_success = (
                                await self._send_order_created_webhook(
                                    request=request,
                                    order_data=order_data,
                                    processing_start_time=processing_start_time,
                                )
                            )

                            if order_webhook_success:
                                logger.info(
                                    "âœ… [DUAL_WEBHOOK] Order creation webhook sent successfully"
                                )
                            else:
                                logger.error(
                                    "âŒ [DUAL_WEBHOOK] Failed to send order creation webhook"
                                )
                        else:
                            logger.error(
                                "âŒ [DUAL_WEBHOOK] Could not extract order data from AI response"
                            )

                    # ğŸ”„ UPDATE_ORDER WEBHOOK: Handle order update requests
                    elif is_update_order:
                        logger.info(
                            "ğŸ”„ [UPDATE_ORDER_WEBHOOK] Sending order update webhook after conversation webhook success"
                        )

                        # Try to get update data directly from AI response webhook_data first
                        update_data = None
                        if parsed_response.get("webhook_data", {}).get("update_data"):
                            update_data = parsed_response["webhook_data"]["update_data"]
                            logger.info(
                                "âœ… [UPDATE_ORDER_WEBHOOK] Using webhook_data from AI response"
                            )
                            logger.info(
                                f"ğŸ”„ [UPDATE_ORDER_WEBHOOK] Complete flag: {update_data.get('complete', False)}"
                            )
                        else:
                            # Fallback: Extract update data using secondary AI call
                            logger.info(
                                "âš ï¸ [UPDATE_ORDER_WEBHOOK] No webhook_data, falling back to extraction"
                            )
                            update_data = await self._extract_update_order_data(
                                parsed_response, request.message
                            )

                        # Validate update data has complete flag and valid order code
                        if (
                            update_data
                            and update_data.get("complete", False) == True
                            and update_data.get("order_code")
                            and update_data.get("order_code") != "UNKNOWN"
                        ):

                            logger.info(
                                f"âœ… [UPDATE_ORDER_WEBHOOK] Valid update data - Order: {update_data.get('order_code')}"
                            )
                            webhook_response_data = (
                                await self._handle_update_order_webhook(
                                    request=request,
                                    update_data=update_data,
                                    processing_start_time=processing_start_time,
                                )
                            )
                            logger.info(
                                f"ğŸ”„ [UPDATE_ORDER_WEBHOOK] Webhook response received: {webhook_response_data.get('success', False)}"
                            )
                        else:
                            logger.error(
                                f"âŒ [UPDATE_ORDER_WEBHOOK] Invalid update data - Complete: {update_data.get('complete', False) if update_data else 'No data'}, Order Code: {update_data.get('order_code', 'Missing') if update_data else 'No data'}"
                            )

                    # ğŸ“Š CHECK_QUANTITY WEBHOOK: Handle quantity check requests
                    elif is_check_quantity:
                        logger.info(
                            "ğŸ“Š [CHECK_QUANTITY_WEBHOOK] Sending quantity check webhook after conversation webhook success"
                        )

                        # Try to get quantity data directly from AI response webhook_data first
                        quantity_data = None
                        if parsed_response.get("webhook_data", {}).get(
                            "check_quantity_data"
                        ):
                            quantity_data = parsed_response["webhook_data"][
                                "check_quantity_data"
                            ]
                            logger.info(
                                "âœ… [CHECK_QUANTITY_WEBHOOK] Using webhook_data from AI response"
                            )
                        else:
                            # Fallback: Extract quantity data using secondary AI call
                            logger.info(
                                "âš ï¸ [CHECK_QUANTITY_WEBHOOK] No webhook_data, falling back to extraction"
                            )
                            quantity_data = await self._extract_check_quantity_data(
                                parsed_response, request.message
                            )

                        if quantity_data:
                            webhook_response_data = (
                                await self._handle_check_quantity_webhook(
                                    request=request,
                                    quantity_data=quantity_data,
                                    processing_start_time=processing_start_time,
                                )
                            )
                            logger.info(
                                f"ğŸ“Š [CHECK_QUANTITY_WEBHOOK] Webhook response received: {webhook_response_data.get('success', False)}"
                            )
                        else:
                            logger.error(
                                "âŒ [CHECK_QUANTITY_WEBHOOK] Could not extract quantity check data"
                            )

                    # ğŸ¯ Update conversation intent from AI response after successful webhook
                    try:
                        intent_updated = await webhook_service.update_conversation_intent_from_ai_response(
                            company_id=request.company_id,
                            conversation_id=getattr(
                                request, "conversation_id", request.session_id
                            ),
                            full_ai_response=ai_response,
                        )
                        if intent_updated:
                            logger.info(
                                f"âœ… Intent updated from AI response for conversation"
                            )
                        else:
                            logger.warning(
                                f"âš ï¸ Could not update intent from AI response"
                            )
                    except Exception as intent_error:
                        logger.error(
                            f"âŒ Error updating intent from AI response: {intent_error}"
                        )

                else:
                    logger.error(
                        f"âŒ [BACKEND_ROUTING] Backend returned {response.status_code}: {response.text}"
                    )

        except Exception as e:
            logger.error(f"âŒ [BACKEND_ROUTING] Failed to send to backend: {e}")
            # Don't raise exception - this shouldn't break the main flow
            # KhÃ´ng raise exception - Ä‘iá»u nÃ y khÃ´ng nÃªn phÃ¡ vá»¡ luá»“ng chÃ­nh

    def _is_check_quantity_webhook_ready(
        self, parsed_response: Dict[str, Any], user_message: str
    ) -> bool:
        """
        Check if CHECK_QUANTITY intent should trigger webhook
        Chá»‰ gá»­i webhook khi khÃ¡ch hÃ ng Ä‘Ã£ cung cáº¥p thÃ´ng tin liÃªn há»‡ vÃ  xÃ¡c nháº­n gá»­i yÃªu cáº§u
        """
        try:
            # 1. Kiá»ƒm tra xem cÃ³ webhook_data trong AI response khÃ´ng
            webhook_data = parsed_response.get("webhook_data", {}).get(
                "check_quantity_data"
            )
            if not webhook_data:
                logger.info(
                    "ğŸ“Š [CHECK_QUANTITY_READY] No webhook_data in AI response - not ready"
                )
                return False

            # 2. Kiá»ƒm tra xem cÃ³ thÃ´ng tin khÃ¡ch hÃ ng khÃ´ng (tÃªn + phone/email)
            customer_data = webhook_data.get("customer", {})
            has_name = customer_data.get("name", "").strip() not in [
                "",
                "KhÃ¡ch hÃ ng",
                "Unknown",
            ]
            has_contact = (
                customer_data.get("phone", "").strip()
                or customer_data.get("email", "").strip()
            )

            if not (has_name and has_contact):
                logger.info(
                    "ğŸ“Š [CHECK_QUANTITY_READY] Missing customer info (name + contact) - not ready"
                )
                return False

            # 3. Kiá»ƒm tra xem cÃ³ item_name khÃ´ng
            item_name = webhook_data.get("item_name", "").strip()
            if not item_name or item_name in ["KhÃ´ng xÃ¡c Ä‘á»‹nh", "Unknown"]:
                logger.info(
                    "ğŸ“Š [CHECK_QUANTITY_READY] Missing or invalid item_name - not ready"
                )
                return False

            # 4. Kiá»ƒm tra final_answer cÃ³ chá»©a tá»« khÃ³a xÃ¡c nháº­n gá»­i yÃªu cáº§u khÃ´ng
            final_answer = parsed_response.get("final_answer", "").lower()
            confirmation_phrases = [
                "Ä‘Ã£ gá»­i yÃªu cáº§u",
                "tÃ´i Ä‘Ã£ gá»­i",
                "em Ä‘Ã£ gá»­i",
                "gá»­i yÃªu cáº§u cá»§a báº¡n",
                "gá»­i yÃªu cáº§u Ä‘áº¿n bá»™ pháº­n",
                "há» sáº½ liÃªn há»‡",
                "sáº½ liÃªn há»‡ láº¡i",
                "bá»™ pháº­n liÃªn quan sáº½",
            ]

            has_confirmation = any(
                phrase in final_answer for phrase in confirmation_phrases
            )
            if not has_confirmation:
                logger.info(
                    "ğŸ“Š [CHECK_QUANTITY_READY] No confirmation message in final_answer - not ready"
                )
                return False

            logger.info(
                "âœ… [CHECK_QUANTITY_READY] All conditions met - ready to send webhook"
            )
            logger.info(
                f"   ğŸ‘¤ Customer: {customer_data.get('name')} - {customer_data.get('phone', customer_data.get('email'))}"
            )
            logger.info(f"   ğŸ“¦ Item: {item_name}")

            return True

        except Exception as e:
            logger.error(
                f"âŒ [CHECK_QUANTITY_READY] Error checking webhook readiness: {e}"
            )
            return False

    def _is_order_ready_for_webhook(self, parsed_response: Dict[str, Any]) -> bool:
        """
        Check if order is ready for webhook based on 'complete' flag in webhook_data
        Kiá»ƒm tra xem Ä‘Æ¡n hÃ ng Ä‘Ã£ sáºµn sÃ ng gá»­i webhook dá»±a trÃªn flag 'complete' trong webhook_data
        """
        try:
            # ğŸ” DEBUG: Log full parsed response structure
            logger.info(
                f"ğŸ” [ORDER_WEBHOOK_CHECK] Checking parsed_response keys: {list(parsed_response.keys())}"
            )

            # Get webhook_data from AI response
            webhook_data = parsed_response.get("webhook_data", {})
            logger.info(
                f"ğŸ” [ORDER_WEBHOOK_CHECK] webhook_data keys: {list(webhook_data.keys()) if webhook_data else 'None'}"
            )

            order_data = webhook_data.get("order_data", {})
            logger.info(
                f"ğŸ” [ORDER_WEBHOOK_CHECK] order_data keys: {list(order_data.keys()) if order_data else 'None'}"
            )

            # Check if complete flag is set to true
            is_complete = order_data.get("complete", False)
            logger.info(f"ğŸ›’ [ORDER_WEBHOOK_CHECK] Complete flag: {is_complete}")

            if is_complete:
                # Verify basic required information exists
                has_items = bool(order_data.get("items"))
                customer_data = order_data.get("customer", {})
                has_customer_info = bool(
                    customer_data.get("name") and customer_data.get("phone")
                )

                logger.info(f"ğŸ›’ [ORDER_WEBHOOK_CHECK] Has items: {has_items}")
                logger.info(
                    f"ğŸ›’ [ORDER_WEBHOOK_CHECK] Has customer info: {has_customer_info}"
                )

                # ğŸ” DEBUG: Log detailed order data
                if has_items:
                    items_count = len(order_data.get("items", []))
                    logger.info(f"ğŸ›’ [ORDER_WEBHOOK_CHECK] Items count: {items_count}")
                    for i, item in enumerate(order_data.get("items", [])):
                        logger.info(
                            f"ğŸ›’ [ORDER_WEBHOOK_CHECK] Item {i+1}: {item.get('name', 'Unknown')} x {item.get('quantity', 1)}"
                        )

                if has_customer_info:
                    logger.info(
                        f"ğŸ›’ [ORDER_WEBHOOK_CHECK] Customer: {customer_data.get('name', '')} - {customer_data.get('phone', '')}"
                    )

                return has_items and has_customer_info
            else:
                logger.info(
                    f"ğŸ›’ [ORDER_WEBHOOK_CHECK] Order not complete - complete flag is {is_complete}"
                )

            return False

        except Exception as e:
            logger.error(
                f"âŒ [ORDER_WEBHOOK_CHECK] Error checking order readiness: {e}"
            )
            return False

    async def _extract_order_data_from_conversation(
        self, request: UnifiedChatRequest, parsed_response: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        Extract order information from conversation history
        TrÃ­ch xuáº¥t thÃ´ng tin Ä‘Æ¡n hÃ ng tá»« lá»‹ch sá»­ há»™i thoáº¡i
        """
        try:
            # Get conversation history
            user_id = request.user_info.user_id if request.user_info else None
            device_id = request.user_info.device_id if request.user_info else None
            session_id = request.session_id

            conversation_history = []
            if self.conversation_manager:
                history = self.conversation_manager.get_optimized_messages_for_frontend(
                    user_id=user_id,
                    device_id=device_id,
                    session_id=session_id,
                    rag_context="",
                    current_query="",
                )
                conversation_history = [f"{msg.role}: {msg.content}" for msg in history]

            # Add current exchange
            conversation_history.append(f"user: {request.message}")
            conversation_history.append(
                f"assistant: {parsed_response.get('final_answer', '')}"
            )

            conversation_text = "\n".join(
                conversation_history[-10:]
            )  # Last 10 messages

            # Use AI to extract structured order data
            extraction_prompt = f"""
Tá»« cuá»™c há»™i thoáº¡i sau, hÃ£y trÃ­ch xuáº¥t thÃ´ng tin Ä‘Æ¡n hÃ ng thÃ nh JSON format:

{conversation_text}

Tráº£ vá» JSON vá»›i format:
{{
  "items": [
    {{
      "name": "tÃªn sáº£n pháº©m",
      "quantity": sá»‘_lÆ°á»£ng,
      "unitPrice": giÃ¡_Ä‘Æ¡n_vá»‹,
      "description": "mÃ´ táº£"
    }}
  ],
  "customer": {{
    "name": "tÃªn khÃ¡ch hÃ ng",
    "phone": "sá»‘ Ä‘iá»‡n thoáº¡i",
    "email": "email",
    "address": "Ä‘á»‹a chá»‰"
  }},
  "delivery": {{
    "method": "delivery hoáº·c pickup",
    "address": "Ä‘á»‹a chá»‰ giao hÃ ng",
    "notes": "ghi chÃº"
  }},
  "payment": {{
    "method": "cash/bank_transfer/credit_card",
    "timing": "tráº£ ngay hoáº·c tráº£ sau"
  }},
  "notes": "ghi chÃº khÃ¡c"
}}

Chá»‰ tráº£ vá» JSON, khÃ´ng cÃ³ text khÃ¡c.
"""

            # Call AI to extract order data
            extraction_response = await self.ai_manager.stream_response(
                question=extraction_prompt, provider="cerebras"
            )

            full_extraction = ""
            async for chunk in extraction_response:
                full_extraction += chunk

            # Parse JSON from AI response
            json_match = re.search(r"\{.*\}", full_extraction, re.DOTALL)
            if json_match:
                order_data = json.loads(json_match.group(0))
                logger.info("ğŸ›’ [ORDER_EXTRACTION] Successfully extracted order data")
                return order_data
            else:
                logger.warning(
                    "ğŸ›’ [ORDER_EXTRACTION] No valid JSON found in extraction response"
                )
                return None

        except Exception as e:
            logger.error(f"âŒ [ORDER_EXTRACTION] Failed to extract order data: {e}")
            return None

    async def _extract_order_data_from_response(
        self, parsed_response: Dict[str, Any], user_message: str
    ) -> Optional[Dict[str, Any]]:
        """
        Extract order data from AI response when webhook_data is not available
        TrÃ­ch xuáº¥t dá»¯ liá»‡u Ä‘Æ¡n hÃ ng tá»« AI response khi khÃ´ng cÃ³ webhook_data
        """
        try:
            final_answer = parsed_response.get("final_answer", "")

            # Use AI to extract structured order data from the response
            extraction_prompt = f"""
Tá»« cÃ¢u tráº£ lá»i AI vÃ  tin nháº¯n cá»§a khÃ¡ch hÃ ng, hÃ£y trÃ­ch xuáº¥t thÃ´ng tin Ä‘Æ¡n hÃ ng thÃ nh JSON format:

Tin nháº¯n khÃ¡ch hÃ ng: {user_message}
CÃ¢u tráº£ lá»i AI: {final_answer}

Tráº£ vá» JSON vá»›i format:
{{
  "items": [
    {{
      "name": "tÃªn sáº£n pháº©m/dá»‹ch vá»¥",
      "quantity": sá»‘_lÆ°á»£ng,
      "unitPrice": giÃ¡_Ä‘Æ¡n_vá»‹,
      "description": "mÃ´ táº£ chi tiáº¿t"
    }}
  ],
  "customer": {{
    "name": "tÃªn khÃ¡ch hÃ ng",
    "phone": "sá»‘ Ä‘iá»‡n thoáº¡i",
    "email": "email",
    "address": "Ä‘á»‹a chá»‰"
  }},
  "delivery": {{
    "method": "delivery hoáº·c pickup",
    "address": "Ä‘á»‹a chá»‰ giao hÃ ng",
    "notes": "ghi chÃº giao hÃ ng"
  }},
  "payment": {{
    "method": "COD/bank_transfer/credit_card",
    "timing": "on_delivery/prepaid",
    "status": "PENDING"
  }},
  "notes": "ghi chÃº Ä‘áº·c biá»‡t"
}}

Chá»‰ tráº£ vá» JSON, khÃ´ng cÃ³ text khÃ¡c.
"""

            # Call AI to extract order data
            extraction_response = await self.ai_manager.stream_response(
                question=extraction_prompt, provider="cerebras"
            )

            full_extraction = ""
            async for chunk in extraction_response:
                full_extraction += chunk

            # Parse JSON from AI response
            json_match = re.search(r"\{.*\}", full_extraction, re.DOTALL)
            if json_match:
                order_data = json.loads(json_match.group(0))
                logger.info(
                    "ğŸ›’ [ORDER_EXTRACTION_FROM_RESPONSE] Successfully extracted order data"
                )
                return order_data
            else:
                logger.warning(
                    "ğŸ›’ [ORDER_EXTRACTION_FROM_RESPONSE] No valid JSON found"
                )
                return None

        except Exception as e:
            logger.error(f"âŒ [ORDER_EXTRACTION_FROM_RESPONSE] Failed: {e}")
            return None

    async def _extract_update_order_data(
        self, parsed_response: Dict[str, Any], user_message: str
    ) -> Optional[Dict[str, Any]]:
        """
        Extract order update data from AI response when webhook_data is not available
        TrÃ­ch xuáº¥t dá»¯ liá»‡u cáº­p nháº­t Ä‘Æ¡n hÃ ng tá»« AI response khi khÃ´ng cÃ³ webhook_data
        """
        try:
            final_answer = parsed_response.get("final_answer", "")

            # Use AI to extract structured update data from the response
            extraction_prompt = f"""
Tá»« cÃ¢u tráº£ lá»i AI vÃ  tin nháº¯n cá»§a khÃ¡ch hÃ ng, hÃ£y trÃ­ch xuáº¥t thÃ´ng tin cáº­p nháº­t Ä‘Æ¡n hÃ ng thÃ nh JSON format:

Tin nháº¯n khÃ¡ch hÃ ng: {user_message}
CÃ¢u tráº£ lá»i AI: {final_answer}

Tráº£ vá» JSON vá»›i format cho UPDATE_ORDER:
{{
  "orderCode": "mÃ£ Ä‘Æ¡n hÃ ng náº¿u cÃ³ trong conversation",
  "updateType": "change_date/change_quantity/change_items/cancel",
  "changes": {{
    "checkInDate": "ngÃ y má»›i náº¿u thay Ä‘á»•i ngÃ y",
    "quantity": sá»‘_lÆ°á»£ng_má»›i,
    "items": [...],
    "notes": "lÃ½ do thay Ä‘á»•i"
  }},
  "customer": {{
    "name": "tÃªn khÃ¡ch hÃ ng",
    "phone": "sá»‘ Ä‘iá»‡n thoáº¡i",
    "email": "email"
  }},
  "companyId": "company_id_náº¿u_cÃ³"
}}

Náº¿u khÃ´ng tÃ¬m tháº¥y mÃ£ Ä‘Æ¡n hÃ ng cá»¥ thá»ƒ, dÃ¹ng "UNKNOWN" cho orderCode.
Chá»‰ tráº£ vá» JSON, khÃ´ng cÃ³ text khÃ¡c.
"""

            # Call AI to extract update data
            extraction_response = await self.ai_manager.stream_response(
                question=extraction_prompt, provider="cerebras"
            )

            full_extraction = ""
            async for chunk in extraction_response:
                full_extraction += chunk

            # Parse JSON from AI response
            json_match = re.search(r"\{.*\}", full_extraction, re.DOTALL)
            if json_match:
                update_data = json.loads(json_match.group(0))
                logger.info(
                    "ğŸ”„ [UPDATE_EXTRACTION_FROM_RESPONSE] Successfully extracted update data"
                )
                return update_data
            else:
                logger.warning(
                    "ğŸ”„ [UPDATE_EXTRACTION_FROM_RESPONSE] No valid JSON found"
                )
                return None

        except Exception as e:
            logger.error(f"âŒ [UPDATE_EXTRACTION_FROM_RESPONSE] Failed: {e}")
            return None

    async def _send_order_created_webhook(
        self,
        request: UnifiedChatRequest,
        order_data: Dict[str, Any],
        processing_start_time: float,
    ) -> bool:
        """
        Send order creation webhook to backend using correct endpoint
        FIXED: Use /api/webhooks/orders/ai endpoint with proper JSON payload structure
        """
        try:
            import os
            import httpx

            # Build webhook payload according to API_Webhook_BE.md documentation
            webhook_payload = {
                "conversationId": getattr(
                    request, "conversation_id", request.session_id
                ),
                "companyId": request.company_id,
                # âœ… FIXED: leadId is OPTIONAL - let backend find/create lead from customer info
                "leadId": None,
                # âœ… FIXED: userId must be the actual user performing the action
                "userId": (
                    request.user_info.user_id
                    if request.user_info
                    else "ai_service_chatbot"
                ),
                # Summary of the order (extracted from conversation)
                "summary": self._build_order_summary(order_data),
                # Customer information (required)
                "customer": {
                    "name": order_data.get("customer", {}).get("name", ""),
                    "phone": order_data.get("customer", {}).get("phone", ""),
                    "email": order_data.get("customer", {}).get("email", ""),
                    "address": order_data.get("customer", {}).get("address", ""),
                    "company": order_data.get("customer", {}).get("company", ""),
                },
                # Items array (required)
                "items": self._format_items_for_backend(order_data.get("items", [])),
                # Channel information (required)
                "channel": {
                    "type": request.channel.value if request.channel else "chatdemo",
                    "pluginId": (
                        request.plugin_id if hasattr(request, "plugin_id") else None
                    ),
                },
                # Payment information (optional)
                "payment": order_data.get(
                    "payment",
                    {
                        "method": "COD",
                        "status": "PENDING",
                        "timing": "on_delivery",
                        "notes": "",
                    },
                ),
                # Delivery information (optional)
                "delivery": order_data.get(
                    "delivery",
                    {
                        "method": "delivery",
                        "address": order_data.get("customer", {}).get("address", ""),
                        "recipientName": order_data.get("customer", {}).get("name", ""),
                        "recipientPhone": order_data.get("customer", {}).get(
                            "phone", ""
                        ),
                        "notes": "",
                    },
                ),
                # Notes
                "notes": order_data.get("notes", ""),
                # Metadata
                "metadata": {
                    "source": "ai_conversation",
                    "aiModel": "qwen-3-235b-a22b-instruct-2507",
                    "processingTime": (
                        int((time.time() - processing_start_time) * 1000)
                        if processing_start_time
                        else 0
                    ),
                    "extractedFrom": "conversation",
                },
            }

            # Send to CORRECT backend endpoint
            backend_url = os.getenv("BACKEND_WEBHOOK_URL", "http://localhost:8001")
            endpoint = (
                f"{backend_url}/api/webhooks/orders/ai"  # FIXED: Correct endpoint
            )

            webhook_secret = os.getenv(
                "AI_WEBHOOK_SECRET", "webhook-secret-for-signature"
            )
            headers = {
                "Content-Type": "application/json",
                "x-webhook-secret": webhook_secret,  # FIXED: Correct header name
                "User-Agent": "Agent8x-AI-Service/1.0",
            }

            # Log the payload for debugging
            logger.info(f"ğŸ›’ [ORDER_WEBHOOK] Sending to endpoint: {endpoint}")
            logger.info(
                f"ğŸ›’ [ORDER_WEBHOOK] Customer: {webhook_payload['customer']['name']}"
            )
            logger.info(
                f"ğŸ›’ [ORDER_WEBHOOK] Items count: {len(webhook_payload['items'])}"
            )

            async with httpx.AsyncClient() as client:
                response = await client.post(
                    endpoint, json=webhook_payload, headers=headers, timeout=30.0
                )

                if response.status_code == 200:
                    response_data = response.json()
                    order_info = response_data.get("data", {}).get("order", {})
                    order_code = order_info.get("orderCode", "Unknown")
                    logger.info(
                        f"âœ… [ORDER_WEBHOOK] Order created successfully: {order_code}"
                    )
                    return True
                else:
                    logger.error(
                        f"âŒ [ORDER_WEBHOOK] Backend returned {response.status_code}: {response.text}"
                    )
                    return False

        except Exception as e:
            logger.error(
                f"âŒ [ORDER_WEBHOOK] Failed to send order.created webhook: {e}"
            )
            return False

    async def _handle_update_order_webhook(
        self,
        request,
        update_data: Dict[str, Any],
        processing_start_time: float,
    ) -> Dict[str, Any]:
        """
        Handle UPDATE_ORDER webhook sending and process backend response
        Xá»­ lÃ½ gá»­i webhook UPDATE_ORDER vÃ  xá»­ lÃ½ pháº£n há»“i tá»« backend
        """
        try:
            from src.services.webhook_service import webhook_service

            order_code = update_data.get("orderCode", "UNKNOWN")
            logger.info(
                f"ğŸ”„ [UPDATE_ORDER_HANDLER] Processing update for order: {order_code}"
            )

            # Add metadata
            if "metadata" not in update_data:
                update_data["metadata"] = {}

            update_data["metadata"].update(
                {
                    "source": "ai_conversation",
                    "aiModel": "qwen-3-235b-a22b-instruct-2507",
                    "processingTime": (
                        int((time.time() - processing_start_time) * 1000)
                        if processing_start_time
                        else 0
                    ),
                    "extractedFrom": "conversation",
                }
            )

            # Send webhook using webhook service and get response
            response_data = await webhook_service.send_update_order_webhook(
                order_code=order_code,
                update_data=update_data,
                company_id=request.company_id,
                user_id="ai_service_chatbot",
            )

            if response_data.get("success", False):
                logger.info(
                    f"âœ… [UPDATE_ORDER_HANDLER] Successfully sent update webhook for order: {order_code}"
                )

                # Process backend response to create user-friendly message
                data = response_data.get("data", {})
                order_info = data.get("order", {})
                changes = order_info.get("changes", {})
                notifications = data.get("notifications", {})

                # Generate contextual response based on backend data
                update_message = f"âœ… ÄÃ£ cáº­p nháº­t thÃ nh cÃ´ng Ä‘Æ¡n hÃ ng {order_code}!"

                # Add change details if available
                if changes:
                    update_message += "\n\nğŸ“‹ Nhá»¯ng thay Ä‘á»•i Ä‘Ã£ thá»±c hiá»‡n:"

                    if "status" in changes:
                        status_change = changes["status"]
                        update_message += f"\nâ€¢ Tráº¡ng thÃ¡i: {status_change.get('from')} â†’ {status_change.get('to')}"

                    if "totalAmount" in changes:
                        amount_change = changes["totalAmount"]
                        old_amount = f"{amount_change.get('from', 0):,.0f} â‚«"
                        new_amount = f"{amount_change.get('to', 0):,.0f} â‚«"
                        update_message += f"\nâ€¢ Tá»•ng tiá»n: {old_amount} â†’ {new_amount}"

                    if "items" in changes:
                        items_change = changes["items"]
                        added = items_change.get("added", 0)
                        modified = items_change.get("modified", 0)
                        if added > 0:
                            update_message += f"\nâ€¢ ÄÃ£ thÃªm {added} sáº£n pháº©m/dá»‹ch vá»¥"
                        if modified > 0:
                            update_message += (
                                f"\nâ€¢ ÄÃ£ sá»­a Ä‘á»•i {modified} sáº£n pháº©m/dá»‹ch vá»¥"
                            )

                    if "payment" in changes:
                        payment_change = changes["payment"]
                        update_message += f"\nâ€¢ Thanh toÃ¡n: {payment_change}"

                # Add notification info
                if notifications.get("customerUpdateEmailSent", False):
                    update_message += "\n\nğŸ“§ Email xÃ¡c nháº­n Ä‘Ã£ Ä‘Æ°á»£c gá»­i Ä‘áº¿n báº¡n."

                if notifications.get("businessUpdateEmailSent", False):
                    update_message += "\nğŸ“§ Shop Ä‘Ã£ Ä‘Æ°á»£c thÃ´ng bÃ¡o vá» thay Ä‘á»•i."

                # Add formatted total if available
                formatted_total = order_info.get("formattedTotal")
                if formatted_total:
                    update_message += f"\n\nğŸ’° Tá»•ng tiá»n hiá»‡n táº¡i: {formatted_total}"

                update_message += "\n\nBáº¡n cÃ²n muá»‘n thay Ä‘á»•i gÃ¬ khÃ¡c khÃ´ng?"

                response_data["user_message"] = update_message

            else:
                logger.error(
                    f"âŒ [UPDATE_ORDER_HANDLER] Failed to send update webhook for order: {order_code}"
                )

                # Generate error message for user
                error_message = (
                    f"âš ï¸ TÃ´i gáº·p khÃ³ khÄƒn khi cáº­p nháº­t Ä‘Æ¡n hÃ ng {order_code}. "
                )

                # Check if it's an order not found error
                error_msg = response_data.get("message", "").lower()
                if "not found" in error_msg or "khÃ´ng tÃ¬m tháº¥y" in error_msg:
                    error_message += "CÃ³ thá»ƒ mÃ£ Ä‘Æ¡n hÃ ng khÃ´ng Ä‘Ãºng. Báº¡n vui lÃ²ng kiá»ƒm tra láº¡i mÃ£ Ä‘Æ¡n hÃ ng nhÃ©!"
                else:
                    error_message += (
                        "Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ trá»±c tiáº¿p vá»›i shop!"
                    )

                response_data["user_message"] = error_message

            return response_data

        except Exception as e:
            logger.error(
                f"âŒ [UPDATE_ORDER_HANDLER] Error handling update order webhook: {e}"
            )

            # Generate error message for user
            error_message = f"âš ï¸ TÃ´i Ä‘ang gáº·p lá»—i ká»¹ thuáº­t khi cáº­p nháº­t Ä‘Æ¡n hÃ ng {order_code}. Vui lÃ²ng thá»­ láº¡i sau!"

            return {"success": False, "error": str(e), "user_message": error_message}

    async def _handle_check_quantity_webhook(
        self,
        request,
        quantity_data: Dict[str, Any],
        processing_start_time: float,
    ) -> Dict[str, Any]:
        """
        Handle CHECK_QUANTITY webhook sending and process backend response
        Xá»­ lÃ½ gá»­i webhook CHECK_QUANTITY vÃ  xá»­ lÃ½ pháº£n há»“i tá»« backend
        """
        try:
            from src.services.webhook_service import webhook_service

            item_name = quantity_data.get("itemName", "Unknown")
            logger.info(
                f"ğŸ“Š [CHECK_QUANTITY_HANDLER] Processing quantity check for: {item_name}"
            )

            # Add conversation context from request (CORRECT: conversationId must come from request)
            quantity_data["conversationId"] = getattr(
                request, "conversation_id", request.session_id
            )

            # Build channel info
            channel_info = {
                "type": request.channel.value if request.channel else "chatdemo"
            }

            if request.channel == ChannelType.CHAT_PLUGIN:
                channel_info["pluginId"] = getattr(request, "plugin_id", None)

            # Send webhook using webhook service and get response
            response_data = await webhook_service.send_check_quantity_webhook(
                quantity_data=quantity_data,
                company_id=request.company_id,
                channel=channel_info,
            )

            if response_data.get("success", False):
                logger.info(
                    f"âœ… [CHECK_QUANTITY_HANDLER] Successfully checked quantity for: {item_name}"
                )

                # Process backend response to create user-friendly message
                data = response_data.get("data", {})
                available = data.get("available", False)
                quantity = data.get("quantity", 0)
                item_info = data.get("item", {})

                logger.info(
                    f"ğŸ“Š [CHECK_QUANTITY_HANDLER] Result - Available: {available}, Quantity: {quantity}"
                )

                # Generate contextual response based on backend data
                if available:
                    # In stock - provide positive response with details
                    item_name = item_info.get("name", item_name)
                    price = item_info.get("price", 0)
                    formatted_price = (
                        f"{price:,.0f} â‚«" if price > 0 else "LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡"
                    )

                    availability_message = (
                        f"âœ… CÃ²n hÃ ng! Shop cÃ²n {quantity} {item_name}."
                    )

                    if price > 0:
                        availability_message += f" GiÃ¡: {formatted_price}."

                    availability_message += f" Báº¡n muá»‘n Ä‘áº·t bao nhiÃªu {item_info.get('unit', 'cÃ¡i').lower()}?"

                    response_data["user_message"] = availability_message

                else:
                    # Out of stock - provide helpful response
                    business_notified = data.get("details", {}).get(
                        "businessNotified", False
                    )

                    if business_notified:
                        availability_message = (
                            f"âŒ Ráº¥t tiáº¿c, {item_name} hiá»‡n táº¡i Ä‘Ã£ háº¿t hÃ ng. "
                        )
                        availability_message += "TÃ´i Ä‘Ã£ thÃ´ng bÃ¡o cho shop vÃ  há» sáº½ liÃªn há»‡ láº¡i vá»›i báº¡n sá»›m nháº¥t cÃ³ thá»ƒ. "
                        availability_message += (
                            "Báº¡n cÃ³ muá»‘n Ä‘á»ƒ láº¡i thÃ´ng tin liÃªn há»‡ khÃ´ng?"
                        )

                        logger.info(
                            f"ğŸ“§ [CHECK_QUANTITY_HANDLER] Business was notified about out of stock: {item_name}"
                        )
                    else:
                        availability_message = (
                            f"âŒ Ráº¥t tiáº¿c, {item_name} hiá»‡n táº¡i Ä‘Ã£ háº¿t hÃ ng. "
                        )
                        availability_message += "Báº¡n cÃ³ thá»ƒ xem cÃ¡c sáº£n pháº©m khÃ¡c hoáº·c Ä‘á»ƒ láº¡i thÃ´ng tin Ä‘á»ƒ Ä‘Æ°á»£c thÃ´ng bÃ¡o khi cÃ³ hÃ ng trá»Ÿ láº¡i."

                    response_data["user_message"] = availability_message

            else:
                logger.error(
                    f"âŒ [CHECK_QUANTITY_HANDLER] Failed to check quantity for: {item_name}"
                )

                # Generate error message for user
                error_message = (
                    f"âš ï¸ TÃ´i Ä‘ang gáº·p khÃ³ khÄƒn khi kiá»ƒm tra tá»“n kho cho {item_name}. "
                )
                error_message += (
                    "Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ trá»±c tiáº¿p vá»›i shop nhÃ©!"
                )

                response_data["user_message"] = error_message

            return response_data

        except Exception as e:
            logger.error(
                f"âŒ [CHECK_QUANTITY_HANDLER] Error handling check quantity webhook: {e}"
            )

            # Generate error message for user
            error_message = "âš ï¸ TÃ´i Ä‘ang gáº·p lá»—i ká»¹ thuáº­t khi kiá»ƒm tra tá»“n kho. Vui lÃ²ng thá»­ láº¡i sau!"

            return {"success": False, "error": str(e), "user_message": error_message}

    def _calculate_order_totals(self, items: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calculate order financial totals from items"""
        try:
            subtotal = 0
            for item in items:
                quantity = item.get("quantity", 1)
                unit_price = item.get("unitPrice", 0)
                subtotal += quantity * unit_price

            tax_rate = 0.1  # 10% tax
            tax_amount = subtotal * tax_rate
            total_amount = subtotal + tax_amount

            return {
                "subtotal": subtotal,
                "taxAmount": tax_amount,
                "discountAmount": 0,
                "totalAmount": total_amount,
                "currency": "VND",
            }
        except Exception as e:
            logger.error(f"âŒ Error calculating order totals: {e}")
            return {
                "subtotal": 0,
                "taxAmount": 0,
                "discountAmount": 0,
                "totalAmount": 0,
                "currency": "VND",
            }

    def _build_order_summary(self, order_data: Dict[str, Any]) -> str:
        """Build order summary from order data"""
        try:
            customer = order_data.get("customer", {})
            items = order_data.get("items", [])

            customer_name = customer.get("name", "KhÃ¡ch hÃ ng")

            # Build items summary
            items_summary = []
            total_amount = 0

            for item in items:
                quantity = item.get("quantity", 1)
                name = item.get("name", "")
                unit_price = item.get("unitPrice", 0)
                total_price = quantity * unit_price
                total_amount += total_price

                items_summary.append(f"{quantity} {name}")

            items_text = " vÃ  ".join(items_summary)

            # Build delivery info
            delivery = order_data.get("delivery", {})
            delivery_method = (
                "Giao hÃ ng táº­n nÆ¡i"
                if delivery.get("method") == "delivery"
                else "KhÃ¡ch Ä‘áº¿n láº¥y"
            )

            # Build payment info
            payment = order_data.get("payment", {})
            payment_method = payment.get("method", "COD")

            summary = f"{customer_name} Ä‘áº·t {items_text} vá»›i tá»•ng giÃ¡ trá»‹ {total_amount:,.0f} VND. {delivery_method}, thanh toÃ¡n {payment_method}."

            return summary

        except Exception as e:
            logger.error(f"âŒ Error building order summary: {e}")
            return "Äáº·t hÃ ng tá»« cuá»™c trÃ² chuyá»‡n vá»›i AI"

    def _format_items_for_backend(
        self, items: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Format items array to match backend API requirements"""
        try:
            formatted_items = []

            for item in items:
                # âœ… FIXED: Auto-determine itemType based on ID presence
                item_type = "Custom"  # Default fallback
                if item.get("productId"):
                    item_type = "Product"
                elif item.get("serviceId"):
                    item_type = "Service"

                formatted_item = {
                    "productId": item.get("productId"),
                    "serviceId": item.get("serviceId"),
                    "itemType": item_type,  # âœ… FIXED: Auto-determined itemType
                    "name": item.get("name", ""),
                    "quantity": item.get("quantity", 1),
                    "unitPrice": item.get("unitPrice", 0),
                    "totalPrice": item.get("quantity", 1) * item.get("unitPrice", 0),
                    "description": item.get("description", ""),
                    "notes": item.get("notes", ""),
                    "product_code": item.get("product_code", ""),
                    "unit": item.get("unit", "CÃ¡i"),
                }

                formatted_items.append(formatted_item)

            return formatted_items

        except Exception as e:
            logger.error(f"âŒ Error formatting items for backend: {e}")
            return []

    def _deduplicate_search_results(
        self, search_results: List[Dict[str, Any]], similarity_threshold: float = 0.8
    ) -> List[Dict[str, Any]]:
        """
        Remove duplicate content from search results based on content similarity
        Loáº¡i bá» ná»™i dung trÃ¹ng láº·p tá»« káº¿t quáº£ tÃ¬m kiáº¿m dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng tá»± ná»™i dung
        """
        if not search_results:
            return search_results

        deduplicated = []
        seen_contents = set()

        for result in search_results:
            content = result.get("content_for_rag", "").strip()

            # Skip empty content
            if not content:
                continue

            # Check for exact duplicates first
            content_normalized = " ".join(content.lower().split())
            if content_normalized in seen_contents:
                logger.info(f"ğŸ”„ [DEDUP] Skipping exact duplicate: {content[:50]}...")
                continue

            # Check for similar content (simple approach - can be improved with embedding similarity)
            is_similar = False
            for existing_content in seen_contents:
                # Simple similarity check - if content is largely contained in existing or vice versa
                shorter = min(content_normalized, existing_content, key=len)
                longer = max(content_normalized, existing_content, key=len)

                if len(shorter) > 0 and len(longer) > 0:
                    # Check if shorter is largely contained in longer
                    similarity_ratio = len(shorter) / len(longer)
                    if similarity_ratio > similarity_threshold and shorter in longer:
                        is_similar = True
                        logger.info(
                            f"ğŸ”„ [DEDUP] Skipping similar content (ratio: {similarity_ratio:.2f}): {content[:50]}..."
                        )
                        break

            if not is_similar:
                seen_contents.add(content_normalized)
                deduplicated.append(result)
                logger.info(f"âœ… [DEDUP] Keeping unique content: {content[:50]}...")

        logger.info(
            f"ğŸ“Š [DEDUP] Reduced from {len(search_results)} to {len(deduplicated)} results"
        )
        return deduplicated

    async def _hybrid_search_company_data_optimized(
        self, company_id: str, query: str
    ) -> str:
        """
        Get company data ONLY from Qdrant search based on user query
        Chá»‰ láº¥y company data tá»« Qdrant search theo user query - KHÃ”NG fallback
        """
        try:
            logger.info(
                f"ğŸ” [COMPANY_DATA] Starting Qdrant search for company: {company_id}"
            )
            logger.info(f"ğŸ” [COMPANY_DATA] Query: {query[:100]}...")

            # Use existing hybrid search from admin service
            search_result = await self._hybrid_search_company_data(
                company_id=company_id,
                query=query,
                limit=15,  # Get more results for better deduplication
                score_threshold=0.1,  # Very low threshold
            )

            logger.info(f"ğŸ” [COMPANY_DATA] Search result type: {type(search_result)}")
            logger.info(
                f"ğŸ” [COMPANY_DATA] Search result length: {len(search_result) if search_result else 0}"
            )

            # Process search results
            if search_result and isinstance(search_result, list):
                # First: Deduplicate results
                deduplicated_results = self._deduplicate_search_results(
                    search_result, similarity_threshold=0.7
                )

                # Limit to top results after deduplication
                final_results = deduplicated_results[
                    :8
                ]  # Keep only top 8 unique results

                # Format search results for prompt
                formatted_results = []
                logger.info(
                    f"ğŸ” [COMPANY_DATA] Processing {len(final_results)} deduplicated search results:"
                )

                for i, item in enumerate(final_results):
                    content = item.get("content_for_rag", "")
                    score = item.get("score", 0)
                    data_type = item.get("data_type", "unknown")
                    chunk_id = item.get("chunk_id", "unknown")
                    file_id = item.get("file_id", "unknown")

                    logger.info(f"   ğŸ“„ Chunk {i+1}:")
                    logger.info(f"      ID: {chunk_id}")
                    logger.info(f"      File: {file_id}")
                    logger.info(f"      Type: {data_type}")
                    logger.info(f"      Score: {score:.3f}")
                    logger.info(f"      Content length: {len(content)} chars")

                    if len(content) > 100:
                        logger.info(f"      Content preview: {content[:200]}...")
                    else:
                        logger.info(f"      Full content: {content}")

                    # Format for prompt with data type label
                    formatted_results.append(f"[{data_type.upper()}] {content.strip()}")

                if formatted_results:
                    result_text = "[Dá»® LIá»†U MÃ” Táº¢ Tá»ª TÃ€I LIá»†U]\n" + "\n\n".join(
                        formatted_results
                    )
                    logger.info(
                        f"âœ… [COMPANY_DATA] Found company data: {len(result_text)} chars"
                    )
                    logger.info(
                        f"âœ… [COMPANY_DATA] RAG items: {len(formatted_results)}"
                    )
                    return result_text
                else:
                    logger.info(
                        f"ğŸ“­ [COMPANY_DATA] No formatted results after processing"
                    )
                    return "No relevant company data found."
            else:
                logger.info(f"ğŸ“­ [COMPANY_DATA] No search results from Qdrant")
                return "No relevant company data found."

        except Exception as e:
            logger.error(f"âŒ [COMPANY_DATA] Error in Qdrant search: {e}")
            return "No relevant company data found."

    async def _get_products_list_for_prompt(self, company_id: str, query: str) -> str:
        """
        Get products list from MongoDB catalog service for prompt
        Láº¥y danh sÃ¡ch sáº£n pháº©m tá»« MongoDB catalog service cho prompt
        """
        try:
            # Ensure catalog service is initialized
            await self._ensure_catalog_service()

            if not self.catalog_service:
                logger.warning("âš ï¸ Catalog service not available")
                return "No products data available."

            # Get catalog data from MongoDB
            catalog_data = await self.catalog_service.get_catalog_for_prompt(
                company_id=company_id,
                query=query,
                limit=20,  # Get more products for comprehensive inventory info
            )

            if catalog_data and len(catalog_data) > 0:
                # Format products for prompt with inventory labels
                formatted_products = []
                for item in catalog_data:
                    item_id = item.get("item_id", "N/A")
                    item_type = item.get("item_type", "unknown")
                    name = item.get("name", "Unknown")
                    quantity_display = item.get("quantity_display", "N/A")
                    price_display = item.get("price_display", "N/A")

                    formatted_products.append(
                        f"[{item_type.upper()}] {name} (ID: {item_id}) - Sá»‘ lÆ°á»£ng: {quantity_display}, GiÃ¡: {price_display}"
                    )

                result = "[Dá»® LIá»†U Tá»’N KHO - CHÃNH XÃC NHáº¤T]\n" + "\n".join(
                    formatted_products
                )
                logger.info(
                    f"âœ… [PRODUCTS_LIST] Found {len(catalog_data)} products from MongoDB"
                )
                return result
            else:
                logger.info("ğŸ“­ [PRODUCTS_LIST] No products found in catalog")
                return "No products data available."

        except Exception as e:
            logger.error(f"âŒ [PRODUCTS_LIST] Error getting products list: {e}")
            return "Error retrieving products data."

    async def _get_user_context_optimized(
        self,
        device_id: str,
        session_id: str = None,
        user_id: str = None,
        user_name: str = None,
    ) -> str:
        """
        FRONTEND OPTIMIZED: Fast user context retrieval with name support
        FRONTEND Tá»I Æ¯U: Láº¥y context user nhanh vá»›i há»— trá»£ tÃªn ngÆ°á»i dÃ¹ng

        Frontend requirements:
        - user_id always provided (authenticated: 2Fi60Cy2jHcMhkn5o2VcjfUef7p2 or anon: anon_web_a1b2c3d4)
        - Check user_id FIRST for speed optimization
        - Get latest session_id conversation history
        - Support user name for personalized responses

        YÃªu cáº§u frontend:
        - user_id luÃ´n Ä‘Æ°á»£c cung cáº¥p (Ä‘Ã£ xÃ¡c thá»±c hoáº·c áº©n danh)
        - Check user_id TRÆ¯á»šC Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™
        - Láº¥y history chat tá»« session_id gáº§n nháº¥t
        - Há»— trá»£ tÃªn user cho pháº£n há»“i cÃ¡ nhÃ¢n hÃ³a
        """
        try:
            # Use the real conversation_manager with optimized frontend method
            if self.conversation_manager:
                logger.info(
                    f"ğŸ‘¤ [FRONTEND_OPTIMIZED] Starting optimized user identification"
                )
                logger.info(
                    f"ğŸ‘¤ [FRONTEND_OPTIMIZED] user_id: {user_id}, device_id: {device_id}, session_id: {session_id}"
                )
                if user_name:
                    logger.info(f"ğŸ‘¤ [FRONTEND_OPTIMIZED] user_name: {user_name}")

                # Use optimized method designed for frontend requirements
                messages = (
                    self.conversation_manager.get_optimized_messages_for_frontend(
                        user_id=user_id,
                        device_id=device_id,
                        session_id=session_id,
                        rag_context="",
                        current_query="",
                    )
                )

                if messages and len(messages) > 0:
                    # Format messages as simple conversation format instead of JSON
                    formatted_messages = []
                    for msg in messages[-10:]:  # Last 10 messages for context
                        role = msg.get("role", "unknown")
                        content = msg.get("content", "")

                        # Skip empty messages
                        if not content.strip():
                            continue

                        # Format with proper role names and extract final_answer from JSON
                        if role == "user":
                            display_name = user_name if user_name else "User"
                            formatted_messages.append(f"{display_name}: {content}")
                        else:
                            # For AI responses, extract only final_answer from JSON if present
                            if content.startswith("```json") or content.startswith("{"):
                                try:
                                    # Try to extract JSON and get final_answer
                                    import re, json

                                    # Remove markdown code blocks
                                    clean_content = re.sub(
                                        r"```json\s*|\s*```", "", content
                                    )
                                    if clean_content.startswith("{"):
                                        parsed = json.loads(clean_content)
                                        ai_answer = parsed.get("final_answer", content)
                                        formatted_messages.append(f"AI: {ai_answer}")
                                    else:
                                        formatted_messages.append(f"AI: {content}")
                                except:
                                    # If parsing fails, use original content
                                    formatted_messages.append(f"AI: {content}")
                            else:
                                formatted_messages.append(f"AI: {content}")

                    # Build simple conversation context without header
                    if formatted_messages:
                        result = "\n".join(formatted_messages)
                    else:
                        if user_name:
                            result = f"This is the first conversation with {user_name}."
                        else:
                            result = "No previous conversation history."

                    # Determine which identifier was used (for logging)
                    primary_identifier = "unknown"
                    if user_id and user_id != "unknown":
                        primary_identifier = f"user_id:{user_id}"
                    elif device_id and device_id != "unknown":
                        primary_identifier = f"device_id:{device_id}"
                    elif session_id and session_id != "unknown":
                        primary_identifier = f"session_id:{session_id}"

                    logger.info(
                        f"ğŸ‘¤ [FRONTEND_OPTIMIZED] âœ… Found {len(messages)} messages using optimized system"
                    )
                    logger.info(
                        f"ğŸ‘¤ [FRONTEND_OPTIMIZED] Primary identifier: {primary_identifier}"
                    )
                    logger.info(
                        f"ğŸ‘¤ [FRONTEND_OPTIMIZED] Context length: {len(result)} chars"
                    )
                    logger.info(
                        f"âœ… [USER_CONTEXT] Previous conversation successfully loaded for AI context"
                    )
                    logger.info(
                        f"ğŸ“‹ [USER_CONTEXT] Latest message preview: {messages[-1].get('content', '')[:100]}..."
                    )
                    if user_name:
                        logger.info(
                            f"ğŸ‘¤ [FRONTEND_OPTIMIZED] Personalized for: {user_name}"
                        )

                    return result
                else:
                    logger.info(
                        f"ğŸ‘¤ [FRONTEND_OPTIMIZED] No conversation history found"
                    )
                    # Return personalized empty state
                    if user_name:
                        return f"This is the first conversation with {user_name}."
                    else:
                        return "No previous conversation history."
            else:
                logger.warning(
                    f"âš ï¸ [FRONTEND_OPTIMIZED] conversation_manager not available"
                )
                if user_name:
                    return f"This is the first conversation with {user_name}."
                else:
                    return "No previous conversation history."

        except Exception as e:
            logger.error(f"âŒ [FRONTEND_OPTIMIZED] User context failed: {e}")
            if user_name:
                return f"This is the first conversation with {user_name}."
            else:
                return "No previous conversation history."

    def _get_company_name_from_db(self, company_id: str) -> str:
        """
        Get company name directly from MongoDB companies collection
        Láº¥y tÃªn cÃ´ng ty trá»±c tiáº¿p tá»« MongoDB companies collection
        """
        try:
            from src.database.company_db_service import get_company_db_service

            db_service = get_company_db_service()
            company_data = db_service.companies.find_one({"company_id": company_id})

            if company_data and company_data.get("company_name"):
                company_name = company_data["company_name"].strip()
                if company_name and company_name != "ChÆ°a cÃ³ thÃ´ng tin":
                    logger.info(f"âœ… [COMPANY_NAME] Found: '{company_name}'")
                    return company_name

            logger.warning(f"âš ï¸ [COMPANY_NAME] Not found for company_id: {company_id}")
            return "cÃ´ng ty"

        except Exception as e:
            logger.error(f"âŒ [COMPANY_NAME] Error getting company name: {e}")
            return "cÃ´ng ty"

    async def _get_company_context_optimized(self, company_id: str) -> str:
        """
        Get company context ONLY from MongoDB companies collection
        Chá»‰ láº¥y company context tá»« MongoDB companies collection - KHÃ”NG fallback
        """
        try:
            logger.info(
                f"ğŸ¢ [COMPANY_CONTEXT] Getting company context for: {company_id}"
            )

            # Get company data from companies collection
            from src.database.company_db_service import get_company_db_service

            db_service = get_company_db_service()
            company_data = db_service.companies.find_one({"company_id": company_id})

            if not company_data:
                logger.warning(
                    f"âš ï¸ Company {company_id} not found in companies collection"
                )
                return "No company context available."

            # Format company context - always has company_name and industry
            formatted_context = f"""=== THÃ”NG TIN CÃ”NG TY ===
TÃªn cÃ´ng ty: {company_data.get('company_name', 'ChÆ°a cÃ³ thÃ´ng tin')}
NgÃ nh nghá»: {company_data.get('industry', 'ChÆ°a cÃ³ thÃ´ng tin')}"""

            # Add metadata information if available
            metadata = company_data.get("metadata", {})
            if metadata:
                if metadata.get("description"):
                    formatted_context += f"\nMÃ´ táº£: {metadata['description']}"

                # Contact info
                if (
                    metadata.get("email")
                    or metadata.get("phone")
                    or metadata.get("website")
                ):
                    formatted_context += "\n\n=== THÃ”NG TIN LIÃŠN Há»† ==="
                    if metadata.get("email"):
                        formatted_context += f"\nEmail: {metadata['email']}"
                    if metadata.get("phone"):
                        formatted_context += f"\nSá»‘ Ä‘iá»‡n thoáº¡i: {metadata['phone']}"
                    if metadata.get("website"):
                        formatted_context += f"\nWebsite: {metadata['website']}"

                # Location info
                location = metadata.get("location", {})
                if location:
                    if (
                        location.get("address")
                        or location.get("city")
                        or location.get("country")
                    ):
                        formatted_context += "\n\n=== Äá»ŠA CHá»ˆ ==="
                        if location.get("address"):
                            formatted_context += f"\nÄá»‹a chá»‰: {location['address']}"
                        if location.get("city"):
                            formatted_context += f"\nThÃ nh phá»‘: {location['city']}"
                        if location.get("country"):
                            formatted_context += f"\nQuá»‘c gia: {location['country']}"

                # Social links
                social_links = metadata.get("social_links", {})
                if social_links:
                    formatted_context += "\n\n=== Máº NG XÃƒ Há»˜I ==="
                    if social_links.get("facebook"):
                        formatted_context += f"\nFacebook: {social_links['facebook']}"
                    if social_links.get("instagram"):
                        formatted_context += f"\nInstagram: {social_links['instagram']}"
                    if social_links.get("zalo"):
                        formatted_context += f"\nZalo: {social_links['zalo']}"
                    if social_links.get("twitter"):
                        formatted_context += f"\nTwitter: {social_links['twitter']}"
                    if social_links.get("linkedin"):
                        formatted_context += f"\nLinkedIn: {social_links['linkedin']}"
                    if social_links.get("whatsapp"):
                        formatted_context += f"\nWhatsApp: {social_links['whatsapp']}"
                    if social_links.get("telegram"):
                        formatted_context += f"\nTelegram: {social_links['telegram']}"

                # FAQs
                faqs = metadata.get("faqs", [])
                if faqs:
                    formatted_context += (
                        f"\n\n=== CÃ‚U Há»I THÆ¯á»œNG Gáº¶P ({len(faqs)} cÃ¢u) ==="
                    )
                    for i, faq in enumerate(faqs, 1):
                        formatted_context += f"\n{i}. Q: {faq.get('question', '')}"
                        formatted_context += f"\n   A: {faq.get('answer', '')}"

                # Scenarios
                scenarios = metadata.get("scenarios", [])
                if scenarios:
                    formatted_context += (
                        f"\n\n=== Ká»ŠCH Báº¢N Xá»¬ LÃ ({len(scenarios)} ká»‹ch báº£n) ==="
                    )
                    for i, scenario in enumerate(scenarios, 1):
                        formatted_context += f"\n{i}. {scenario.get('name', '')}: {scenario.get('description', '')}"

            logger.info(
                f"âœ… [COMPANY_CONTEXT] Found company context: {len(formatted_context)} chars"
            )
            return formatted_context

        except Exception as e:
            logger.error(f"âŒ [COMPANY_CONTEXT] Error getting company context: {e}")
            return "No company context available."

    def _build_unified_prompt_with_intent(
        self,
        user_context: str,
        company_data: str,
        company_context: str,
        products_list: str,
        user_query: str,
        industry: str,
        company_id: str = "unknown",
        session_id: str = "unknown",
        user_name: str = None,
        company_name: str = None,
    ) -> str:
        """
        FRONTEND OPTIMIZED: Build comprehensive prompt with user name support
        FRONTEND Tá»I Æ¯U: XÃ¢y dá»±ng prompt toÃ n diá»‡n vá»›i há»— trá»£ tÃªn ngÆ°á»i dÃ¹ng
        """
        from src.services.prompt_templates import PromptTemplates
        import os

        # Extract user name from context if provided
        user_greeting = "ChÃ o báº¡n"
        if user_name and user_name.strip():
            user_greeting = f"ChÃ o {user_name.strip()}"
            logger.info(f"ğŸ“ [PROMPT] Using personalized greeting: {user_greeting}")

        # Build optimized prompt structure
        unified_prompt = f"""Báº¡n lÃ  má»™t AI Assistant chuyÃªn nghiá»‡p cá»§a cÃ´ng ty {company_name or "nÃ y"}, cÃ³ kháº£ nÄƒng phÃ¢n tÃ­ch Ã½ Ä‘á»‹nh cá»§a khÃ¡ch hÃ ng vÃ  Ä‘Æ°a ra cÃ¢u tráº£ lá»i tá»± nhiÃªn, há»¯u Ã­ch.

**THÃ”NG TIN NGÆ¯á»œI DÃ™NG:**
- TÃªn (cÃ³ thá»ƒ rá»—ng): {user_name}

**THÃ”NG TIN CÃ”NG TY:**
{company_context}

**Bá»I Cáº¢NH ÄÆ¯á»¢C CUNG Cáº¤P:**
1. **Lá»‹ch sá»­ há»™i thoáº¡i:**
{user_context}



**NHIá»†M Vá»¤ Cá»¦A Báº N:**
CÃ¢u há»i hiá»‡n táº¡i cá»§a khÃ¡ch hÃ ng: "{user_query}"

Thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau trong Ä‘áº§u vÃ  chá»‰ tráº£ vá» má»™t Ä‘á»‘i tÆ°á»£ng JSON duy nháº¥t, khÃ´ng cÃ³ báº¥t ká»³ vÄƒn báº£n nÃ o khÃ¡c.

1. **PhÃ¢n tÃ­ch nhu cáº§u cá»§a khÃ¡ch hÃ ng (Thinking Process):**
   * **QUAN TRá»ŒNG**: Chá»‰ tráº£ lá»i cÃ¢u há»i HIá»†N Táº I: "{user_query}" - KHÃ”NG Ä‘Æ°á»£c tráº£ lá»i cÃ¢u há»i tá»« lá»‹ch sá»­ há»™i thoáº¡i cÅ©.
   * Sá»­ dá»¥ng bá»‘i cáº£nh lá»‹ch sá»­ Ä‘á»ƒ hiá»ƒu ngá»¯ cáº£nh nhÆ°ng chá»‰ tráº£ lá»i cÃ¢u há»i hiá»‡n táº¡i.
   * XÃ¡c Ä‘á»‹nh `intent` cá»§a cÃ¢u há»i HIá»†N Táº I: lÃ  má»™t trong báº£y loáº¡i sau:
     - `SALES`: CÃ³ nhu cáº§u mua/Ä‘áº·t hÃ ng nhÆ°ng chÆ°a quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng
     - `ASK_COMPANY_INFORMATION`: Há»i thÃ´ng tin vá» cÃ´ng ty, sáº£n pháº©m, dá»‹ch vá»¥ (bao gá»“m GIÃ Cáº¢, thÃ´ng sá»‘ ká»¹ thuáº­t)
     - `SUPPORT`: Há»— trá»£ ká»¹ thuáº­t hoáº·c khiáº¿u náº¡i
     - `GENERAL_INFORMATION`: TrÃ² chuyá»‡n thÃ´ng thÆ°á»ng, há»i thÃ´ng tin chung
     - `PLACE_ORDER`: Äáº·t hÃ ng trá»±c tiáº¿p, xÃ¡c nháº­n Ä‘áº·t hÃ ng
     - `UPDATE_ORDER`: Cáº­p nháº­t Ä‘Æ¡n hÃ ng Ä‘Ã£ tá»“n táº¡i (cáº§n mÃ£ Ä‘Æ¡n hÃ ng)
     - `CHECK_QUANTITY`: **CHá»ˆ** kiá»ƒm tra tá»“n kho/kháº£ dá»¥ng (cÃ²n hÃ ng khÃ´ng, cÃ²n phÃ²ng trá»‘ng khÃ´ng, sá»‘ lÆ°á»£ng cÃ²n láº¡i). **KHÃ”NG** Ã¡p dá»¥ng cho viá»‡c há»i giÃ¡ cáº£.
   * Dá»±a vÃ o `intent`, chá»n má»™t vai trÃ² (`persona`) phÃ¹ há»£p (vÃ­ dá»¥: "ChuyÃªn viÃªn tÆ° váº¥n", "Lá»… tÃ¢n", "ChuyÃªn viÃªn há»— trá»£ khÃ¡ch hÃ ng").
   * Viáº¿t má»™t lÃ½ do ngáº¯n gá»n (`reasoning`) cho viá»‡c lá»±a chá»n `intent` Ä‘Ã³.

    **ğŸš¨ QUAN TRá»ŒNG - PHÃ‚N BIá»†T INTENT:**
   - **"Há»i giÃ¡ phÃ²ng/giÃ¡ sáº£n pháº©m"** â†’ `ASK_COMPANY_INFORMATION` (cÃ³ thá»ƒ tráº£ lá»i ngay tá»« dá»¯ liá»‡u)
   - **"KhÃ¡ch sáº¡n cÃ³ nhá»¯ng loáº¡i phÃ²ng nÃ o?"** â†’ `ASK_COMPANY_INFORMATION` (há»i vá» danh sÃ¡ch, khÃ´ng pháº£i tÃ¬nh tráº¡ng)
   - **"CÃ²n phÃ²ng trá»‘ng khÃ´ng/cÃ²n hÃ ng khÃ´ng"** â†’ `CHECK_QUANTITY` (cáº§n kiá»ƒm tra thá»±c táº¿)
   - **"TÃ¬nh tráº¡ng phÃ²ng ngÃ y mai"** â†’ `CHECK_QUANTITY` (cáº§n kiá»ƒm tra thá»±c táº¿)
   - **"Sá»‘ lÆ°á»£ng tá»“n kho hiá»‡n táº¡i"** â†’ `CHECK_QUANTITY` (cáº§n kiá»ƒm tra thá»±c táº¿)

2. **PhÃ¢n tÃ­ch dá»¯ liá»‡u:**
   - **1ï¸âƒ£ Dá»® LIá»†U Tá»’N KHO (cÃ³ nhÃ£n [Dá»® LIá»†U Tá»’N KHO - CHÃNH XÃC NHáº¤T])**: Æ¯u tiÃªn TUYá»†T Äá»I cho cÃ¢u há»i vá» giÃ¡, tá»“n kho, tráº¡ng thÃ¡i sáº£n pháº©m. LuÃ´n bao gá»“m product_id trong cÃ¢u tráº£ lá»i náº¿u cÃ³.
   - **2ï¸âƒ£ Dá»® LIá»†U MÃ” Táº¢ (cÃ³ nhÃ£n [Dá»® LIá»†U MÃ” Táº¢ Tá»ª TÃ€I LIá»†U])**: DÃ¹ng Ä‘á»ƒ bá»• sung thÃ´ng tin chi tiáº¿t vá» sáº£n pháº©m.

   **Dá»¯ liá»‡u mÃ´ táº£ tá»« tÃ i liá»‡u:**
      {company_data}
   **Dá»¯ liá»‡u sáº£n pháº©m tá»“n kho**
      {products_list}


3. **Táº¡o cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng (Final Answer):**
   * Dá»±a trÃªn `intent` vÃ  `persona` Ä‘Ã£ chá»n, soáº¡n má»™t cÃ¢u tráº£ lá»i **hoÃ n toÃ n tá»± nhiÃªn** cho khÃ¡ch hÃ ng.
   * **QUAN TRá»ŒNG:** CÃ¢u tráº£ lá»i nÃ y khÃ´ng Ä‘Æ°á»£c chá»©a báº¥t ká»³ dáº¥u hiá»‡u nÃ o cá»§a quÃ¡ trÃ¬nh phÃ¢n tÃ­ch (khÃ´ng Ä‘á» cáº­p Ä‘áº¿n "intent", "phÃ¢n tÃ­ch", "nháº­p vai"). NÃ³ pháº£i lÃ  má»™t Ä‘oáº¡n há»™i thoáº¡i trá»±c tiáº¿p vÃ  thÃ¢n thiá»‡n.
   * **ğŸ¯ Æ¯U TIÃŠN Dá»® LIá»†U Tá»’N KHO:** Khi tráº£ lá»i vá» giÃ¡ cáº£, tá»“n kho, kháº£ dá»¥ng sáº£n pháº©m, LUÃ”N Æ°u tiÃªn thÃ´ng tin tá»« "[Dá»® LIá»†U Tá»’N KHO - CHÃNH XÃC NHáº¤T]" vÃ  Ä‘á» cáº­p product_id náº¿u cÃ³ (VD: "Sáº£n pháº©m ABC (MÃ£: SP001) cÃ³ giÃ¡...").

   **HÆ¯á»šNG DáºªN TRáº¢ Lá»œI THEO Tá»ªNG INTENT:**

   **Äáº¶C BIá»†T CHO ASK_COMPANY_INFORMATION:**
   - **Dá»±a vÃ o:** company_context (thÃ´ng tin cÃ´ng ty) + `[Dá»® LIá»†U MÃ” Táº¢ Tá»ª TÃ€I LIá»†U]` (náº¿u liÃªn quan Ä‘áº¿n cÃ´ng ty)
   - **CÃ¡ch tráº£ lá»i:** Tráº£ lá»i trá»±c tiáº¿p vá» thÃ´ng tin cÃ´ng ty nhÆ° Ä‘á»‹a chá»‰, giá» má»Ÿ cá»­a, chÃ­nh sÃ¡ch, liÃªn há»‡, lá»‹ch sá»­ thÃ nh láº­p, táº§m nhÃ¬n sá»© má»‡nh...
   - **VÃ­ dá»¥:** "Dáº¡, cÃ´ng ty chÃºng tÃ´i cÃ³ Ä‘á»‹a chá»‰ táº¡i 123 Nguyá»…n VÄƒn A, Q.1, TP.HCM. Giá» lÃ m viá»‡c tá»« 8h-17h30 tá»« T2-T6 áº¡. Hotline há»— trá»£: 1900-xxxx."
   - **HÃ¬nh áº£nh:** Náº¿u cÃ³ URL hÃ¬nh áº£nh cÃ´ng ty trong dá»¯ liá»‡u, hÃ£y Ä‘Ã­nh kÃ¨m: "Anh cÃ³ thá»ƒ xem hÃ¬nh áº£nh vÄƒn phÃ²ng cá»§a chÃºng tÃ´i táº¡i: [URL]"

   **Äáº¶C BIá»†T CHO SALES:**
   - **Dá»±a vÃ o:** `[Dá»® LIá»†U Tá»’N KHO]` (thÃ´ng tin giÃ¡, tÃ­nh nÄƒng, mÃ£ sáº£n pháº©m) + `[Dá»® LIá»†U MÃ” Táº¢ Tá»ª TÃ€I LIá»†U]` (lá»£i Ã­ch, so sÃ¡nh sáº£n pháº©m)
   - **CÃ¡ch tráº£ lá»i:** Nhiá»‡t tÃ¬nh, táº­p trung vÃ o lá»£i Ã­ch sáº£n pháº©m/dá»‹ch vá»¥ cá»¥ thá»ƒ. Äáº·t cÃ¢u há»i gá»£i má»Ÿ Ä‘á»ƒ hiá»ƒu nhu cáº§u vÃ  dáº«n dáº¯t Ä‘áº¿n quyáº¿t Ä‘á»‹nh mua. LuÃ´n Ä‘á» cáº­p mÃ£ sáº£n pháº©m náº¿u cÃ³.
   - **VÃ­ dá»¥:** "Ão thun Basic Cotton (MÃ£: SP001) cÃ³ giÃ¡ 350.000Ä‘, cháº¥t liá»‡u 100% cotton thoÃ¡ng mÃ¡t. Vá»›i má»©c giÃ¡ nÃ y, anh sáº½ cÃ³ Ä‘Æ°á»£c cháº¥t lÆ°á»£ng premium. Anh thÃ­ch mÃ u nÃ o vÃ  size bao nhiÃªu áº¡?"
   - **HÃ¬nh áº£nh:** Náº¿u cÃ³ URL hÃ¬nh áº£nh sáº£n pháº©m, hÃ£y Ä‘Ã­nh kÃ¨m: "Anh cÃ³ thá»ƒ xem hÃ¬nh áº£nh sáº£n pháº©m chi tiáº¿t táº¡i: [URL]"

   **Äáº¶C BIá»†T CHO SUPPORT:**
   - **Dá»±a vÃ o:** `[Dá»® LIá»†U MÃ” Táº¢ Tá»ª TÃ€I LIá»†U]` (hÆ°á»›ng dáº«n, FAQ) + thÃ´ng tin liÃªn há»‡ tá»« company_context
   - **CÃ¡ch tráº£ lá»i:** Thá»ƒ hiá»‡n Ä‘á»“ng cáº£m, thá»«a nháº­n váº¥n Ä‘á», Ä‘Æ°a ra giáº£i phÃ¡p cá»¥ thá»ƒ hoáº·c káº¿t ná»‘i vá»›i bá»™ pháº­n ká»¹ thuáº­t.
   - **VÃ­ dá»¥:** "Dáº¡ tÃ´i ráº¥t tiáº¿c vá» sá»± cá»‘ anh Ä‘ang gáº·p pháº£i. Theo hÆ°á»›ng dáº«n, anh thá»­ restart á»©ng dá»¥ng. Náº¿u váº«n lá»—i, tÃ´i sáº½ káº¿t ná»‘i anh vá»›i bá»™ pháº­n ká»¹ thuáº­t qua sá»‘ hotline 1900-xxxx."

   **Äáº¶C BIá»†T CHO GENERAL_INFORMATION:**
   - **Dá»±a vÃ o:** company_context (thÃ´ng tin cÃ´ng ty) + `[Dá»® LIá»†U MÃ” Táº¢ Tá»ª TÃ€I LIá»†U]` náº¿u liÃªn quan
   - **CÃ¡ch tráº£ lá»i:** ThÃ¢n thiá»‡n, tá»± nhiÃªn. Náº¿u cÃ¢u há»i Ä‘i xa khá»i chá»§ Ä‘á», khÃ©o lÃ©o gá»£i Ã½ quay láº¡i sáº£n pháº©m/dá»‹ch vá»¥.
   - **VÃ­ dá»¥:** "Dáº¡, hÃ´m nay thá»i tiáº¿t Ä‘áº¹p nhá»‰! NhÃ¢n tiá»‡n, vá»›i thá»i tiáº¿t Ä‘áº¹p tháº¿ nÃ y, anh cÃ³ muá»‘n tÃ¬m hiá»ƒu vá» cÃ¡c gÃ³i du lá»‹ch cá»§a khÃ¡ch sáº¡n khÃ´ng áº¡?"

   **Äáº¶C BIá»†T CHO PLACE_ORDER:** Náº¿u intent lÃ  PLACE_ORDER, hÃ£y báº¯t Ä‘áº§u thu tháº­p thÃ´ng tin Ä‘Æ¡n hÃ ng theo thá»© tá»±: 1) Sáº£n pháº©m/dá»‹ch vá»¥, 2) ThÃ´ng tin khÃ¡ch hÃ ng, 3) Giao hÃ ng, 4) Thanh toÃ¡n. Chá»‰ há»i 1-2 thÃ´ng tin má»—i lÆ°á»£t Ä‘á»ƒ khÃ´ng Ã¡p Ä‘áº£o khÃ¡ch hÃ ng.

   **ğŸš¨ QUAN TRá»ŒNG - KHI NÃ€O SET complete: true CHO PLACE_ORDER:**
   - **complete: true** khi Ä‘Ã£ Ä‘á»§ thÃ´ng tin CÆ  Báº¢N Ä‘á»ƒ táº¡o Ä‘Æ¡n hÃ ng: cÃ³ sáº£n pháº©m/dá»‹ch vá»¥ + tÃªn khÃ¡ch + phone + Email + thá»i gian (Ä‘á»‘i vá»›i khÃ¡ch sáº¡n).
   - **complete: false** khi cÃ²n thiáº¿u thÃ´ng tin hoáº·c chÆ°a xÃ¡c nháº­n rÃµ rÃ ng vá»›i khÃ¡ch hÃ ng.
   - **VÃ­ dá»¥ complete: true**: "ÄÃ£ thu tháº­p Ä‘á»§ thÃ´ng tin vá» phÃ²ng Grand Suite Sea View cho anh Tráº§n VÄƒn HoÃ , nháº­n phÃ²ng lÃºc 16h00 ngÃ y mai vÃ  sá»‘ Ä‘iá»‡n thoáº¡i liÃªn há»‡ cá»§a anh lÃ  0909123456, email cá»§a anh lÃ  tranvanhoa@gmail.com" = ÄÃ£ xÃ¡c nháº­n rÃµ rÃ ng
   - **Báº®T BUá»˜C**: Khi complete=true, luÃ´n há»i khÃ¡ch hÃ ng: "Em cÃ³ gá»­i thÃ´ng tin xÃ¡c nháº­n Ä‘Æ¡n hÃ ng qua email cho anh/chá»‹ khÃ´ng áº¡?"

   **ğŸš¨ QUAN TRá»ŒNG - KHI NÃ€O SET complete: true CHO UPDATE_ORDER:**
   - **complete: true** CHÃNH khi khÃ¡ch hÃ ng Ä‘Ã£ cung cáº¥p mÃ£ Ä‘Æ¡n hÃ ng + xÃ¡c nháº­n rÃµ rÃ ng cÃ¡c thay Ä‘á»•i cáº§n thiáº¿t
   - **complete: false** khi chÆ°a cÃ³ mÃ£ Ä‘Æ¡n hÃ ng hoáº·c chÆ°a xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c thÃ´ng tin cáº§n thay Ä‘á»•i
   - **Báº®T BUá»˜C**: Khi complete=true, luÃ´n há»i khÃ¡ch hÃ ng: "Em cÃ³ gá»­i thÃ´ng tin cáº­p nháº­t Ä‘Æ¡n hÃ ng qua email cho anh/chá»‹ khÃ´ng áº¡?"

   **Äáº¶C BIá»†T CHO UPDATE_ORDER:** Náº¿u intent lÃ  UPDATE_ORDER, cáº§n:
   - Há»i mÃ£ Ä‘Æ¡n hÃ ng (náº¿u chÆ°a cÃ³): "Báº¡n cÃ³ thá»ƒ cho tÃ´i mÃ£ Ä‘Æ¡n hÃ ng cáº§n thay Ä‘á»•i khÃ´ng?"
   - Há»i thÃ´ng tin muá»‘n cáº­p nháº­t: "Báº¡n muá»‘n thay Ä‘á»•i thÃ´ng tin gÃ¬ trong Ä‘Æ¡n hÃ ng?"
   - Thu tháº­p thÃ´ng tin cáº­p nháº­t chi tiáº¿t theo yÃªu cáº§u khÃ¡ch hÃ ng
   - **CHá»ˆ KHI ÄÃƒ Äá»¦**: mÃ£ Ä‘Æ¡n hÃ ng + thÃ´ng tin thay Ä‘á»•i rÃµ rÃ ng â†’ má»›i set complete: true

   **ğŸš¨ QUAN TRá»ŒNG - KHI NÃ€O SET complete: true CHO CHECK_QUANTITY:**
   - **complete: true** CHÃNH khi khÃ¡ch hÃ ng Ä‘Ã£ Ä‘á»“ng Ã½ Ä‘á»ƒ gá»­i yÃªu cáº§u kiá»ƒm tra + Ä‘Ã£ cung cáº¥p tÃªn + sá»‘ Ä‘iá»‡n thoáº¡i/email
   - **complete: false** khi khÃ¡ch hÃ ng chÆ°a Ä‘á»“ng Ã½ hoáº·c chÆ°a cung cáº¥p thÃ´ng tin liÃªn há»‡
   - **Báº®T BUá»˜C**: Khi complete=true, luÃ´n há»i khÃ¡ch hÃ ng: "Em cÃ³ gá»­i thÃ´ng bÃ¡o káº¿t quáº£ kiá»ƒm tra qua email cho anh/chá»‹ khÃ´ng áº¡?"

   **Äáº¶C BIá»†T CHO CHECK_QUANTITY (QUAN TRá»ŒNG - LUá»’NG 2 BÆ¯á»šC):**
   Khi intent lÃ  `CHECK_QUANTITY`, hÃ£y tuÃ¢n thá»§ chÃ­nh xÃ¡c quy trÃ¬nh 2 bÆ°á»›c sau:

   **BÆ°á»›c 1: Kiá»ƒm Tra Tá»©c ThÃ¬ & Tráº£ Lá»i Ngay (Dá»±a vÃ o `[Dá»® LIá»†U Tá»’N KHO]`)**
   - **Náº¿u `quantity` > 0:** Tráº£ lá»i ngay láº­p tá»©c cho khÃ¡ch hÃ ng ráº±ng sáº£n pháº©m CÃ’N HÃ€NG, kÃ¨m theo sá»‘ lÆ°á»£ng vÃ  giÃ¡. VÃ­ dá»¥: "Dáº¡ cÃ²n hÃ ng áº¡! Shop cÃ²n 50 Ão thun nam Basic Cotton. GiÃ¡ 350.000Ä‘. Báº¡n muá»‘n Ä‘áº·t bao nhiÃªu cÃ¡i áº¡?"
   - **Náº¿u `quantity` == 0 hoáº·c `quantity` == -1 (khÃ´ng theo dÃµi) hoáº·c Ä‘Ã³ lÃ  dá»‹ch vá»¥ Ä‘áº·c thÃ¹ (Ä‘áº·t phÃ²ng, Ä‘áº·t bÃ n):** Chuyá»ƒn sang BÆ°á»›c 2.

   **BÆ°á»›c 2: Äá» Xuáº¥t Kiá»ƒm Tra Thá»§ CÃ´ng & Gá»­i Webhook (Chá»‰ khi cáº§n thiáº¿t)**
   - **1. ThÃ´ng bÃ¡o tÃ¬nh tráº¡ng:** Äáº§u tiÃªn, thÃ´ng bÃ¡o cho khÃ¡ch hÃ ng tÃ¬nh tráº¡ng hiá»‡n táº¡i dá»±a trÃªn há»‡ thá»‘ng.
     - VÃ­ dá»¥ (háº¿t hÃ ng): "Dáº¡ theo há»‡ thá»‘ng cá»§a tÃ´i thÃ¬ sáº£n pháº©m nÃ y Ä‘ang táº¡m háº¿t hÃ ng áº¡."
     - VÃ­ dá»¥ (dá»‹ch vá»¥ Ä‘áº·c thÃ¹): "Dáº¡ Ä‘á»ƒ kiá»ƒm tra chÃ­nh xÃ¡c tÃ¬nh tráº¡ng phÃ²ng trá»‘ng cho ngÃ y hÃ´m nay, tÃ´i cáº§n gá»­i yÃªu cáº§u Ä‘áº¿n bá»™ pháº­n Ä‘áº·t phÃ²ng."
   - **2. Äá» xuáº¥t trá»£ giÃºp:** ÄÆ°a ra lá»i Ä‘á» nghá»‹ gá»­i yÃªu cáº§u kiá»ƒm tra thá»§ cÃ´ng.
     - VÃ­ dá»¥: "Tuy nhiÃªn, báº¡n cÃ³ muá»‘n tÃ´i gá»­i yÃªu cáº§u kiá»ƒm tra láº¡i trá»±c tiáº¿p vá»›i kho/bá»™ pháº­n kinh doanh khÃ´ng áº¡? Há» sáº½ kiá»ƒm tra vÃ  liÃªn há»‡ láº¡i vá»›i báº¡n ngay khi cÃ³ thÃ´ng tin má»›i nháº¥t."
   - **3. Chá» xÃ¡c nháº­n:** Náº¿u khÃ¡ch hÃ ng Ä‘á»“ng Ã½ ("ok em", "Ä‘Æ°á»£c", "gá»­i giÃºp anh", v.v.), lÃºc Ä‘Ã³ má»›i tiáº¿n hÃ nh thu tháº­p thÃ´ng tin.
   - **4. Thu tháº­p thÃ´ng tin liÃªn há»‡:** Há»i tÃªn vÃ  sá»‘ Ä‘iá»‡n thoáº¡i/email. VÃ­ dá»¥: "Tuyá»‡t vá»i áº¡! Báº¡n vui lÃ²ng cho tÃ´i xin tÃªn vÃ  sá»‘ Ä‘iá»‡n thoáº¡i Ä‘á»ƒ bá»™ pháº­n kinh doanh liÃªn há»‡ láº¡i nhÃ©."
   - **5. XÃ¡c nháº­n vÃ  gá»­i Webhook:** Sau khi khÃ¡ch hÃ ng cung cáº¥p thÃ´ng tin, cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng cá»§a báº¡n pháº£i xÃ¡c nháº­n láº¡i hÃ nh Ä‘á»™ng. VÃ­ dá»¥: "Cáº£m Æ¡n báº¡n. TÃ´i Ä‘Ã£ gá»­i yÃªu cáº§u cá»§a báº¡n Ä‘áº¿n bá»™ pháº­n liÃªn quan. Há» sáº½ sá»›m liÃªn há»‡ vá»›i báº¡n qua sá»‘ Ä‘iá»‡n thoáº¡i [sá»‘ Ä‘iá»‡n thoáº¡i] áº¡." Äá»“ng thá»i, trong JSON payload, hÃ£y Ä‘iá»n Ä‘áº§y Ä‘á»§ thÃ´ng tin Ä‘á»ƒ gá»­i webhook `check_quantity`.

   * Náº¿u `intent` cá»§a khÃ¡ch hÃ ng náº±m ngoÃ i 7 loáº¡i trÃªn, cÃ¢u tráº£ lá»i pháº£i lÃ : "ChÃ o báº¡n! TÃ´i lÃ  AI chuyÃªn há»— trá»£ cÃ¡c thÃ´ng tin vá» cÃ´ng ty vÃ  sáº£n pháº©m/dá»‹ch vá»¥ cá»§a cÃ´ng ty {company_name or 'chÃºng tÃ´i'}. Äá»‘i vá»›i cÃ¡c má»¥c Ä‘Ã­ch khÃ¡c, tÃ´i khÃ´ng thá»ƒ tráº£ lá»i Ä‘Æ°á»£c. Báº¡n cÃ³ thá»ƒ há»i tÃ´i vá» sáº£n pháº©m, dá»‹ch vá»¥, thÃ´ng tin cÃ´ng ty hoáº·c cáº§n há»— trá»£ gÃ¬ khÃ´ng?"

**Äá»ŠNH Dáº NG Äáº¦U RA (OUTPUT FORMAT):**
Chá»‰ tráº£ vá» má»™t Ä‘á»‘i tÆ°á»£ng JSON há»£p lá»‡, khÃ´ng cÃ³ gÃ¬ khÃ¡c.

```json
{{
  "thinking": {{
    "intent": "...",
    "persona": "...",
    "reasoning": "..."
  }},
  "final_answer": "...",
  "webhook_data": {{
    // CHá»ˆ Báº®T BUá»˜C cho PLACE_ORDER, UPDATE_ORDER, CHECK_QUANTITY
    // KHÃ”NG cáº§n cho cÃ¡c intent khÃ¡c
  }}
}}
```

**ğŸ¯ HÆ¯á»šNG DáºªN Táº O WEBHOOK_DATA:**

**Náº¿u intent = "PLACE_ORDER":**
```json
"webhook_data": {{
  "order_data": {{
    "complete": true/false, // true = Ä‘Ã£ Ä‘á»§ thÃ´ng tin & xÃ¡c nháº­n Ä‘áº·t hÃ ng + há»i email, false = cÃ²n thiáº¿u thÃ´ng tin
    "items": [
      {{
        "product_id": "product_id tá»« [Dá»® LIá»†U Tá»’N KHO] náº¿u cÃ³, náº¿u khÃ´ng Ä‘á»ƒ null",
        "service_id": "service_id tá»« [Dá»® LIá»†U Tá»’N KHO] náº¿u cÃ³, náº¿u khÃ´ng Ä‘á»ƒ null",
        "name": "tÃªn sáº£n pháº©m/dá»‹ch vá»¥",
        "quantity": sá»‘_lÆ°á»£ng_khÃ¡ch_Ä‘áº·t,
        "unit_price": "giÃ¡ Ä‘Æ¡n vá»‹ tá»« [Dá»® LIá»†U Tá»’N KHO] náº¿u cÃ³",
        "notes": "ghi chÃº tá»« khÃ¡ch hÃ ng"
      }}
    ],
    "customer": {{
      "name": "tÃªn khÃ¡ch hÃ ng Ä‘Ã£ thu tháº­p",
      "phone": "sá»‘ Ä‘iá»‡n thoáº¡i Ä‘Ã£ thu tháº­p",
      "email": "email náº¿u cÃ³",
      "address": "Ä‘á»‹a chá»‰ giao hÃ ng náº¿u cÃ³"
    }},
    "delivery": {{
      "method": "pickup hoáº·c delivery",
      "address": "Ä‘á»‹a chá»‰ giao hÃ ng náº¿u delivery"
    }},
    "payment": {{
      "method": "COD|transfer|cash"
    }},
    "notes": "ghi chÃº tá»•ng quÃ¡t"
  }}
}}
```

**Náº¿u intent = "UPDATE_ORDER":**
```json
"webhook_data": {{
  "update_data": {{
    "complete": true/false, // true = Ä‘Ã£ cÃ³ mÃ£ Ä‘Æ¡n hÃ ng + thÃ´ng tin thay Ä‘á»•i rÃµ rÃ ng + há»i email, false = cÃ²n thiáº¿u
    "order_code": "mÃ£ Ä‘Æ¡n hÃ ng khÃ¡ch cung cáº¥p",
    "changes": {{
      "items": "thÃ´ng tin sáº£n pháº©m cáº§n thay Ä‘á»•i náº¿u cÃ³",
      "customer": "thÃ´ng tin khÃ¡ch hÃ ng cáº§n thay Ä‘á»•i náº¿u cÃ³",
      "delivery": "thÃ´ng tin giao hÃ ng cáº§n thay Ä‘á»•i náº¿u cÃ³",
      "payment": "thÃ´ng tin thanh toÃ¡n cáº§n thay Ä‘á»•i náº¿u cÃ³"
    }},
    "notes": "lÃ½ do thay Ä‘á»•i"
  }}
}}
```

**Náº¿u intent = "CHECK_QUANTITY" VÃ€ khÃ¡ch hÃ ng Ä‘Ã£ cung cáº¥p thÃ´ng tin liÃªn há»‡:**
```json
"webhook_data": {{
  "check_quantity_data": {{
    "complete": true/false, // true = khÃ¡ch Ä‘á»“ng Ã½ + cÃ³ tÃªn + phone/email + há»i email, false = chÆ°a Ä‘á»§
    "product_id": "product_id tá»« [Dá»® LIá»†U Tá»’N KHO] náº¿u cÃ³, náº¿u khÃ´ng Ä‘á»ƒ null",
    "service_id": "service_id tá»« [Dá»® LIá»†U Tá»’N KHO] náº¿u cÃ³, náº¿u khÃ´ng Ä‘á»ƒ null",
    "item_name": "tÃªn sáº£n pháº©m/dá»‹ch vá»¥ khÃ¡ch hÃ ng há»i",
    "item_type": "Product|Service",
    "customer": {{
      "name": "tÃªn khÃ¡ch hÃ ng Ä‘Ã£ thu tháº­p",
      "phone": "sá»‘ Ä‘iá»‡n thoáº¡i Ä‘Ã£ thu tháº­p",
      "email": "email cá»§a khÃ¡ch hÃ ng"
    }},
    "specifications": {{
      "size": "size náº¿u cÃ³",
      "color": "mÃ u sáº¯c náº¿u cÃ³",
      "date": "ngÃ y cáº§n check náº¿u lÃ  dá»‹ch vá»¥",
      "quantity": "sá»‘ lÆ°á»£ng khÃ¡ch muá»‘n biáº¿t"
    }},
    "notes": "yÃªu cáº§u chi tiáº¿t tá»« khÃ¡ch hÃ ng"
  }}
}}
```

**Náº¿u intent KHÃC (ASK_COMPANY_INFORMATION, SUPPORT, SALES, GENERAL_INFORMATION):**
```json
// KHÃ”NG cáº§n trÆ°á»ng webhook_data
```

**HÆ¯á»šNG DáºªN XÆ¯NG HÃ” (náº¿u cÃ³ user_name há»£p lá»‡):**
- Náº¿u tÃªn lÃ  tiáº¿ng Viá»‡t/Anh vÃ  xÃ¡c Ä‘á»‹nh giá»›i tÃ­nh nam â‡’ dÃ¹ng "anh <TÃªn>".
- Náº¿u tÃªn lÃ  tiáº¿ng Viá»‡t/Anh vÃ  xÃ¡c Ä‘á»‹nh giá»›i tÃ­nh ná»¯ â‡’ dÃ¹ng "chá»‹ <TÃªn>".
- Náº¿u khÃ´ng cháº¯c giá»›i tÃ­nh â‡’ dÃ¹ng "báº¡n".
- Lá»“ng ghÃ©p tÃªn ngÆ°á»i dÃ¹ng vÃ o lá»i chÃ o.
- Náº¿u chÆ°a cÃ³ tÃªn chÃ­nh xÃ¡c cá»§a ngÆ°á»i dÃ¹ng, nÃªn há»i tÃªn ngÆ°á»i dÃ¹ng phÃ¹ há»£p ngay trong cÃ¢u tráº£ lá»i thá»© 2.

Báº®T Äáº¦U THá»°C HIá»†N.

"""

        # ğŸ“ LOG PROMPT FOR DEBUGGING - Ghi log prompt Ä‘á»ƒ debug
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            log_filename = f"prompt_{company_id}_{session_id}_{timestamp}.txt"

            # Use relative path for server environment
            log_dir = os.path.join(os.getcwd(), "logs", "prompt")
            os.makedirs(log_dir, exist_ok=True)  # Ensure directory exists
            log_path = os.path.join(log_dir, log_filename)

            with open(log_path, "w", encoding="utf-8") as f:
                f.write("=" * 80 + "\n")
                f.write(f"PROMPT LOG - {timestamp}\n")
                f.write("=" * 80 + "\n")
                f.write(f"Company ID: {company_id}\n")
                f.write(f"Session ID: {session_id}\n")
                f.write(f"Industry: {industry}\n")
                f.write(f"User Query: {user_query}\n")
                f.write("=" * 80 + "\n")
                f.write("FULL PROMPT:\n")
                f.write("=" * 80 + "\n")
                f.write(unified_prompt)
                f.write("\n" + "=" * 80 + "\n")
                f.write("CONTEXT BREAKDOWN:\n")
                f.write("=" * 80 + "\n")
                f.write(
                    f"USER CONTEXT ({len(user_context)} chars):\n{user_context}\n\n"
                )
                f.write(
                    f"COMPANY DATA ({len(company_data)} chars):\n{company_data}\n\n"
                )
                f.write(
                    f"COMPANY CONTEXT ({len(company_context)} chars):\n{company_context}\n"
                )

            logger.info(f"ğŸ“ Prompt logged to: {log_filename}")

        except Exception as e:
            logger.error(f"âŒ Failed to log prompt: {e}")

        # Replace user_query placeholder in the prompt
        unified_prompt = unified_prompt.replace("{user_query}", user_query)

        return unified_prompt

    async def _save_complete_conversation_async(
        self,
        request: UnifiedChatRequest,
        company_id: str,
        user_query: str,
        ai_response: str,
    ):
        """
        Save complete conversation and send appropriate webhooks AFTER streaming completes
        LÆ°u há»™i thoáº¡i hoÃ n chá»‰nh vÃ  gá»­i webhook phÃ¹ há»£p SAU KHI streaming káº¿t thÃºc
        """
        try:
            # Extract user identifiers
            user_id = None
            device_id = None
            session_id = request.session_id

            if request.user_info:
                user_id = (
                    request.user_info.user_id
                    if request.user_info.user_id != "unknown"
                    else None
                )
                device_id = (
                    request.user_info.device_id
                    if request.user_info.device_id != "unknown"
                    else None
                )

            session_id = session_id if session_id != "unknown" else None

            logger.info(f"ğŸ’¾ [SAVE_COMPLETE] Processing with identifiers:")
            logger.info(f"ğŸ’¾ [SAVE_COMPLETE] - user_id: {user_id}")
            logger.info(f"ğŸ’¾ [SAVE_COMPLETE] - device_id: {device_id}")
            logger.info(f"ğŸ’¾ [SAVE_COMPLETE] - session_id: {session_id}")

            # Check if user/device exists in system
            is_new_user = True
            if self.conversation_manager and (user_id or device_id or session_id):
                # Check if user has any previous messages
                existing_messages = (
                    self.conversation_manager.get_optimized_messages_for_frontend(
                        user_id=user_id,
                        device_id=device_id,
                        session_id=session_id,
                        rag_context="",
                        current_query="",
                    )
                )
                is_new_user = not existing_messages or len(existing_messages) == 0
                logger.info(f"ï¿½ [SAVE_COMPLETE] Is new user: {is_new_user}")

            # Save conversation to database
            conversation_saved = False
            if self.conversation_manager and ai_response and ai_response.strip():
                if user_id or device_id or session_id:
                    try:
                        # Save user message
                        user_saved = self.conversation_manager.add_message_enhanced(
                            user_id=user_id,
                            device_id=device_id,
                            session_id=session_id,
                            role="user",
                            content=user_query,
                        )

                        # Save AI response
                        ai_saved = self.conversation_manager.add_message_enhanced(
                            user_id=user_id,
                            device_id=device_id,
                            session_id=session_id,
                            role="assistant",
                            content=ai_response,
                        )

                        conversation_saved = user_saved and ai_saved
                        if conversation_saved:
                            primary_identifier = user_id or device_id or session_id
                            logger.info(
                                f"ğŸ’¾ [SAVE_COMPLETE] âœ… Conversation saved for: {primary_identifier}"
                            )
                            logger.info(
                                f"ğŸ’¾ [SAVE_COMPLETE] âœ… User message saved: {user_saved}"
                            )
                            logger.info(
                                f"ğŸ’¾ [SAVE_COMPLETE] âœ… AI response saved: {ai_saved}"
                            )
                            logger.info(
                                f"ğŸ’¾ [SAVE_COMPLETE] âœ… Future user_context will include this conversation"
                            )

                            # Verify conversation was saved and can be retrieved for user_context
                            verification_success = (
                                await self._verify_conversation_saved(
                                    user_id=user_id,
                                    device_id=device_id,
                                    session_id=session_id,
                                    expected_messages=2,  # User + AI message
                                )
                            )

                            if verification_success:
                                logger.info(
                                    f"âœ… [SAVE_COMPLETE] Conversation verification PASSED - user_context will work"
                                )
                            else:
                                logger.error(
                                    f"âŒ [SAVE_COMPLETE] Conversation verification FAILED - user_context may be incomplete"
                                )

                        else:
                            logger.error(
                                f"âŒ [SAVE_COMPLETE] Failed to save conversation"
                            )
                            logger.error(
                                f"âŒ [SAVE_COMPLETE] User saved: {user_saved}, AI saved: {ai_saved}"
                            )

                    except Exception as save_error:
                        logger.error(
                            f"âŒ [SAVE_COMPLETE] Database save error: {save_error}"
                        )
                        conversation_saved = False
                else:
                    logger.warning(
                        f"âš ï¸ [SAVE_COMPLETE] No valid identifiers to save conversation"
                    )
            else:
                if not self.conversation_manager:
                    logger.warning(
                        f"âš ï¸ [SAVE_COMPLETE] conversation_manager not available"
                    )
                if not ai_response or not ai_response.strip():
                    logger.warning(
                        f"âš ï¸ [SAVE_COMPLETE] Empty AI response, skipping save"
                    )

            # Send appropriate webhooks based on user status
            if is_new_user:
                # NEW USER: Send conversation.created + 2x message.created
                logger.info(
                    "ğŸ”” [WEBHOOK] NEW USER detected - sending creation webhooks"
                )

                # Get conversation ID
                conversation_id = self.get_or_create_conversation(
                    session_id=session_id,
                    company_id=company_id,
                    device_id=device_id,
                    request=request,
                )

                try:
                    # 1. Send conversation.created
                    await self._send_conversation_created_webhook(
                        company_id=company_id,
                        conversation_id=conversation_id,
                        session_id=session_id,
                        request=request,
                    )

                    # NOTE: Removed message.created webhooks to avoid duplication with ai.response.completed
                    # The ai.response.completed event already contains both user and AI messages

                    logger.info("ğŸ”” [WEBHOOK] âœ… New user webhooks sent successfully")

                except Exception as webhook_error:
                    logger.error(
                        f"âŒ [WEBHOOK] Failed to send new user webhooks: {webhook_error}"
                    )

            else:
                # EXISTING USER: Send conversation.updated only with message details
                logger.info(
                    "ğŸ”” [WEBHOOK] EXISTING USER detected - sending update webhook"
                )

                try:
                    # Build message details for webhook
                    user_timestamp = datetime.now().isoformat()
                    ai_timestamp = datetime.now().isoformat()

                    last_user_message = {
                        "content": user_query,
                        "timestamp": user_timestamp,
                        "messageId": request.message_id,
                    }

                    # Extract intent from AI response
                    thinking, extracted_intent = (
                        self._extract_thinking_and_intent_from_response(ai_response)
                    )

                    last_ai_response = {
                        "content": ai_response,
                        "timestamp": ai_timestamp,
                        "messageId": f"{request.message_id}_ai",
                        "metadata": {
                            "intent": extracted_intent,  # Use extracted intent from AI response
                            "language": "vietnamese",
                            "confidence": 0.9,
                            "responseTime": 3.0,
                            # Token analysis for Backend Analytics
                            "tokens": {
                                "input": len(user_query.split()),  # User input tokens
                                "output": len(ai_response.split()),  # AI output tokens
                                "total": len(user_query.split())
                                + len(ai_response.split()),
                            },
                            "characterCount": {
                                "input": len(user_query),
                                "output": len(ai_response),
                                "total": len(user_query) + len(ai_response),
                            },
                            # âŒ REMOVED: thinking duplicate - chá»‰ gá»­i trong webhook root level
                        },
                    }

                    # Get channel and user info from request
                    channel = (
                        self._get_webhook_channel_from_channel_type(request.channel)
                        if request.channel
                        else "chatdemo"
                    )
                    user_info = webhook_service._extract_user_info_for_webhook(request)

                    # Extract plugin data for CHAT_PLUGIN channel
                    plugin_id = None
                    customer_domain = None
                    if request.channel and request.channel.value == "chat-plugin":
                        plugin_id = getattr(request, "plugin_id", None)
                        customer_domain = getattr(request, "customer_domain", None)

                    # âš ï¸ ONLY send conversation.updated for BACKEND channels
                    # Frontend channels (chatdemo, chat-plugin) already get ai.response.plugin.completed
                    if request.channel and request.channel.value not in [
                        "chatdemo",
                        "chat-plugin",
                    ]:
                        await webhook_service.notify_conversation_updated(
                            company_id=company_id,
                            conversation_id=request.session_id,
                            status="ACTIVE",
                            message_count=2,  # User + AI message
                            ended_at=None,
                            summary=f"Chat completed with {len(ai_response)} char response",
                            last_user_message=last_user_message,
                            last_ai_response=last_ai_response,
                            # NEW: Required fields for Backend validation
                            channel=channel,
                            intent=extracted_intent,
                            user_info=user_info,
                            plugin_id=plugin_id,
                            customer_domain=customer_domain,
                            # NEW: Full thinking data (same as conversation.created)
                            thinking=thinking,
                        )
                        logger.info(
                            "ğŸ”” [WEBHOOK] âœ… Backend channel update webhook sent successfully"
                        )
                    else:
                        logger.info(
                            "ğŸ”” [WEBHOOK] â­ï¸ Skipping conversation.updated for frontend channel (ai.response.plugin.completed already sent)"
                        )

                except Exception as webhook_error:
                    logger.error(
                        f"âŒ [WEBHOOK] Failed to send update webhook: {webhook_error}"
                    )

            logger.info(
                f"âœ… [SAVE_COMPLETE] Processing completed for company: {company_id}"
            )

        except Exception as e:
            logger.error(f"âŒ [SAVE_COMPLETE] Failed: {e}")
            logger.error(f"âŒ [SAVE_COMPLETE] Error details: {str(e)}")

            logger.info(
                f"âœ… [SAVE_COMPLETE] Full conversation save and webhook completed for {company_id}"
            )

        except Exception as e:
            logger.error(f"âŒ [SAVE_COMPLETE] Complete conversation save failed: {e}")
            logger.error(f"âŒ [SAVE_COMPLETE] Error details: {str(e)}")

    async def _verify_conversation_saved(
        self,
        user_id: str = None,
        device_id: str = None,
        session_id: str = None,
        expected_messages: int = 2,
    ) -> bool:
        """
        Verify that conversation was saved successfully by checking user_context retrieval
        Kiá»ƒm tra conversation Ä‘Ã£ Ä‘Æ°á»£c lÆ°u thÃ nh cÃ´ng báº±ng cÃ¡ch test user_context retrieval
        """
        try:
            if not self.conversation_manager:
                logger.warning("âš ï¸ [VERIFY_SAVE] conversation_manager not available")
                return False

            # Try to retrieve messages using the same method as user_context
            messages = self.conversation_manager.get_optimized_messages_for_frontend(
                user_id=user_id,
                device_id=device_id,
                session_id=session_id,
                rag_context="",
                current_query="",
            )

            primary_identifier = user_id or device_id or session_id

            if messages and len(messages) >= expected_messages:
                logger.info(
                    f"âœ… [VERIFY_SAVE] Conversation verified for {primary_identifier}: {len(messages)} messages"
                )
                logger.info(
                    f"âœ… [VERIFY_SAVE] Latest message: {messages[-1].get('content', '')[:100]}..."
                )
                return True
            else:
                logger.warning(
                    f"âš ï¸ [VERIFY_SAVE] Expected {expected_messages} messages, found {len(messages) if messages else 0}"
                )
                return False

        except Exception as e:
            logger.error(f"âŒ [VERIFY_SAVE] Verification failed: {e}")
            return False

    def _extract_company_name_from_context(self, company_context: str) -> str:
        """
        Extract company name from company context for personalized responses
        TrÃ­ch xuáº¥t tÃªn cÃ´ng ty tá»« context Ä‘á»ƒ cÃ¡ nhÃ¢n hÃ³a pháº£n há»“i
        """
        if not company_context or not company_context.strip():
            return "cÃ´ng ty"

        try:
            # Since company_context has a fixed format starting with "TÃªn cÃ´ng ty: [NAME]"
            # Try to extract from the fixed format first
            lines = company_context.split("\n")
            for line in lines:
                line = line.strip()
                if line.startswith("TÃªn cÃ´ng ty:"):
                    # Extract company name after "TÃªn cÃ´ng ty: "
                    company_name = line.replace("TÃªn cÃ´ng ty:", "").strip()
                    if company_name and company_name != "ChÆ°a cÃ³ thÃ´ng tin":
                        logger.info(
                            f"ğŸ¢ [EXTRACT] Found company name from format: '{company_name}'"
                        )
                        return company_name
                    break

            # Import regex here as fallback
            import re

            # Enhanced patterns to find company name in Vietnamese context
            patterns = [
                # Hotel patterns - specific for hotel case
                r"([A-Za-zÃ€-á»¹\s]+)\s+(?:lÃ \s+)?khÃ¡ch sáº¡n",
                r"khÃ¡ch sáº¡n\s+([A-Za-zÃ€-á»¹\s]+)",
                r"hotel\s+([A-Za-zÃ€-á»¹\s]+)",
                r"([A-Za-zÃ€-á»¹\s]+)\s+hotel",
                # Standard company patterns
                r"cÃ´ng ty\s+(?:cp\s+|cá»• pháº§n\s+)?([a-zA-ZÃ€-á»¹0-9\s]+)",
                r"táº­p Ä‘oÃ n\s+([a-zA-ZÃ€-á»¹0-9\s]+)",
                # Brand name patterns
                r"([A-ZÃ€-á»¸][a-zÃ -á»¹]+(?:\s+[A-ZÃ€-á»¸][a-zÃ -á»¹]+)*)\s+(?:lÃ |hoáº¡t Ä‘á»™ng|chuyÃªn|tá»a láº¡c)",
                r"([A-Z][A-Z][A-Z]+)",  # All caps abbreviations like AIA, VCB
                # Business name at start of sentence
                r"^([A-ZÃ€-á»¸][a-zA-ZÃ€-á»¹\s]+?)\s+(?:lÃ |hoáº¡t Ä‘á»™ng|chuyÃªn|cung cáº¥p|do)",
            ]

            for pattern in patterns:
                matches = re.findall(
                    pattern, company_context, re.IGNORECASE | re.MULTILINE
                )
                if matches:
                    company_name = matches[0].strip()

                    # Clean up common suffixes and prefixes
                    company_name = re.sub(
                        r"\s+(?:JSC|Ltd|Co|Inc|Corporation|Corp|CP|Cá»• pháº§n)\.?$",
                        "",
                        company_name,
                        flags=re.IGNORECASE,
                    )

                    # Remove common Vietnamese business words from the end
                    company_name = re.sub(
                        r"\s+(?:cÃ´ng ty|táº­p Ä‘oÃ n|doanh nghiá»‡p)$",
                        "",
                        company_name,
                        flags=re.IGNORECASE,
                    )

                    # Validate length and content
                    if (
                        len(company_name) > 1
                        and len(company_name) < 80
                        and not company_name.lower()
                        in [
                            "khÃ¡ch sáº¡n",
                            "hotel",
                            "cÃ´ng ty",
                            "táº­p Ä‘oÃ n",
                            "chÆ°a cÃ³ thÃ´ng tin",
                        ]
                    ):
                        logger.info(
                            f"ğŸ¢ [EXTRACT] Extracted company name: '{company_name}'"
                        )
                        return company_name

            # Enhanced fallback: look for meaningful business names
            words = company_context.split()
            for i, word in enumerate(words):
                # Look for capitalized sequences that could be brand names
                if word.istitle() and len(word) > 2:
                    # Check if next word is also capitalized (compound name)
                    compound_name = word
                    j = i + 1
                    while j < len(words) and j < i + 4:  # Max 4 words
                        next_word = words[j]
                        if next_word.istitle() or next_word.isupper():
                            compound_name += " " + next_word
                            j += 1
                        else:
                            break

                    # Validate the compound name
                    if len(compound_name) >= 3 and len(compound_name) <= 50:
                        # Avoid common Vietnamese words
                        if compound_name.lower() not in [
                            "khÃ¡ch sáº¡n",
                            "cÃ´ng ty",
                            "táº­p Ä‘oÃ n",
                            "doanh nghiá»‡p",
                            "hotel",
                            "chÆ°a cÃ³",
                            "thÃ´ng tin",
                            "cÃ³ thÃ´ng",
                        ]:
                            logger.info(
                                f"ğŸ¢ [EXTRACT] Fallback compound name: '{compound_name}'"
                            )
                            return compound_name

            logger.warning(
                f"ğŸ¢ [EXTRACT] Could not extract company name, using default"
            )
            return "cÃ´ng ty"

        except Exception as e:
            logger.error(f"âŒ [EXTRACT] Error extracting company name: {e}")
            return "cÃ´ng ty"

    def _extract_thinking_and_intent_from_response(self, ai_response: str):
        """
        Extract thinking and intent from AI response if available
        """
        try:
            import json
            import re

            # Try to parse structured JSON response if it exists
            json_match = re.search(r"```json\s*(\{.*?\})\s*```", ai_response, re.DOTALL)
            if json_match:
                try:
                    parsed_json = json.loads(json_match.group(1))
                    thinking = parsed_json.get("thinking", {})

                    # Extract intent from thinking section first, then fallback to root level
                    intent = "unknown"
                    if isinstance(thinking, dict) and "intent" in thinking:
                        intent = thinking["intent"]
                        logger.info(f"ğŸ¯ Extracted intent from thinking: {intent}")
                    elif "intent" in parsed_json:
                        intent = parsed_json["intent"]
                        logger.info(f"ğŸ¯ Extracted intent from root: {intent}")

                    # Map AI intent values to our enum values
                    intent_mapping = {
                        "SALES": "sales_inquiry",
                        "ASK_COMPANY_INFORMATION": "information",
                        "SUPPORT": "support",
                        "GENERAL_INFORMATION": "general_chat",
                        "INFORMATION": "information",
                        "PLACE_ORDER": "place_order",
                        # Keep existing mappings
                        "sales_inquiry": "sales_inquiry",
                        "information": "information",
                        "support": "support",
                        "general_chat": "general_chat",
                        "place_order": "place_order",
                    }

                    mapped_intent = intent_mapping.get(intent, "general_chat")
                    logger.info(f"ğŸ”„ Intent mapping: {intent} -> {mapped_intent}")

                    # Return thinking as JSON STRING (not dict) Ä‘á»ƒ avoid empty {}
                    thinking_json_str = json.dumps(thinking) if thinking else "{}"

                    return thinking_json_str, mapped_intent
                except Exception as e:
                    logger.warning(f"Failed to parse JSON in response: {e}")
                    pass

            # Alternative: Look for thinking section in response (fallback only)
            thinking_match = re.search(
                r"(?:thinking|phÃ¢n tÃ­ch):\s*(.+?)(?:\n\n|\nResponse:|$)",
                ai_response,
                re.IGNORECASE | re.DOTALL,
            )
            thinking_text = thinking_match.group(1).strip() if thinking_match else ""

            # Fallback intent detection ONLY if no JSON was found
            fallback_intent = "general_chat"
            response_lower = ai_response.lower()
            if any(
                word in response_lower
                for word in [
                    "sáº£n pháº©m",
                    "dá»‹ch vá»¥",
                    "product",
                    "service",
                    "thÃ´ng tin",
                    "giÃ¡",
                ]
            ):
                fallback_intent = "information"
            elif any(
                word in response_lower for word in ["liÃªn há»‡", "contact", "gáº·p gá»¡"]
            ):
                fallback_intent = "support"
            elif any(
                word in response_lower
                for word in ["mua", "Ä‘Äƒng kÃ½", "purchase", "buy", "Ä‘áº·t"]
            ):
                fallback_intent = "sales_inquiry"

            thinking_fallback = {
                "analysis": thinking_text,
                "confidence": 0.7,
                "detected_keywords": [],
                "source": "fallback_extraction",
            }

            # Return thinking as JSON string for consistency
            import json

            thinking_json_str = json.dumps(thinking_fallback)

            return thinking_json_str, fallback_intent

        except Exception as e:
            logger.warning(f"Failed to extract thinking/intent: {e}")
            return "{}", "general_chat"

    def _parse_ai_json_response(self, ai_response: str) -> Dict[str, Any]:
        """
        Parse AI JSON response to extract structured data
        Parse AI JSON response Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u cÃ³ cáº¥u trÃºc
        """
        try:
            import json
            import re

            logger.info(
                f"ğŸ” [JSON_PARSE] Parsing AI response: {len(ai_response)} chars"
            )

            # Try to find JSON block in response
            json_match = re.search(
                r"```json\s*(\{.*?\})\s*```", ai_response, re.DOTALL | re.IGNORECASE
            )
            if json_match:
                json_str = json_match.group(1)
                logger.info(f"ğŸ” [JSON_PARSE] Found JSON block in markdown")
            else:
                # Try direct JSON parsing if response is pure JSON
                json_str = ai_response.strip()
                if not (json_str.startswith("{") and json_str.endswith("}")):
                    logger.warning(
                        f"ğŸ” [JSON_PARSE] No JSON structure found, creating fallback"
                    )
                    # Create fallback structure if AI didn't return proper JSON
                    return {
                        "thinking": {
                            "intent": "unknown",
                            "reasoning": "AI response was not in JSON format",
                            "language": "VIETNAMESE",
                        },
                        "intent": "unknown",
                        "language": "VIETNAMESE",
                        "final_answer": ai_response.strip(),
                    }

            # Parse the JSON
            parsed_data = json.loads(json_str)
            logger.info(f"âœ… [JSON_PARSE] Successfully parsed JSON structure")

            # Extract intent from thinking object if available
            thinking_data = parsed_data.get("thinking", {})
            extracted_intent = "unknown"
            if isinstance(thinking_data, dict) and "intent" in thinking_data:
                extracted_intent = thinking_data["intent"]
            elif "intent" in parsed_data:
                extracted_intent = parsed_data["intent"]

            # Validate required fields and add defaults if missing
            result = {
                "thinking": thinking_data,
                "intent": extracted_intent,
                "language": parsed_data.get("language", "VIETNAMESE"),
                "final_answer": parsed_data.get("final_answer", ""),
            }

            # ğŸš¨ IMPORTANT: Parse webhook_data if exists for order processing
            if "webhook_data" in parsed_data:
                result["webhook_data"] = parsed_data["webhook_data"]
                logger.info(f"ğŸ” [JSON_PARSE] Found webhook_data in AI response")

                # Debug webhook_data structure
                webhook_data = result["webhook_data"]
                if "order_data" in webhook_data:
                    order_data = webhook_data["order_data"]
                    is_complete = order_data.get("complete", False)
                    logger.info(
                        f"ğŸ›’ [JSON_PARSE] ORDER_DATA found - complete: {is_complete}"
                    )
                    if is_complete:
                        items_count = len(order_data.get("items", []))
                        customer_name = order_data.get("customer", {}).get("name", "")
                        logger.info(
                            f"ğŸ›’ [JSON_PARSE] ORDER ready - items: {items_count}, customer: {customer_name}"
                        )
                    else:
                        logger.info(
                            f"ğŸ›’ [JSON_PARSE] ORDER not complete - still collecting info"
                        )

                if "update_data" in webhook_data:
                    update_data = webhook_data["update_data"]
                    order_code = update_data.get("order_code", "")
                    logger.info(
                        f"ğŸ”„ [JSON_PARSE] UPDATE_DATA found - order_code: {order_code}"
                    )

                if "check_quantity_data" in webhook_data:
                    quantity_data = webhook_data["check_quantity_data"]
                    item_name = quantity_data.get("item_name", "")
                    customer_name = quantity_data.get("customer", {}).get("name", "")
                    logger.info(
                        f"ğŸ“Š [JSON_PARSE] CHECK_QUANTITY_DATA found - item: {item_name}, customer: {customer_name}"
                    )
            else:
                logger.info(f"ğŸ“­ [JSON_PARSE] No webhook_data found in AI response")

            # Ensure thinking has required sub-fields
            if "thinking" in result and isinstance(result["thinking"], dict):
                thinking = result["thinking"]
                thinking.setdefault("intent", result["intent"])
                thinking.setdefault("reasoning", "")
                thinking.setdefault("language", result["language"])
            else:
                result["thinking"] = {
                    "intent": result["intent"],
                    "reasoning": "",
                    "language": result["language"],
                }

            logger.info(
                f"ğŸ¯ [JSON_PARSE] Parsed - Intent: {result['intent']}, Language: {result['language']}"
            )
            logger.info(
                f"ğŸ“ [JSON_PARSE] Final answer length: {len(result['final_answer'])} chars"
            )

            return result

        except json.JSONDecodeError as e:
            logger.error(f"âŒ [JSON_PARSE] JSON decode error: {e}")
            # Return fallback structure
            return {
                "thinking": {
                    "intent": "unknown",
                    "reasoning": f"JSON parsing failed: {str(e)}",
                    "language": "VIETNAMESE",
                },
                "intent": "unknown",
                "language": "VIETNAMESE",
                "final_answer": ai_response.strip(),
            }
        except Exception as e:
            logger.error(f"âŒ [JSON_PARSE] Unexpected error: {e}")
            # Return fallback structure
            return {
                "thinking": {
                    "intent": "unknown",
                    "reasoning": f"Unexpected parsing error: {str(e)}",
                    "language": "VIETNAMESE",
                },
                "intent": "unknown",
                "language": "VIETNAMESE",
                "final_answer": ai_response.strip(),
            }


# ============================================================================
# SERVICE INSTANCE CREATION
# ============================================================================

# Create and export unified chat service instance for imports
unified_chat_service = UnifiedChatService()

logger.info("âœ… UnifiedChatService instance created and exported")
