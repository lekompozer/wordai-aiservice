# SLIDE FORMAT WORKER - PHÃ‚N TÃCH NGUYÃŠN NHÃ‚N THáº¤T Báº I

## ğŸ” TÃ“M Táº®T Váº¤N Äá»€

**Job ID:** `769accf2-f7ef-4208-92fb-c703fc0cfc65`
**User Request:** Format 3 slides (9, 10, 11)
**Káº¿t quáº£:** Chá»‰ 1/3 slides hoÃ n thÃ nh, worker bá»‹ stuck rá»“i die

### Triá»‡u chá»©ng quan sÃ¡t Ä‘Æ°á»£c:
1. âœ… Batch job status = `completed` trong Redis
2. âŒ Chá»‰ cÃ³ 1 slide trong `slides_results` (thay vÃ¬ 3)
3. âŒ Chunk task `_chunk_0` váº«n status = `processing` sau 2 giá»
4. âŒ Worker container `unhealthy` vÃ  khÃ´ng log gÃ¬ trong 10 phÃºt
5. âš ï¸ Warning log: "Mode 2 but missing document_id or user_id, cannot update MongoDB"
6. âŒ Task data bá»‹ máº¥t khi worker crash (Redis chá»‰ cÃ²n status, khÃ´ng cÃ³ HTML)

---

## ğŸ› ROOT CAUSES - CÃC NGUYÃŠN NHÃ‚N Gá»C Rá»„

### **1. WORKER DIE/CRASH KHÃ”NG ROLLBACK TASK STATUS** âš ï¸ CRITICAL
**Vá»‹ trÃ­:** Worker main loop khÃ´ng cÃ³ cleanup khi shutdown

**Váº¥n Ä‘á»:**
```python
# Worker set status = "processing"
await set_job_status(
    job_id=job_id,
    status="processing",  # âœ… Set trÆ°á»›c khi xá»­ lÃ½
    ...
)

# Náº¿u worker crash GIá»®A CHá»ªNG â†’ status váº«n lÃ  "processing"
# â†’ Worker khÃ¡c KHÃ”NG nháº·t láº¡i task (trÃ¡nh duplicate)
# â†’ Task Bá»Š STUCK MÃƒI MÃƒI
```

**NguyÃªn nhÃ¢n worker die:**
- TimeoutError sau 5 phÃºt (line 95)
- Exception khÃ´ng catch Ä‘Æ°á»£c (line 108)
- SIGTERM/SIGINT tá»« Docker restart
- OOM (Out of Memory)
- Redis connection lost
- Claude API timeout quÃ¡ lÃ¢u

**Impact:** Task bá»‹ stuck, user khÃ´ng tháº¥y káº¿t quáº£, khÃ´ng auto-retry

---

### **2. TASK DATA KHÃ”NG PERSISTENT - CHá»ˆ LÆ¯U STATUS** âš ï¸ CRITICAL
**Vá»‹ trÃ­:** `queue_manager.dequeue_generic_task()` vÃ  task storage

**Váº¥n Ä‘á»:**
```python
# API routes táº¡o task vá»›i Ä‘áº§y Ä‘á»§ data
task = SlideFormatTask(
    document_id=request.document_id,  # âœ… CÃ³
    current_html=combined_html,       # âœ… CÃ³ (lá»›n 10KB+)
    ...
)

# Enqueue vÃ o Redis
await queue.enqueue_generic_task(task)  # LÆ°u vÃ o queue + status key

# Khi worker crash:
# - Queue item bá»‹ LPOP (xÃ³a khá»i queue)
# - Status key CHá»ˆ CÃ’N basic fields (job_id, status, user_id)
# - KHÃ”NG CÃ’N current_html, document_id chi tiáº¿t!

# Khi re-enqueue:
redis-cli RPUSH queue:slide_format "task_id"  # âŒ CHá»ˆ CÃ“ ID!
# Worker nháº·t lÃªn parse â†’ FAIL: thiáº¿u current_html
```

**Evidence tá»« Redis:**
```json
{
  "task_id": "..._chunk_0",
  "status": "pending",
  "user_id": "...",
  "document_id": null,  // âŒ LOST!
  "created_at": "...",
  "error_message": null
  // âŒ KHÃ”NG CÃ“: current_html, elements, background, format_type!
}
```

**Impact:** KhÃ´ng thá»ƒ retry task sau khi crash, data bá»‹ máº¥t vÄ©nh viá»…n

---

### **3. MODE 2 WARNING: THIáº¾U DOCUMENT_ID** âš ï¸ HIGH
**Vá»‹ trÃ­:** `_merge_chunk_results()` line 629

**Váº¥n Ä‘á»:**
```python
# Worker check document_id trÆ°á»›c khi update MongoDB
if document_id and user_id:
    # Update slide_backgrounds trong MongoDB
    ...
else:
    logger.warning(
        "âš ï¸ Mode 2 but missing document_id or user_id, cannot update MongoDB"
    )
    # âŒ SKIP UPDATE â†’ Frontend khÃ´ng tháº¥y káº¿t quáº£!
```

**NguyÃªn nhÃ¢n document_id = None:**
1. **API khÃ´ng truyá»n document_id** (Mode 2 khÃ´ng require)
2. **Task data bá»‹ máº¥t** khi worker crash (nhÆ° #2)
3. **Frontend khÃ´ng gá»­i** document_id trong request

**Frontend request cáº§n check:**
```typescript
// âŒ SAI - Thiáº¿u document_id cho Mode 2
{
  slides_data: [{slide_index: 9, current_html: "..."}],
  process_all_slides: false,
  // âŒ THIáº¾U: document_id
}

// âœ… ÄÃšNG - CÃ³ document_id
{
  document_id: "doc_06de72fea3d7",  // âœ… Báº®T BUá»˜C cho Mode 2
  slides_data: [...],
  process_all_slides: false
}
```

**Impact:**
- Worker xá»­ lÃ½ xong nhÆ°ng KHÃ”NG LÆ¯U VÃ€O MONGODB
- Frontend polling MongoDB khÃ´ng tháº¥y formatted_html
- User tháº¥y job "completed" nhÆ°ng khÃ´ng cÃ³ káº¿t quáº£

---

### **4. BATCH JOB LOGIC SAI: TÃNH TOTAL_SLIDES Tá»ª CHUNK** âš ï¸ MEDIUM
**Vá»‹ trÃ­:** API `slide_ai_routes.py` line 280

**Váº¥n Ä‘á»:**
```python
# API táº¡o batch job vá»›i 3 slides
await set_job_status(
    batch_job_id=batch_job_id,
    total_slides=num_slides,  # âœ… = 3
    ...
)

# NhÆ°ng khi táº¡o chunk task:
task = SlideFormatTask(
    batch_job_id=batch_job_id,
    total_slides=len(chunk_slides),  # âŒ = 1 (slides trong chunk nÃ y)
    ...
)

# Worker cÃ³ thá»ƒ nháº§m láº«n:
# - Batch job cÃ³ total_slides = 3
# - Chunk task cÃ³ total_slides = 1
# - Náº¿u logic sai â†’ Ä‘áº¿m sai completed
```

**Tuy nhiÃªn:** Code worker hiá»‡n táº¡i ÄÃšNG - khÃ´ng dÃ¹ng `task.total_slides` Ä‘á»ƒ update batch job, mÃ  dÃ¹ng `batch_job.get("total_slides")` tá»« Redis.

**Impact:** Nháº§m láº«n logic, nhÆ°ng khÃ´ng gÃ¢y lá»—i trá»±c tiáº¿p

---

### **5. REDIS CONNECTION ERRORS KHÃ”NG RETRY** âš ï¸ MEDIUM
**Vá»‹ trÃ­:** Worker main loop line 723

**Váº¥n Ä‘á»:**
```python
except Exception as e:
    logger.error(f"âŒ Worker: Error in main loop: {e}", exc_info=True)
    await asyncio.sleep(5)  # Sleep 5s rá»“i tiáº¿p tá»¥c

# âœ… CÃ“ retry logic
# âŒ NHÆ¯NG: Náº¿u Redis connection lost lÃ¢u > 5s
#          â†’ Worker retry liÃªn tá»¥c â†’ Spam logs â†’ CÃ³ thá»ƒ OOM
```

**Cáº§n thÃªm:**
- Exponential backoff (5s â†’ 10s â†’ 20s â†’ 60s)
- Max retry count
- Circuit breaker pattern

---

### **6. TIMEOUT 5 PHÃšT QUÃ NGáº®N CHO BATCH Lá»šN** âš ï¸ MEDIUM
**Vá»‹ trÃ­:** `process_task()` line 92

**Váº¥n Ä‘á»:**
```python
timeout_seconds = 300  # 5 phÃºt

# Vá»›i batch 12 slides:
# - Claude API: 30-120s per slide
# - Total: 360-1440s (6-24 phÃºt)
# â†’ TIMEOUT cháº¯c cháº¯n!

# Náº¿u timeout â†’ Task fail
# â†’ Batch job fail
# â†’ User máº¥t points nhÆ°ng khÃ´ng cÃ³ káº¿t quáº£
```

**Cáº§n:**
- Timeout Ä‘á»™ng dá»±a vÃ o `total_slides`: `timeout = 60 + (total_slides * 30)`
- Hoáº·c tÄƒng lÃªn 15-30 phÃºt cho batch lá»›n

---

### **7. CHUNK DELAY 90S KHI WORKER RESTART** âš ï¸ LOW
**Vá»‹ trÃ­:** Worker `_process_task_internal()` line 157

**Váº¥n Ä‘á»:**
```python
if task.chunk_index and task.chunk_index > 0:
    delay_seconds = 90 * task.chunk_index
    await asyncio.sleep(delay_seconds)
    # Chunk 1: sleep 90s
    # Chunk 2: sleep 180s
    # ...
```

**Náº¿u worker restart:**
- Chunk Ä‘Ã£ delay rá»“i nhÆ°ng restart â†’ delay láº¡i tá»« Ä‘áº§u
- User chá» lÃ¢u gáº¥p Ä‘Ã´i

**Cáº§n:** LÆ°u `chunk_started_at` trong Redis, check xem Ä‘Ã£ delay chÆ°a

---

## ğŸ“Š FRONTEND REQUEST FLOW - PHÃ‚N TÃCH

### **Cáº§n check frontend gá»­i gÃ¬:**

```typescript
// Frontend call POST /api/slides/format

// âŒ REQUEST SAI (thiáº¿u document_id):
{
  "slides_data": [
    {
      "slide_index": 8,
      "current_html": "<div>...</div>",
      "elements": [],
      "background": null
    },
    {
      "slide_index": 9,
      "current_html": "<div>...</div>",
      "elements": [],
      "background": null
    },
    {
      "slide_index": 10,
      "current_html": "<div>...</div>",
      "elements": [],
      "background": null
    }
  ],
  "user_instruction": null,
  "format_type": "format",
  "process_all_slides": false
  // âŒ THIáº¾U: document_id!
}

// âœ… REQUEST ÄÃšNG:
{
  "document_id": "doc_06de72fea3d7",  // âœ… Báº®T BUá»˜C!
  "slides_data": [...],
  "user_instruction": null,
  "format_type": "format",
  "process_all_slides": false
}
```

**Háº­u quáº£ khi thiáº¿u document_id:**
1. API váº«n accept (vÃ¬ `document_id` lÃ  Optional)
2. Task Ä‘Æ°á»£c táº¡o vá»›i `document_id=None`
3. Worker xá»­ lÃ½ xong nhÆ°ng SKIP MongoDB update (warning log)
4. Redis cÃ³ káº¿t quáº£ nhÆ°ng MongoDB KHÃ”NG CÃ“
5. Frontend polling MongoDB â†’ khÃ´ng tháº¥y gÃ¬
6. User tháº¥y loading mÃ£i

---

## ğŸ”§ GIáº¢I PHÃP - PRIORITY ORDER

### **ğŸš¨ P0 - CRITICAL (Deploy ngay)**

#### **1. Báº®T BUá»˜C document_id CHO MODE 2**
```python
# File: src/models/slide_ai_models.py
class SlideAIFormatRequest(BaseModel):
    document_id: str = Field(  # âŒ XÃ³a Optional
        ...,  # âœ… Required
        description="Document ID - REQUIRED for all modes to save results"
    )
```

#### **2. CLEANUP STUCK TASKS KHI WORKER START**
```python
# File: src/workers/slide_format_worker.py
async def initialize(self):
    await self.queue_manager.connect()

    # âœ… Reset stuck tasks
    await self._cleanup_stuck_tasks()

async def _cleanup_stuck_tasks(self):
    """Reset tasks stuck in 'processing' > 10 minutes"""
    stuck_keys = await self.redis_client.keys("job:*")
    for key in stuck_keys:
        job = await get_job_status(self.redis_client, key)
        if job.get("status") == "processing":
            started_at = job.get("started_at")
            if started_at:
                elapsed = (datetime.utcnow() - datetime.fromisoformat(started_at)).total_seconds()
                if elapsed > 600:  # 10 phÃºt
                    logger.warning(f"ğŸ”„ Resetting stuck job {key}")
                    await set_job_status(
                        self.redis_client,
                        job_id=key,
                        status="failed",
                        error="Worker crashed, task reset"
                    )
```

#### **3. LÆ¯U TASK DATA VÃ€O REDIS HASH (cho retry)**
```python
# File: src/queue/queue_manager.py
async def enqueue_generic_task(self, task: BaseModel) -> bool:
    # âœ… LÆ°u FULL task data vÃ o hash
    task_key = f"task:{task.task_id}"
    await self.redis_client.hset(task_key, mapping={
        "task_json": task.json(),  # Full data
        "created_at": datetime.utcnow().isoformat()
    })
    await self.redis_client.expire(task_key, 86400)  # 24h TTL

    # Enqueue task ID vÃ o queue
    await self.redis_client.rpush(f"queue:{self.queue_name}", task.task_id)
```

```python
# File: src/workers/slide_format_worker.py
async def retry_failed_task(self, task_id: str):
    """Retry task tá»« Redis hash"""
    task_key = f"task:{task_id}"
    task_data = await self.redis_client.hget(task_key, "task_json")
    if task_data:
        task = SlideFormatTask.parse_raw(task_data)
        await self.process_task(task)
```

---

### **âš ï¸ P1 - HIGH (Deploy trong tuáº§n)**

#### **4. TÄ‚NG TIMEOUT CHO BATCH Lá»šN**
```python
# Dynamic timeout
timeout_seconds = 60 + (task.total_slides or 1) * 30  # 60s base + 30s/slide
```

#### **5. EXPONENTIAL BACKOFF CHO REDIS ERRORS**
```python
retry_count = 0
max_retries = 5
backoff = 5

while retry_count < max_retries:
    try:
        await self.queue_manager.connect()
        break
    except Exception as e:
        retry_count += 1
        wait_time = backoff * (2 ** retry_count)  # 5s, 10s, 20s, 40s, 80s
        logger.warning(f"Redis connection failed, retry {retry_count}/{max_retries} in {wait_time}s")
        await asyncio.sleep(wait_time)
```

#### **6. HEALTH CHECK ENDPOINT CHO WORKER**
```python
# File: src/workers/slide_format_worker.py
from aiohttp import web

async def health_check(request):
    # Check Redis connection
    # Check running tasks
    # Return 200 if healthy
    return web.json_response({"status": "healthy", "active_tasks": len(running_tasks)})

# Docker healthcheck
# HEALTHCHECK CMD curl -f http://localhost:8080/health || exit 1
```

---

### **ğŸ“Œ P2 - MEDIUM (Tuáº§n sau)**

#### **7. MONITORING & ALERTING**
```python
# Prometheus metrics
from prometheus_client import Counter, Gauge

tasks_processed = Counter('worker_tasks_processed_total', 'Total tasks processed')
tasks_failed = Counter('worker_tasks_failed_total', 'Total tasks failed')
active_tasks = Gauge('worker_active_tasks', 'Currently active tasks')
```

#### **8. DEAD LETTER QUEUE**
```python
# Tasks fail > 3 láº§n â†’ chuyá»ƒn vÃ o DLQ
if task.retry_count >= 3:
    await self.redis_client.rpush("queue:slide_format:dlq", task.json())
    logger.error(f"Task {task.task_id} moved to DLQ after 3 failures")
```

---

## ğŸ“‹ SUMMARY - Káº¾T LUáº¬N

### **3 Váº¤N Äá»€ CHÃNH:**

1. **âŒ Frontend thiáº¿u `document_id` trong request Mode 2**
   - â†’ Worker khÃ´ng lÆ°u Ä‘Æ°á»£c MongoDB
   - â†’ Frontend khÃ´ng tháº¥y káº¿t quáº£

2. **âŒ Worker crash khÃ´ng reset task status**
   - â†’ Task stuck á»Ÿ "processing" mÃ£i mÃ£i
   - â†’ User khÃ´ng tháº¥y lá»—i, khÃ´ng retry Ä‘Æ°á»£c

3. **âŒ Task data khÃ´ng persistent**
   - â†’ Crash máº¥t háº¿t HTML, khÃ´ng retry Ä‘Æ°á»£c
   - â†’ Pháº£i request láº¡i tá»« Ä‘áº§u

### **ACTION ITEMS:**

**Ngay láº­p tá»©c:**
1. âœ… Check frontend code - báº¯t buá»™c gá»­i `document_id`
2. âœ… Deploy fix: require `document_id` trong API
3. âœ… Deploy fix: cleanup stuck tasks khi worker start
4. âœ… Deploy fix: lÆ°u full task data vÃ o Redis hash

**Tuáº§n nÃ y:**
5. â° TÄƒng timeout cho batch lá»›n
6. ğŸ”„ Exponential backoff cho Redis errors
7. â¤ï¸ Health check endpoint

**Sau:**
8. ğŸ“Š Monitoring metrics
9. ğŸ’€ Dead letter queue
10. ğŸ§ª Integration tests

---

**NgÃ y phÃ¢n tÃ­ch:** 2026-01-06
**NgÆ°á»i phÃ¢n tÃ­ch:** GitHub Copilot
**Äá»™ Æ°u tiÃªn:** CRITICAL - Cáº§n deploy fixes trong 24h
